we animate physical phenomena like cloth and fluids. But animating characters remains a manual and tedious process. Traditional animation techniques tend to  produce stiff and unresponsive behaviors. We are using reinforcement learning to develop more life-like and responsive physically simulated characters. Our character learns to perform life-like motions by imitating human motion data, such as walking, running, and sword swings. Our character is put through an intense training regimen for 10 years in simulation. Thanks to NVIDIAâ€™s massively parallel GPU simulator, this just takes 3 days of real world time.  The character then learns to perform a large variety of motor skills. Once the character has been trained, it can use those skills  that it has learned to perform more complex tasks. Here, the character is trained to run to a target object and knock it over. We can also steer the character to walk in different directions like you would with a game character. Our model allows the character to automatically synthesize life-like responsive behaviors to new situations. We can also control the character using natural language commands. For example, we can tell the character to do a shield bash or swing its sword. We hope this technology will eventually make animating simulated characters  as easy and seamless as talking to a real actor. 