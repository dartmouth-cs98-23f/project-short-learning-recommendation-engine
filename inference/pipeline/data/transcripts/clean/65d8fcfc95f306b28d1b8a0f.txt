and start talking about our first technical subject of this course and as an introduction to computer architecture were going to be talking about what is architecture versus microarchitecture and I want to just briefly say that as you take this class the first three lectures or so should be review so if you sing in the class and youre saying oh Ive seen all this before dont get up wait to the fourth or fifth lecture and then the content will become new and this is because I want to teach everything from first principles and get everyone up to speed but its that those first few lectures are going to go very fast so if youre lost in the first three lectures which should be reviewed then thats probably a bad in indicator so well start off by talking about architecture versus microarchitecture and I wanted to say briefly what I mean by architecture and I have in this slide here a very large a4 what Ill sometimes call Big Eight architecture so your Patterson has he calls this instruction set architecture and when I contrast this with micro architecture or paracin hennessy calls organization so big 8 architecture is an abstraction layer provided to software or instruction set architectures our abstraction layer provided to software which is designed to not change very much and it doesnt say it says how a theoretical fundamental sort of machine execute programs it does not say exactly the size of different structures how fast those things will run the exact implementation issues that falls into organization and one of the things I wanted to emphasize is that computer architecture is all about trade-offs so when I say its all about trade-offs you can make different design decisions up here in the big a architecture or the instruction set architecture thatll influence the application itll influence the microarchitecture but also you can make different design decisions down here and make a lot of different trade-offs on how to go about implementing a particular instruction set architecture and largely when you go to look at computer architecture and computer architecture implementation the design space is relatively flat theres sort of an optimum point where you you want to be but the other points around it are many times not horribly horribly bad though there are you know at the at extremes probably horribly bad design decisions but you know a lot of different design points are equally good or close to the optimal and the job of computer architect is to make the very subtle design decisions around how do you move around this point to make it both easier to program lives on for many years theres a little power and the sort of other a little bit of aesthetic characteristics mixed together with just making your computer and processor go fast well say and these trade-offs I will reiterate this over and over again in this class that because theres multiple different metrics so for instance speed energy cost and they trade off against each other many times and there is no necessarily optimal point it depends on you know if are you more cost driven in or energy driven or speed driven and within that point theres sort of sometimes Pareto optimal curves where all the points are are equally good if youre trying to trade off these different things for different cost models okay so lets lets talk about what is a instruction set architecture and what is a microarchitecture so a instruction set architecture or big a architecture is trying to provide the programmer some abstract machine model and many times what it really boils down to is its all the programmer visible state so for instance how does the machine have memory doesnt have registers so thats the thats the programmer visible state it also encompasses the fundamental operation that the computer can run so these are called instructions and it defines the instructions and how they operate so for instance ad ad might be a fundamental instruction or fundamental operation in your computer instruction set architecture and it says the exact semantics on how to take one word in a register and add it to another word register and where it ends ends up then theres more complicated execution semantics so whatll be my execution semantics well if you just say ads take two numbers and add them together and put them in another register that many times does not encompass all of the instruction set architecture youll have other things going on for instance IO interrupts and you have to define in your instruction set architecture or your big a computer architecture what is these X semantics of an interrupt or a instruction or a piece of data coming in on Io how does that interact with the rest of the processor so many times the instruction execution semantics is only half of it and we have to worry about is the the rest of the machine execution semantics Big Eight architecture has to define how the inputs and the outputs work and finally we has to define the data types and the sizes of the fundamental data words that you operate on so for instance do you operate on a bytes at a time four bytes at a time two bytes at a time how big is a byte do you actually have bytes so this is gets into sizes and then data types here might mean that you have other types of fundamental data so for instance the most basic one is you have just some bits sitting on on you know in a register in your processor but it could be much more complex so you could have for instance something like floating-point numbers where its not just a bunch of bits its its formatted in a particular way and has very specific meanings its a floating-point number that can range over lets say most of the the real numbers okay so in todays lecture were going to step through all these different characteristics and requirements of building an instruction set architecture and I wanted to and well talk about how its different than microarchitecture or organization so lets take out some examples of microarchitecture and organization so what microarchitecture and organization is really thinking about here is the trade-offs as youre going to implement a fixed instruction set architecture so for instance something like Intels x86 is an instruction set architecture and theres many different micro architectures or implementations there is the AMD versions of the chips and then theres the Intel versions of the chips and even inside of lets say the Intel versions of the chips they have their high performance version for the laptop which looks one way or high performance personal info Id say a server or or high-end laptop which looks one way and theres another chip for our tablets Intels trying to make chips for tablets these days and they have their Atom processors and internally they look very different because they have very different speed energy cost trade-offs but they will all execute the same code and they all implement the same instruction set architecture so lets look at some examples of things that you might trade off in a microarchitecture so you might have different pipeline depth numbers of pipelines so you might have one processor pipeline or you might have six like something like the core i7s today cache sizes how big the chip is the silicon area how whats your peak power execution ordering well does the code run in order or can you execute the code out of order thats right it is possible to take a sequential program and actually execute later portions of the program before earlier portions of the program and thats kind of mind-boggling but its a way to go about getting parallelism and if you keep your ordering correct things things work out the Swifts ALU whiffs you if you have a say a 64-bit machine you can actually go and implement that as a bunch of one bit adders for instance and people have done things like that in the microarchitecture and this allows you to build more expensive or less expensive versions of the same processor so lets talk about the history of why we came up with these two differentiations between architecture and microarchitecture and it came about because software sort of pushed it on us and ended up being a nice abstraction layer so back in the early 50s late 40s you had software that people mostly programmed either in assembly language or machine code language so yeah right ones and zeros or you had to write assembly code and sometime in the the mid 50s we started to see libraries show up so these are sort of floating point operations were made easier we had transcendentals as the sine cosine libraries you had some matrix and equation solvers and he started to see some libraries that people who call but people were not necessarily writing code by themselves or any large bodies of code in assembly programming because it was pretty painful and then at some point there was the invention of higher-level languages so a good example this was Fortran I came out in 1956 and a lot of things came along with this we had assemblers loaders linkers compilers a bunch of other software to track how your software is being used even and because we started to see these higher-level languages this started to give some portability to programming it wasnt that you had to write your program and have it only mapped to one Pro one processor ever and back in the 50s even 60s time frame here machines required experienced operators who could write the programs and you know you youve got these machines and they had to be sold with a lot of software along with them so you had to basically run only the software that was given because it was yet to be a master programmer or someone who worked for the company too even that built the machine to even build a program these machines back in the day and the idea of instruction set architectures and these breaking the microarchitecture from the architecture didnt really exist back then and back in the early 60s IBM had four different product lines and they were all incompatible so you couldnt run code that you ran on one on the other so to give you an example here the IBM 701 was for scientific computing the 1401 was mostly for business computation and I think they even had a second one that was sort of for business but different types of business computation and people sort of bought into a line and then as you as the line matured and developed they had either rewrite their code or they had to stick into one line but IBM had some and some crazy insights here is that they didnt want to have to when they went to the next generation of processor they wouldnt want to propagate these four lines they wanted to try to unify the four lines but one of the problems was these different lines had very different implementations and different cost points so the thing you were building for scientific computing wasnt necessarily the thing you want to build for business computing and the one that you built for business computing lets say didnt you wanted to not have it have very good floating-point performance so how do how do they go about solving this and their solution was they came up with something called the IBM 360 and the IBM 360 is probably the first true instruction set architecture that was implemented to be an instruction set architecture and the idea here was they wanted to unify all of these products into one platform but then implement different versions that were specialized for the different market niches so they could build they could unify a lot of their software systems unify a lot of what they built but still build different versions so lets lets take a look at the IBM 360 instruction set architecture and then talk about different micro architectures that have been built of the IBM 360 so the IBM 360 is a general purpose register machine and well talk more about that later in this lecture but to give you an idea this is what the programmer saw or what the software system saw this isnt what was actually built in the hardware because that would be a microarchitecture constraint but the processor state had 16 general-purpose 3 two-bit registers it had four floating-point registers had control flags if you will had a condition codes and control flags and it was a 24-bit address machine at the time that was huge so to the 24 was a very large number nowadays its not so large and theyve since expanded that on the IBM 360 successors but they thought it was good for many many years and it was good for many many years and they defined a bunch of different data formats so there was 8-bit bytes 16-bit half words 32-bit words 64-bit double words and these were the fundamental data types that you could work on and you can name these different fundamental data types and it was actually the IBM 360 that came up with this idea that bytes should be 8 bits long and thats lived on on for today because before that we had lots of different choices there was binary-coded decimal systems where the you actually would encode a number between 0 and 9 and then you had the each digits and this is sometimes good for sort of spreadsheet calculations or business calculations we want to be very sice on your rounding to the penny and sometimes bit based things dont actually round appropriately oh theyll do the you lose pennies off the end and so you had these binary coded decimal systems and well-nigh BM 360 they they unified it all and said well no were gonna throw out certain things and make make choices now they of course because its the IBM 360 and they did have business applications they still support it binary coded decimal in a certain way and lets look at the microarchitecture implementations of this first instruction set architecture so at in this is in the same timeframe the same generation here there is the model 30 in the model 70 and this was very very different performance characteristics so if we we look at the machine lets start off by looking at the storage the the low-end model here had between 8 and 64 kilobytes and the high-end model had between 256 and 512 kilobytes so very very different sizes and this is what Im trying to get across here is the microarchitecture can actually change quite a bit even though the architecture supports 64-bit and ads and additions you can actually implement different size data paths so in the low-end machine they had an 8 bit data path and for one to do a 64-bit operation it had to do eight sapin operations to make up a 64-bit operation and probably it actually even had to do more than that to handle all the carries correctly versus the high-end implementation had a full adder there and it can actually do a 64-bit ad by itself without having to do lots of micro sequence operations and oh yes with minor modifications it lives on today so this was designed in the 60s and even today we still have system/360 derivative machines and a piece of code you ran or you wrote back in 1965 will still run on these machine today which is pretty pretty amazing natively so how does this survive on today so heres actually the IBM 360 47 years later as in the Z 11 microprocessor so the IBM 360 has since been renamed to the IBM 370 and then it has been renamed to the IBM 370 e^x which was in the 80s there was never a IBM 380 strangely enough and then later on they just changed the name to the Z series so have a cooler bottling model numbers here so we had the IBM z series processors and this lives on today so going back to that 8-bit processor which had a 1 microsecond control store read which is forever we now have the z11 which is running at 5.2 gigahertz has 1.4 billion transistors they they have updated the addressing so its no longer 24-bit addressing but it still supports the original 360 addressing has four cores out of order issue out of order memory system big caches on on chip 24 megabytes of your l3 cache and you can even put multiple these together to build a multiprocessor system out of lots and lots of multi course and what Im trying to get across here is that if you go forward over time and you build your instructions set architecture correct it can live on and you have many different microarchitecture implementations and still leverage the same software and a few few more examples just to reinforce this a little bit more lets take a look at an example of something where you have the same architecture but different micro architectures so here we have the AMD phenom x4 and here we have the Adam Intel Atom processor the first Intel Atom processor and what youll notice actually is that they have the exact same instruction set architecture they prefer on x86 code and that is sign implementations and this is just to point out here these are the same time frames so this is modern modern roughly modern-day processors this one has four cores 125 watts here we have single core 2 watts so theres design trade-offs so you want to build different processors in the same design technology will say but with very different cost power performance trade-offs this one can decode 3 instructions this one can decode 2 instructions so its a different microarchitecture difference this one has 64 kilobyte cache l1 this one as a 32 kilobytes l1 I cache very different cache sizes even though theyre employing the same architecture or big a architecture strangely enough they have the same l2 size you know things happen this ones out of order versus in order and clock speeds are very different and I want to contrast this with different architecture or different Begay architecture and different microarchitecture so if we think about some different examples of instruction set architectures theres x86 theres PowerPC theres IBM 360 theres alpha theres arm youve probably heard all these different names and these are different instruction set architectures so you cant run the same software on those two different instruction set architectures so here we have an example of two different instruction set architectures with two different microarchitectures so we have the phenom x4 here versus the IBM power 7 and we already talked about the x4 here but the power 7 has our instruction set which is different than the x86 instruction set so you cant run one piece of code thats compiled for this over here and vice versa and the microarchitecture is are different so here we have eight core 200 watts and decode six instructions per cycle while this is a pretty beefy processor its also out of order and has the same clock frequency something that I that can also happen is you can end up with architectures where you have different instruction set architecture a different big a architecture but almost the same microarchitecture and this this does this does happen so you end up with lets say two processors that are both three wide issue same calf sizes but lets say one of them implements PowerPC and the other one implements x86 and things things like that do happen thats more of a coincidence but Im trying to get across the idea that many times the that the microarchitecture could be the same and those are more trade-off considerations versus the instruction set architecture which is more of a software programming design constraint you 