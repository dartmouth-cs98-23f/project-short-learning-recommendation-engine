second,duration,transcript
6.95,4.89,[Music]
9.36,4.08,let's begin this lesson by defining the
11.84,3.999,term statistics
13.44,4.08,statistics is a mathematical science
15.839,4.321,pertaining to the collection
17.52,3.679,presentation analysis and interpretation
20.16,2.959,of data
21.199,4.401,it's widely used to understand the
23.119,4.561,complex problems of the real world and
25.6,3.36,simplify them to make well-informed
27.68,3.439,decisions
28.96,4.4,several statistical principles functions
31.119,5.041,and algorithms can be used to analyze
33.36,5.6,primary data build a statistical model
36.16,5.68,and predict the outcomes
38.96,6.08,an analysis of any situation can be done
41.84,5.6,in two ways statistical analysis or a
45.04,4.56,non-statistical analysis
47.44,4.32,statistical analysis is the science of
49.6,4.24,collecting exploring and presenting
51.76,3.68,large amounts of data to identify the
53.84,3.84,patterns and trends
55.44,4.48,statistical analysis is also called
57.68,4.16,quantitative analysis
59.92,4.48,non-statistical analysis provides
61.84,5.68,generic information and includes text
64.4,5.6,sound still images and moving images
67.52,5.599,non-statistical analysis is also called
70.0,5.76,qualitative analysis although both forms
73.119,4.64,of analysis provide results statistical
75.76,3.28,analysis gives more insight and a
77.759,3.04,clearer picture
79.04,3.28,a feature that makes it vital for
80.799,3.521,businesses
82.32,4.799,there are two major categories of
84.32,4.88,statistics descriptive statistics and
87.119,4.401,inferential statistics
89.2,4.08,descriptive statistics helps organize
91.52,3.68,data and focuses on the main
93.28,3.76,characteristics of the data
95.2,4.08,it provides a summary of the data
97.04,5.039,numerically or graphically
99.28,5.92,numerical measures such as average mode
102.079,4.961,standard deviation or sd and correlation
105.2,3.36,are used to describe the features of a
107.04,3.439,data set
108.56,3.599,suppose you want to study the height of
110.479,4.0,students in a classroom
112.159,4.24,in the descriptive statistics you would
114.479,4.32,record the height of every person in the
116.399,4.72,classroom and then find out the maximum
118.799,4.241,height minimum height and average height
121.119,4.241,of the population
123.04,4.88,inferential statistics generalizes the
125.36,4.72,larger data set and applies probability
127.92,4.0,theory to draw a conclusion
130.08,3.519,it allows you to infer population
131.92,3.92,parameters based on the sample
133.599,3.761,statistics and to model relationships
135.84,3.119,within the data
137.36,3.84,modeling allows you to develop
138.959,4.241,mathematical equations which describe
141.2,3.36,the inner relationships between two or
143.2,3.52,more variables
144.56,4.319,consider the same example of calculating
146.72,4.159,the height of students in the classroom
148.879,4.241,in inferential statistics you would
150.879,4.961,categorize height as tall
153.12,4.88,medium and small and then take only a
155.84,3.52,small sample from the population to
158.0,2.8,study the height of students in the
159.36,3.28,classroom
160.8,4.24,the field of statistics touches our
162.64,4.56,lives in many ways from the daily
165.04,4.32,routines in our homes to the business of
167.2,5.36,making the greatest cities run the
169.36,5.28,effect of statistics are everywhere
172.56,3.759,there are various statistical terms that
174.64,3.28,one should be aware of while dealing
176.319,5.121,with statistics
177.92,6.239,population sample variable quantitative
181.44,6.4,variable qualitative variable discrete
184.159,5.761,variable continuous variable
187.84,4.88,a population is the group from which
189.92,7.039,data is to be collected
192.72,4.239,a sample is a subset of a population
197.76,3.6,a variable is a feature that is
199.599,4.0,characteristic of any member of the
201.36,4.56,population differing in quality or
203.599,4.56,quantity from another member
205.92,4.399,a variable differing in quantity is
208.159,4.401,called a quantitative variable for
210.319,4.961,example the weight of a person number of
212.56,4.8,people in a car
215.28,3.92,a variable differing in quality is
217.36,5.04,called a qualitative variable or
219.2,6.16,attribute for example color the degree
222.4,5.199,of damage of a car in an accident
225.36,4.32,a discrete variable is one which no
227.599,3.36,value can be assumed between the two
229.68,3.68,given values
230.959,4.081,for example the number of children in a
233.36,4.079,family
235.04,4.72,a continuous variable is one in which
237.439,3.681,any value can be assumed between the two
239.76,4.08,given values
241.12,4.399,for example the time taken for a 100
243.84,3.44,meter run
245.519,3.841,typically there are four types of
247.28,3.2,statistical measures used to describe
249.36,3.68,the data
250.48,5.84,they are measures of frequency measures
253.04,5.199,of central tendency measures of spread
256.32,4.319,measures of position
258.239,4.321,let's learn each in detail
260.639,4.0,frequency of the data indicates the
262.56,4.4,number of times a particular data value
264.639,4.56,occurs in the given data set
266.96,4.16,the measures of frequency are number and
269.199,3.841,percentage
271.12,3.92,central tendency indicates whether the
273.04,4.08,data values tend to accumulate in the
275.04,3.12,middle of the distribution or toward the
277.12,2.88,end
278.16,2.64,the measures of central tendency are
280.0,3.919,mean
280.8,5.679,median and mode
283.919,4.481,spread describes how similar or varied
286.479,3.521,the set of observed values are for a
288.4,3.28,particular variable
290.0,4.96,the measures of spread are standard
291.68,5.2,deviation variance and quartiles
294.96,4.4,the measure of spread are also called
296.88,4.8,measures of dispersion
299.36,4.32,position identifies the exact location
301.68,3.2,of a particular data value in the given
303.68,3.6,data set
304.88,4.879,the measures of position are percentiles
307.28,5.28,quartiles and standard scores
309.759,5.041,statistical analysis system or sas
312.56,4.079,provides a list of procedures to perform
314.8,3.6,descriptive statistics
316.639,3.041,they are as follows
318.4,2.72,proc print
319.68,2.72,proc contents
321.12,4.4,proc means
322.4,5.12,proc frequency proc univariate
325.52,3.76,proc g chart
327.52,3.76,proc box plot
329.28,3.28,proc g plot
331.28,3.28,proc print
332.56,3.84,it prints all the variables in a sas
334.56,4.56,data set
336.4,4.96,proc contents it describes the structure
339.12,3.519,of a data set
341.36,3.679,proc means
342.639,4.241,it provides data summarization tools to
345.039,4.16,compute descriptive statistics for
346.88,5.84,variables across all observations and
349.199,5.041,within the groups of observations
352.72,4.479,proc frequency
354.24,5.12,it produces one way to inway frequency
357.199,4.481,and cross tabulation tables
359.36,5.2,frequencies can also be an output of a
361.68,2.88,sas data set
364.96,4.4,proc univariate
366.56,4.72,it goes beyond what proc means does and
369.36,3.92,is useful in conducting some basic
371.28,4.88,statistical analyses and includes high
373.28,4.56,resolution graphical features
376.16,4.08,proc g chart
377.84,5.04,the g chart procedure produces six types
380.24,4.239,of charts block charts horizontal
382.88,4.8,vertical bar charts
384.479,5.201,pi doughnut charts and star charts
387.68,4.4,these charts graphically represent the
389.68,4.639,value of a statistic calculated for one
392.08,3.2,or more variables in an input sas data
394.319,2.72,set
395.28,5.039,the tread variables can be either
397.039,3.28,numeric or character
400.4,4.079,proc box plot
402.0,4.24,the box plot procedure creates side by
404.479,4.081,side box and whisker plots of
406.24,5.04,measurements organized in groups
408.56,4.8,a box and whisker plot displays the mean
411.28,5.039,quartiles and minimum and maximum
413.36,4.64,observations for a group
416.319,3.921,proc g-plot
418.0,4.88,g-plot procedure creates two-dimensional
420.24,4.959,graphs including simple scatter plots
422.88,4.4,overlay plots in which multiple sets of
425.199,3.041,data points are displayed on one set of
427.28,3.44,axes
428.24,5.76,plots against the second vertical axis
430.72,5.44,bubble plots and logarithmic plots
434.0,4.319,in this demo you'll learn how to use
436.16,4.72,descriptive statistics to analyze the
438.319,4.481,mean from the electronic data set
440.88,4.08,let's import the electronic data set
442.8,5.0,into the sas console
444.96,5.76,in the left plane right-click the
447.8,5.16,electronic.xlsx dataset and click import
450.72,4.24,data
452.96,3.359,the code to import the data generates
454.96,3.359,automatically
456.319,5.0,copy the code and paste it in the new
458.319,3.0,window
466.16,4.4,the proc means procedure is used to
468.479,4.241,analyze the mean of the imported data
470.56,2.16,set
474.08,3.519,the keyword data identifies the input
476.4,3.76,data set
477.599,5.28,in this demo the input data set is
480.16,2.719,electronic
483.28,4.24,the output obtained is shown on the
485.199,2.321,screen
487.919,4.72,note that the number of observations
489.919,4.641,mean standard deviation and maximum and
492.639,4.881,minimum values of the electronic data
494.56,5.12,set are obtained
497.52,4.32,this concludes the demo on how to use
499.68,4.48,descriptive statistics to analyze the
501.84,4.639,mean from the electronic data set
504.16,3.599,so far you've learned about descriptive
506.479,2.881,statistics
507.759,3.201,let's now learn about inferential
509.36,3.84,statistics
510.96,4.4,hypothesis testing is an inferential
513.2,3.759,statistical technique to determine
515.36,3.76,whether there is enough evidence in a
516.959,4.08,data sample to infer that a certain
519.12,3.2,condition holds true for the entire
521.039,3.12,population
522.32,4.16,to understand the characteristics of the
524.159,4.401,general population we take a random
526.48,3.12,sample and analyze the properties of the
528.56,2.719,sample
529.6,3.44,we then test whether or not the
531.279,4.321,identified conclusions correctly
533.04,5.04,represent the population as a whole
535.6,4.08,the population of hypothesis testing is
538.08,3.6,to choose between two competing
539.68,4.24,hypotheses about the value of a
541.68,3.44,population parameter
543.92,3.2,for example
545.12,4.399,one hypothesis might claim that the
547.12,4.08,wages of men and women are equal while
549.519,3.921,the other might claim that women make
551.2,4.4,more than men
553.44,4.399,hypothesis testing is formulated in
555.6,6.239,terms of two hypotheses
557.839,6.0,null hypothesis which is referred to as
561.839,4.161,alternative hypothesis which is referred
563.839,4.161,to as h1
566.0,4.24,the null hypothesis is assumed to be
568.0,3.68,true unless there is strong evidence to
570.24,3.36,the contrary
571.68,4.08,the alternative hypothesis is assumed to
573.6,3.919,be true when the null hypothesis is
575.76,4.0,proven false
577.519,4.401,let's understand the null hypothesis and
579.76,3.68,alternative hypothesis using a general
581.92,3.76,example
583.44,4.8,null hypothesis attempts to show that no
585.68,5.12,variation exists between variables and
588.24,4.24,alternative hypothesis is any hypothesis
590.8,4.32,other than the null
592.48,4.479,for example say a pharmaceutical company
595.12,4.0,has introduced a medicine in the market
596.959,4.081,for a particular disease and people have
599.12,4.24,been using it for a considerable period
601.04,3.359,of time and it's generally considered
603.36,3.52,safe
604.399,4.081,if the medicine is proved to be safe
606.88,3.2,then it is referred to as null
608.48,4.08,hypothesis
610.08,4.879,to reject null hypothesis we should
612.56,5.12,prove that the medicine is unsafe
614.959,5.921,if the null hypothesis is rejected then
617.68,5.76,the alternative hypothesis is used
620.88,4.8,before you perform any statistical tests
623.44,4.16,with variables it's significant to
625.68,3.04,recognize the nature of the variables
627.6,3.2,involved
628.72,5.2,based on the nature of the variables
630.8,5.039,it's classified into four types
633.92,4.56,they are categorical or nominal
635.839,6.481,variables ordinal variables
638.48,5.84,interval variables and ratio variables
642.32,4.0,nominal variables are ones which have
644.32,4.16,two or more categories and it's
646.32,4.24,impossible to order the values
648.48,4.4,examples of nominal variables include
650.56,4.64,gender and blood group
652.88,4.72,ordinal variables have values ordered
655.2,5.199,logically however the relative distance
657.6,4.96,between two data values is not clear
660.399,4.481,examples of ordinal variables include
662.56,4.8,considering the size of a coffee cup
664.88,5.36,large medium and small and considering
667.36,4.32,the ratings of a product bad good and
670.24,3.12,best
671.68,4.08,interval variables are similar to
673.36,4.0,ordinal variables except that the values
675.76,3.519,are measured in a way where their
677.36,4.4,differences are meaningful
679.279,4.56,with an interval scale equal differences
681.76,3.759,between scale values do have equal
683.839,3.601,quantitative meaning
685.519,4.0,for this reason an interval scale
687.44,3.92,provides more quantitative information
689.519,3.841,than the ordinal scale
691.36,4.56,the interval scale does not have a true
693.36,5.2,zero point a true zero point means that
695.92,4.919,a value of zero on the scale represents
698.56,5.12,zero quantity of the construct being
700.839,4.841,assessed examples of interval variables
703.68,4.32,include the fahrenheit scale used to
705.68,5.36,measure temperature and distance between
708.0,4.959,two compartments in a train
711.04,4.32,ratio scales are similar to interval
712.959,4.641,scales in that equal differences between
715.36,3.2,scale values have equal quantitative
717.6,3.44,meaning
718.56,4.64,however ratio scales also have a true
721.04,3.2,zero point which give them an additional
723.2,3.36,property
724.24,4.48,for example the system of inches used
726.56,5.279,with a common ruler is an example of a
728.72,5.119,ratio scale there is a true zero point
731.839,5.44,because zero inches does in fact
733.839,5.761,indicate a complete absence of length
737.279,5.56,in this demo you'll learn how to perform
739.6,6.64,the hypothesis testing using
742.839,5.401,sas this example let's check against the
746.24,4.159,length of certain observations from a
748.24,4.719,random sample
750.399,5.12,the keyword data identifies the input
752.959,2.56,data set
755.6,4.64,the input statement is used to declare
757.92,6.039,the aging variable and cards to read
760.24,3.719,data into sas
774.48,5.039,let's perform a t-test to check the null
776.8,2.719,hypothesis
784.32,4.639,let's assume that the null hypothesis to
786.639,5.601,be that the mean days to deliver a
788.959,3.281,product is six days
793.12,5.44,so null hypothesis equals six
796.16,5.28,alpha value is the probability of making
798.56,7.24,an error which is 5 percent standard and
801.44,4.36,hence alpha equals 0.05
806.48,6.2,the variable statement names the
808.32,4.36,variable to be used in the analysis
821.44,4.0,the output is shown on the screen
825.839,6.081,note that the p-value is greater than
827.76,8.319,the alpha value which is 0.05 therefore
831.92,4.159,we fail to reject the null hypothesis
836.88,6.0,this concludes the demo on how to
838.639,6.401,perform the hypothesis testing using sas
842.88,3.28,let's now learn about hypothesis testing
845.04,2.88,procedures
846.16,3.2,there are two types of hypothesis
847.92,3.359,testing procedures
849.36,4.24,they are parametric tests and
851.279,4.641,non-parametric tests
853.6,4.96,in statistical inference or hypothesis
855.92,5.599,testing the traditional tests such as
858.56,4.0,t-test and anova are called parametric
861.519,3.201,tests
862.56,4.719,they depend on the specification of a
864.72,4.4,probability distribution except for a
867.279,3.281,set of free parameters
869.12,3.36,in simple words
870.56,4.0,you can say that if the population
872.48,4.719,information is known completely by its
874.56,3.76,parameter then it is called a parametric
877.199,2.88,test
878.32,4.0,if the population or parameter
880.079,4.56,information is not known and you are
882.32,4.639,still required to test the hypothesis of
884.639,4.481,the population then it's called a
886.959,4.721,non-parametric test
889.12,4.88,non-parametric tests do not require any
891.68,4.719,strict distributional assumptions
894.0,3.76,there are various parametric tests they
896.399,2.481,are as follows
897.76,2.48,t-test
898.88,2.639,anova
900.24,3.039,chi squared
901.519,4.32,linear regression
903.279,4.081,let's understand them in detail
905.839,4.081,t-test
907.36,4.24,a t-test determines if two sets of data
909.92,2.56,are significantly different from each
911.6,2.96,other
912.48,3.919,the t-test is used in the following
914.56,4.0,situations
916.399,5.041,to test if the mean is significantly
918.56,5.04,different than a hypothesized value
921.44,5.12,to test if the mean for two independent
923.6,5.2,groups is significantly different to
926.56,6.399,test if the mean for two dependent or
928.8,5.52,paired groups is significantly different
932.959,3.12,for example
934.32,3.519,let's say you have to find out which
936.079,3.44,region spends the highest amount of
937.839,4.0,money on shopping
939.519,4.081,it's impractical to ask everyone in the
941.839,3.521,different regions about their shopping
943.6,3.919,expenditure
945.36,3.839,in this case you can calculate the
947.519,3.76,highest shopping expenditure by
949.199,3.281,collecting sample observations from each
951.279,3.441,region
952.48,3.599,with the help of the t-test you can
954.72,3.76,check if the difference between the
956.079,4.641,regions are significant or a statistical
958.48,3.76,fluke
960.72,3.76,anova
962.24,4.56,anova is a generalized version of the
964.48,4.4,t-test and used when the mean of the
966.8,4.88,interval dependent variable is different
968.88,4.879,to the categorical independent variable
971.68,4.48,when we want to check variance between
973.759,4.64,two or more groups we apply the anova
976.16,2.239,test
978.48,4.479,for example let's look at the same
980.56,4.56,example of the t-test example
982.959,4.081,now you want to check how much people in
985.12,2.88,various regions spend every month on
987.04,3.359,shopping
988.0,4.399,in this case there are four groups
990.399,3.601,namely east west
992.399,3.921,north and south
994.0,3.759,with the help of the anova test you can
996.32,3.84,check if the difference between the
997.759,4.64,regions is significant or a statistical
1000.16,4.16,fluke
1002.399,4.321,chi-square
1004.32,4.319,chi-square is a statistical test used to
1006.72,4.16,compare observed data with data you
1008.639,4.401,would expect to obtain according to a
1010.88,4.079,specific hypothesis
1013.04,3.599,let's understand the chi-square test
1014.959,3.841,through an example
1016.639,3.601,you have a data set of male shoppers and
1018.8,3.36,female shoppers
1020.24,4.0,let's say you need to assess whether the
1022.16,4.879,probability of females purchasing items
1024.24,5.12,of 500 or more is significantly
1027.039,5.681,different from the probability of males
1029.36,5.28,purchasing items of 500 or more
1032.72,4.56,linear regression
1034.64,4.96,there are two types of linear regression
1037.28,4.159,simple linear regression and multiple
1039.6,3.92,linear regression
1041.439,4.321,simple linear regression is used when
1043.52,4.48,one wants to test how well a variable
1045.76,4.56,predicts another variable
1048.0,4.72,multiple linear regression allows one to
1050.32,4.8,test how well multiple variables or
1052.72,3.52,independent variables predict a variable
1055.12,3.84,of interest
1056.24,4.799,when using multiple linear regression we
1058.96,5.04,additionally assume the predictor
1061.039,5.441,variables are independent
1064.0,5.28,for example finding relationship between
1066.48,5.68,any two variables say sales and profit
1069.28,4.72,is called simple linear regression
1072.16,4.96,finding relationship between any three
1074.0,5.76,variables say sales cost telemarketing
1077.12,4.64,is called multiple linear regression
1079.76,4.279,some of the non-parametric tests are
1081.76,4.799,wilcoxon rank sum test and
1084.039,4.76,kruskal-wallis h-test
1086.559,4.961,wilcoxon rank sum test
1088.799,4.88,the wilcoxon signed rank test is a
1091.52,4.72,non-parametric statistical hypothesis
1093.679,5.041,test used to compare two related samples
1096.24,5.28,or matched samples to assess whether or
1098.72,5.6,not their population mean ranks differ
1101.52,5.12,in wilcoxon rank some test you can test
1104.32,4.4,the null hypothesis on the basis of the
1106.64,4.48,ranks of the observations
1108.72,5.04,kruskal-wallis h-test
1111.12,5.12,kruskal-wallis h-test is a rank-based
1113.76,4.48,non-parametric test used to compare
1116.24,3.92,independent samples of equal or
1118.24,3.92,different sample sizes
1120.16,4.24,in this test you can test the null
1122.16,4.24,hypothesis on the basis of the ranks of
1124.4,4.08,the independent samples
1126.4,3.519,the advantages of parametric tests are
1128.48,4.0,as follows
1129.919,4.561,provide information about the population
1132.48,3.68,in terms of parameters and confidence
1134.48,4.079,intervals
1136.16,4.16,easier to use in modeling analyzing and
1138.559,5.281,for describing data with central
1140.32,5.84,tendencies and data transformations
1143.84,4.32,express the relationship between two or
1146.16,3.92,more variables
1148.16,4.16,don't need to convert data into rank
1150.08,4.56,order to test
1152.32,4.16,the disadvantages of parametric tests
1154.64,5.12,are as follows
1156.48,7.36,only support normally distributed data
1159.76,6.159,only applicable on variables not
1163.84,5.04,let's now list the advantages and
1165.919,5.201,disadvantages of non-parametric tests
1168.88,3.84,the advantages of non-parametric tests
1171.12,4.4,are as follows
1172.72,5.04,simple and easy to understand
1175.52,4.159,do not involve population parameters and
1177.76,4.159,a sampling theory
1179.679,4.321,make fewer assumptions
1181.919,3.681,provide results similar to parametric
1184.0,4.0,procedures
1185.6,4.72,the disadvantages of non-parametric
1188.0,5.28,tests are as follows
1190.32,5.28,not as efficient as parametric tests
1193.28,5.36,difficult to perform operations on large
1195.6,3.04,samples manually
1201.52,4.08,hey want to become an expert in big data
1204.08,3.44,then subscribe to the simply learn
1205.6,4.16,channel and click here to watch more
1207.52,6.519,such videos to nerd up and get certified
1209.76,4.279,in big data click here
