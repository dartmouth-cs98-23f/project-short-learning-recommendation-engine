second,duration,transcript
0.0,2.48,being good at data structures and
1.12,3.199,algorithms is a computer science
2.48,3.76,equivalent of having
4.319,3.201,i mean everyone assumes you're a genius
6.24,2.399,you get high paying offers from
7.52,2.8,prestigious companies
8.639,3.521,and you even have a high social market
10.32,3.84,value on internet forums but the journey
12.16,2.559,from lead cell to algo chat is not an
14.16,1.84,easy one
14.719,3.281,it's filled with frustration and
16.0,4.08,imposter syndrome i know i've been there
18.0,4.16,but now i have offers from feng which
20.08,3.92,basically qualifies me to cure cancer
22.16,3.52,so to give back and help even the most
24.0,3.84,confusing programmers
25.68,4.56,consider this video my cure since this
27.84,9.83,industry is cancer
30.24,7.43,[Music]
38.879,3.041,the most important part of learning
40.16,2.559,something new is that you actually want
41.92,2.799,to learn it
42.719,3.121,this is why i failed out of spanish one
44.719,2.721,so before we start
45.84,3.76,ask yourself why do you want to learn
47.44,4.0,this don't do it to get a job at google
49.6,3.279,do it because learning this changes the
51.44,2.08,way you think data structures and
52.879,2.721,algorithms
53.52,3.519,is about solving problems efficiently a
55.6,2.88,bad programmer solves the problem
57.039,3.2,inefficiently and a
58.48,3.44,really bad programmer doesn't even know
60.239,2.561,why their solution is inefficient so
61.92,3.01,let's start with that
62.8,3.92,how do we rank an algorithm's efficiency
64.93,3.229,[Music]
66.72,3.04,say we wrote a function that goes
68.159,3.361,through every number in a list and adds
69.76,2.24,it to a total sum variable if you
71.52,2.4,consider
72.0,3.68,adding to be one operation then running
73.92,4.0,this function on a list with 10 numbers
75.68,4.56,costs 10 operations running it on a list
77.92,3.839,with 20 numbers costs 20 operations
80.24,3.28,say we wrote another function that just
81.759,3.601,returns the first number in a list then
83.52,3.52,no matter how large the list is this
85.36,2.32,function will never cost more than one
87.04,2.16,operation
87.68,3.2,clearly these two algorithms have a
89.2,3.2,different time complexity or
90.88,3.12,relationship between growth of input
92.4,3.039,size and growth of operations we
94.0,2.079,communicate these time complexities
95.439,3.36,using big
96.079,4.161,o notation referring to input size as n
98.799,4.721,common complexities are
100.24,6.879,constant linear quadratic
103.52,5.84,logarithmic n log n exponential
107.119,3.04,and factorial our first algorithm runs
109.36,2.88,in o of n
110.159,3.841,meaning its operations grow in a linear
112.24,3.44,relationship with the input size which
114.0,3.28,in this case is the amount of numbers in
115.68,3.36,the list our second algorithm
117.28,3.68,is not dependent on the input size at
119.04,3.52,all so it runs in constant time let's
120.96,2.96,take a look at how many operations a
122.56,3.919,program will have to execute in a
123.92,4.72,function with an input size of 5
126.479,4.081,versus 50. it might not matter when the
128.64,4.08,input is small but this gap gets very
130.56,2.96,dramatic as the input size increases if
132.72,2.72,n were 10
133.52,3.76,000 a function that runs in log of n
135.44,3.6,would only take 14 operations while the
137.28,3.92,function that runs in n factorial
139.04,4.16,would set your computer on fire for big
141.2,5.28,o notation we drop constants so
143.2,5.039,o of 10 times n and o of n over 10 are
146.48,3.759,both equivalent to o of n because the
148.239,4.0,graph is still linear and bagel notation
150.239,4.0,is also used for space complexity which
152.239,4.401,works the same way for how much space an
154.239,3.761,algorithm uses as n grows
156.64,3.04,unless you sit in your room doing
158.0,3.28,algorithms all day there's a good chance
159.68,2.96,you forgot what logarithms are
161.28,3.599,logarithms are the inverse to
162.64,4.0,exponential functions let's say i wanted
164.879,4.08,to find a word in a dictionary
166.64,3.28,one method is to check every word one by
168.959,3.681,one this is o
169.92,3.52,n but nobody does that so how are humans
172.64,3.04,able to find
173.44,4.079,any word in a dictionary with a hundred
175.68,3.68,thousand words in seconds we do
177.519,3.681,something more along method two
179.36,3.44,cut the search window in half each time
181.2,3.52,by checking the middle element
182.8,3.84,if we passed our word search on the left
184.72,3.36,half otherwise search on the right half
186.64,1.92,and then we repeat this until we find
188.08,2.72,our word
188.56,4.72,if our input n doubled in size that
190.8,4.719,would only grow our operations by one
193.28,4.319,in computer science this is the binary
195.519,3.921,search but for the binary search to work
197.599,3.521,the collection has to be sorted which
199.44,2.24,opens up a huge field of computer
201.12,2.96,science
201.68,4.08,sorting algorithms a very basic sort is
204.08,2.96,a selection sort you have one pointer at
205.76,3.039,the start of the list and another
207.04,2.96,pointer that is linear scan to find the
208.799,2.481,next minimum element
210.0,2.799,then you swap those elements and
211.28,3.36,increment the pointer since you're doing
212.799,2.401,a linear scan for every element in the
214.64,2.56,collection
215.2,4.16,this runs in all of n squared a more
217.2,3.679,efficient algorithm is the merge sort a
219.36,3.36,merged source splits a collection in
220.879,3.36,half into sub-collections until those
222.72,3.28,sub-collections can be sorted in
224.239,3.761,constant time and then it works its way
226.0,3.76,back up by merging sorted subcollections
228.0,3.36,until the entire collection is sorted
229.76,3.6,since it's splitting in half there will
231.36,4.799,be log n splits and thereby
233.36,4.4,log n merges it is o then to merge two
236.159,2.16,sorted collections into one sorted
237.76,2.399,collection
238.319,3.041,since we're doing that log n times the
240.159,4.321,time complexity is of
241.36,4.799,n times log n no algorithm can sort an
244.48,3.6,arbitrary collection in a better time
246.159,4.961,complexity than that so we consider
248.08,4.48,n log n to be the cost of sorting
251.12,3.199,perhaps the most fundamental data
252.56,3.679,structure is an array an array is an
254.319,3.92,indexable contiguous chunk of memory
256.239,3.761,arrays are fixed size you can't insert a
258.239,3.28,ninth element into an array meant for
260.0,3.52,eight elements a list data structure
261.519,3.68,with a flexible size is a linked list
263.52,3.119,the idea is to package your data into
265.199,3.841,nodes that hold one
266.639,3.201,your data and two a point that points to
269.04,2.4,the next node
269.84,3.12,traversing a linked list reminds me of
271.44,3.6,those youtube direction chains
272.96,3.04,like you see a comment that says read my
275.04,3.04,profile picture
276.0,3.759,and their profile picture says click on
278.08,2.8,my profile which brings you to their
279.759,3.281,header which says
280.88,4.0,read my bio so you go to their bio and
283.04,3.439,it says click the link below and you
284.88,3.759,click it and then it installs a virus
286.479,4.081,onto your browser
288.639,3.681,if a note's next pointer points to null
290.56,3.52,it's the end of the list you can add a
292.32,3.2,new node to the list in constant time by
294.08,1.92,just setting that pointer to the new
295.52,2.08,node
296.0,3.44,by doing additional tom [ __ ] with
297.6,3.039,pointers we can also insert and delete
299.44,3.039,nodes in constant time
300.639,3.441,sometimes nodes also contain a pointer
302.479,3.041,to the previous node in a variation
304.08,3.04,called the doubly linked list but a
305.52,2.16,major downside of linked list is that
307.12,2.639,you can't
307.68,4.0,access elements in constant time via
309.759,3.601,index like an array in practice both
311.68,3.519,programming languages have dynamically
313.36,3.76,sized arrays or lists which work by
315.199,3.681,creating arrays with a fixed size
317.12,3.04,if the array is full capacity and you
318.88,2.96,try to add a new element
320.16,3.12,the programming language automatically
321.84,2.24,creates a new array with double the
323.28,2.479,capacity
324.08,3.36,copies the current elements over and
325.759,3.921,sets your pointer to that new array
327.44,4.0,since this happens so infrequently we
329.68,4.72,generally consider appending to a list
331.44,4.16,to be a constant time operation
334.4,2.639,link lists aren't the only data
335.6,2.8,structure that include nodes referring
337.039,3.44,to other nodes what if instead of
338.4,4.0,pointing to a next node nodes pointed to
340.479,3.28,a left and a right child node this is
342.4,2.88,called a binary tree
343.759,3.28,these child notes can also be called
345.28,2.24,subtrees since trees are recursive in
347.039,2.16,nature
347.52,3.28,a node with no children is called a leaf
349.199,1.921,node while a node with seven children is
350.8,2.48,my
351.12,4.0,father-in-law a common type of tree is
353.28,2.639,the binary search tree which follows
355.12,2.48,these rules
355.919,3.361,basically a node's left child must have
357.6,4.879,a smaller value while a node's right
359.28,4.88,child must have a greater or equal value
362.479,3.28,let's say you're looking for element x
364.16,3.2,you start at the root and if the number
365.759,3.521,is smaller than the root you go to the
367.36,3.6,left tree if it's larger you go to the
369.28,2.72,right and you keep repeating this until
370.96,2.72,you arrive at your number
372.0,3.199,in the worst case you have to traverse
373.68,2.799,the height of the tree so the time
375.199,4.0,complexity to search
376.479,3.521,insert and delete elements is of h where
379.199,2.72,h is the height
380.0,3.199,this is efficient because on average the
381.919,3.201,height will be log n
383.199,4.321,but what if you inserted every element
385.12,3.199,of a sorted array into an empty binary
387.52,3.6,search tree
388.319,3.6,well that's a linked list meaning the
391.12,3.28,height would be
391.919,4.4,n but we can guarantee log n time
394.4,3.84,complexities using a self-balancing
396.319,2.961,binary search tree such as red black
398.24,2.88,trees which maintain
399.28,4.0,additional properties to guarantee that
401.12,3.44,the height of the tree is o of log n
403.28,2.56,binary search trees are kind of
404.56,2.639,considered to be a workhorse
405.84,3.12,distribution that can solve most
407.199,3.521,problems with decent efficiency but i
408.96,2.239,found situations where binary search
410.72,3.12,trees
411.199,5.601,really shine are when you're asked a
413.84,5.199,question about binary search trees
416.8,3.76,another type of tree is a heap the
419.039,3.041,primary difference between this and the
420.56,3.039,binary search tree is
422.08,2.88,actually use this one it's also
423.599,2.961,sometimes called a priority queue
424.96,3.04,because at the root of it is always the
426.56,3.039,highest priority element
428.0,3.039,and min heap will have the min element
429.599,2.961,and the max heap will have the max
431.039,3.761,element at the root but don't get me
432.56,4.32,wrong the rest of the heap is unsorted
434.8,3.519,it is an absolute wasteland down there
436.88,3.92,searching in the rest of the heap
438.319,4.801,may as well be an unsorted array we only
440.8,4.399,care about what's at the top
443.12,3.199,just like capitalism to insert a new
445.199,2.961,element into a heap
446.319,3.361,first we find the next available spot to
448.16,2.72,add a leaf node then we compare it with
449.68,3.28,his parents and if it's a higher
450.88,3.28,priority it swaps and bubbles his way up
452.96,3.519,we're doing at most
454.16,4.319,log n comparisons you can build a heap
456.479,3.041,from a random collection by inserting n
458.479,3.28,times which cost
459.52,3.84,o of n log n but there's also a way to
461.759,3.601,build a heap in o of end time
463.36,3.839,i'd suggest reading this wikipedia page
465.36,2.399,because it's super interesting stuff and
467.199,2.081,lastly
467.759,3.28,since the heap is nearly complete
469.28,3.199,although we can visualize it as a tree
471.039,2.801,we could actually use these properties
472.479,4.641,to represent it with an
473.84,4.24,array one way to traverse a tree is a
477.12,3.44,depth first search
478.08,4.399,which is like going deep fully exploring
480.56,3.84,one path and then moving on to the next
482.479,3.921,one way to visit this tree in a depth
484.4,5.28,first order could be to start at 10
486.4,5.84,go to 13 go to 4 then 6 then 12
489.68,4.4,then 8 and then 1 whereas another option
492.24,2.32,is a breadth first search where we view
494.08,2.72,it more
494.56,4.24,level by level a way to print this same
496.8,5.36,tree in a bfs manner could be
498.8,5.679,10 13 12 4 6
502.16,4.159,8 1. when it comes to implementation
504.479,3.601,depth first search can use a stack a
506.319,3.28,stack is a list-based data structure
508.08,3.92,where the only two operations
509.599,3.36,are add to the end and pop from the end
512.0,4.0,this makes a stack
512.959,4.401,lifo last in first out dfs are often
516.0,3.519,done using recursion
517.36,3.919,which indirectly uses a stack the
519.519,3.76,recursive stack so if your recursion
521.279,3.841,exceeds a certain amount of depth then
523.279,3.761,you get a stack overflow let's look at a
525.12,3.68,way to print this tree in a dfs matter
527.04,3.12,using a stack so first initialize the
528.8,3.36,stack and add the root
530.16,4.16,then while there are still elements in
532.16,4.08,the stack pop from the stack print that
534.32,4.16,element and then add its children to the
536.24,3.599,stack on the contrary a breadth first
538.48,4.56,search uses a queue
539.839,5.041,a queue is fifo first in first out so
543.04,2.32,instead of popping from the end of the
544.88,2.16,list
545.36,3.44,you pop from the beginning doing the
547.04,3.84,same algorithm as before but
548.8,3.52,using a q instead of a stack the tree
550.88,6.079,will now print in a bfs
552.32,6.56,order all trees are graphs but not all
556.959,3.761,graphs are trees a graph is a collection
558.88,3.519,of vertices which are like points
560.72,3.52,and edges which are like connections
562.399,3.681,from one vertex to another vertex a
564.24,2.88,graph can be directed meaning edges can
566.08,2.879,only go one way
567.12,4.08,so this edge means you can only go from
568.959,3.761,a to b or undirected meaning you can
571.2,3.6,also go from b to a
572.72,4.559,two common ways to model edges are
574.8,3.76,adjacency lists and adjacency matrices
577.279,3.041,graphs are my favorite part of
578.56,3.279,destruction algorithms so i'd like to
580.32,3.28,show how cool they are with three
581.839,3.44,example scenarios on where you can use
583.6,3.76,them
585.279,3.281,so it recently dawned on me that i know
587.36,3.52,kanye west
588.56,4.48,and by that i mean i know joma tech but
590.88,4.399,joma tech knows jarvis johnson who knows
593.04,4.16,mkbhd who knows elon musk
595.279,3.601,who knows kanye west which is five
597.2,3.44,degrees of separation between me and
598.88,2.24,kanye west i wanted to find something
600.64,2.72,shorter
601.12,4.24,well turns out i know bretman rock who
603.36,3.12,knows rihanna who knows kanye three
605.36,3.2,degrees of separation
606.48,3.2,which also means that anyone who knows
608.56,2.56,me is at most
609.68,3.2,four degrees of separation away from
611.12,3.279,kanye if we wanted to make a program
612.88,3.199,that computes the smallest degrees of
614.399,3.601,separation between two people
616.079,4.081,a graph would be the perfect choice you
618.0,4.56,model people as vertices and you model
620.16,3.679,relationships as edges the shortest path
622.56,3.6,between the source node
623.839,3.841,me and the target node kanye can be
626.16,3.359,found with a breath first search
627.68,3.599,since we're moving out level by level we
629.519,3.681,can guarantee that the first time
631.279,2.8,reaching the kanye node will also be the
633.2,2.079,shortest path
634.079,2.88,the problem with implementing this
635.279,2.0,algorithm the way i just described is
636.959,2.32,that
637.279,3.841,nobody has a concrete list of all the
639.279,4.081,people they know nor would that be
641.12,4.08,publicly accessible by me but a possible
643.36,3.44,variation could be in a social network
645.2,2.879,like facebook where we can use the
646.8,2.479,friend list as edges
648.079,3.041,we would then be able to run this
649.279,2.961,algorithm and find the smallest degrees
651.12,4.56,of separation between
652.24,5.2,any two users in that social network
655.68,3.2,imagine a map system like google maps
657.44,2.72,that wants to find the shortest path
658.88,2.959,between two locations
660.16,2.88,this is different than the last example
661.839,2.321,because although they both deal with
663.04,2.4,shortest paths the degrees of
664.16,3.359,separations did not have
665.44,3.44,weighted edges where a map system does
667.519,3.121,for example if we're computing the
668.88,3.199,shortest path between two vertices and
670.64,3.52,there's a direct edge between them
672.079,2.801,weighing 20 versus a path of two edges
674.16,2.48,weighing eight
674.88,3.04,each a breath first search would give us
676.64,3.12,the shortest path in terms of the
677.92,3.52,vertices away but not the smallest
679.76,3.199,weight one algorithm that computes the
681.44,3.44,shortest path in a graph with positive
682.959,3.601,weighted edges is dijkstra's algorithm
684.88,3.12,using the heap data structure in the
686.56,3.36,original version of this video
688.0,4.32,i explained dijkstra's and my video shot
689.92,4.56,up 6 minutes so instead just research it
692.32,3.68,for yourself if you're interested
694.48,3.28,but graphs aren't just good for path
696.0,2.8,finding imagine a course schedule in
697.76,2.88,school with classes
698.8,3.44,and prerequisites for each class and say
700.64,3.04,you wanted to find the order in which
702.24,3.039,you can take all your classes while
703.68,3.36,still fulfilling your prerequisites well
705.279,3.761,model the classes as vertices and
707.04,4.0,prerequisites as edges count how many
709.04,3.84,incoming edge each vertex has add
711.04,3.28,vertices with zero incoming edges to a
712.88,2.639,queue then pop and print the element
714.32,3.04,from the queue and decrement the
715.519,3.921,incoming edges of all its children
717.36,3.599,if a child now has zero incoming edges
719.44,3.12,add it to the cube and repeat while
720.959,3.761,there are still elements in the queue
722.56,2.58,this algorithm is known as a topological
724.72,2.32,sort
725.14,3.74,[Music]
727.04,3.76,hash maps are sort of the holy grail of
728.88,3.199,data structures with basically constant
730.8,2.719,time retrieval of data
732.079,2.961,the saying goes that if you don't know
733.519,2.641,what you're doing just try throwing
735.04,2.88,hashtags at the question
736.16,3.2,as an example one time i was in a coding
737.92,4.08,interview and froze so
739.36,4.479,i just told the interviewer hmm i think
742.0,3.92,the solution to use a hash map
743.839,3.281,unfortunately the question was what are
745.92,2.719,your biggest weaknesses
747.12,3.44,so the better answer was hang up the
748.639,3.361,phone to show that i have none a hashmap
750.56,2.8,is a data structure built on top of an
752.0,3.279,array optimized to store
753.36,4.0,key value pairs what makes it so
755.279,2.8,powerful is you can retrieve delete and
757.36,2.96,store data
758.079,3.76,in on average constant time here we have
760.32,3.44,a map where keys are strings
761.839,3.361,representing people's names and values
763.76,3.68,are their corresponding ages
765.2,4.4,we can directly access trend black's age
767.44,3.519,like this it's almost as if strings can
769.6,3.679,be used as indices
770.959,4.241,but how is that even possible because of
773.279,3.36,this little thing called a hash function
775.2,2.96,a hash function will take a key and
776.639,3.041,return a hash code if we take that
778.16,3.6,number modulus the length of its
779.68,3.76,underlying array we can use that as an
781.76,3.759,index to store its value but the hash
783.44,2.56,function has to compute the same hash
785.519,2.241,code if
786.0,3.76,given the same key so hash of trend
787.76,4.079,black should always return the same hash
789.76,4.16,code or else we lose the index but what
791.839,4.081,if hash of trend black and hash of ziz
793.92,3.12,both end with the same index well this
795.92,2.719,is called collision
797.04,3.039,one way to deal with this is to store
798.639,3.281,our value in a linked list
800.079,4.081,so when we go to stores is and see that
801.92,2.96,index three already has a value we have
804.16,2.56,that value
804.88,4.24,point to the new value this is why a
806.72,3.28,hash map is not strictly of one because
809.12,3.2,if you write some
810.0,4.0,god awful hash function then it won't be
812.32,3.68,balanced and we will have to do a lot of
814.0,3.68,linkless traversing good hash functions
816.0,3.76,evenly spread out hash codes
817.68,3.44,in practice modern languages use very
819.76,2.0,good hash functions so you don't have to
821.12,2.159,write your own
821.76,3.6,an example of a hashmap is the
823.279,3.521,dictionary in python or the object in
825.36,3.2,javascript and remember
826.8,3.2,constant lookup of data is very
828.56,1.85,overpowered so try to use it when you
830.0,2.32,can
830.41,3.51,[Music]
832.32,3.44,and that's pretty much all you need to
833.92,4.24,know for data structures and algorithms
835.76,4.079,a six month college course taught in 13
838.16,3.52,minutes now of course you didn't learn
839.839,3.761,anything in great detail but trust me it
841.68,3.76,is a lot easier to learn something in
843.6,3.12,great detail if you already learned the
845.44,3.12,big picture first
846.72,4.0,this is why college sucks at teaching it
848.56,3.279,dives very deep into one topic and then
850.72,3.28,moves on to the next
851.839,3.841,it's like a depth first search i believe
854.0,3.519,the better way of learning is to get a
855.68,2.159,general understanding and then build on
857.519,2.161,it
857.839,3.041,like a breath first search so if you
859.68,2.399,want to keep going what are my
860.88,2.56,recommendations to build on your
862.079,3.44,knowledge well the first one
863.44,4.8,is jomo class you know those really nice
865.519,4.721,animations in this video like this one
868.24,3.68,yeah i got them from joma class if you
870.24,3.36,don't care about getting extremely
871.92,3.599,theoretical and just want simple
873.6,3.919,to the point everything you need to know
875.519,3.921,and nothing you don't type lessons then
877.519,4.401,jomo class makes this difficult topic
879.44,3.44,very accessible but i will admit that i
881.92,3.039,roasted the
882.88,3.12,[ __ ] out of jomah a while back because
884.959,3.68,he was pushing some
886.0,4.959,actual snake oil well unlike some people
888.639,3.361,he took my criticism very well and to
890.959,3.12,vindicate his name
892.0,3.839,he made something that is actually
894.079,3.681,valuable and i will defend that
895.839,3.921,he put much more effort into these
897.76,3.759,explanations dropped the price from a
899.76,3.68,thousand dollars to eight dollars a
901.519,3.68,month and most importantly he dropped
903.44,3.28,the
905.199,3.361,dead weight if you're a complete
906.72,3.919,beginner it also comes with a course on
908.56,3.92,how to code in python and of course on
910.639,3.76,sql if you're a bit more advanced but i
912.48,2.4,gotta say the best part is the community
914.399,2.56,aspect
914.88,3.68,each lesson has a whole community behind
916.959,3.761,it where people ask questions
918.56,4.399,discuss topics and just learn together
920.72,3.84,well i like the course so much that i
922.959,4.721,actually called joma
924.56,4.719,and i was like yo what the [ __ ] dude
927.68,2.959,this is actually good i'm gonna start
929.279,3.12,recommending this to people
930.639,3.681,and he was so excited to hear that i
932.399,3.521,liked it that he was actually willing to
934.32,4.639,offer my audience a discount
935.92,5.76,so if you go to trend.jomoclass.com
938.959,4.161,then you'll get 15 off but even though
941.68,2.719,paying for stuff increases the chance
943.12,1.6,that you'll actually complete it you
944.399,2.161,don't
944.72,3.52,have to spend money not everyone has
946.56,3.519,eight dollars a month to drop and i want
948.24,2.88,to assure you that you can still learn
950.079,2.481,everything for free
951.12,3.839,so it might take a bit more
952.56,4.0,self-discipline but you can do it so
954.959,3.601,don't listen to anyone who says you
956.56,3.6,have to pay so if you do want to go down
958.56,2.56,the free route i'd recommend these
960.16,2.64,college lectures
961.12,3.839,they're literally taught by mit
962.8,3.76,professors and posted for free online
964.959,3.601,they're pretty theoretical but very
966.56,2.959,comprehensive and it's perfect if you
968.56,2.56,like that old-school
969.519,11.201,chalkboard setting so yeah good luck
971.12,9.6,guys and go get that guck 3000
