ok so now we're going to change topics
and start talking about our first
technical subject of this course and as
an introduction to computer architecture
we're going to be talking about what is
architecture versus microarchitecture
and I want to just briefly say that as
you take this class the first three
lectures or so should be review so if
you sing in the class and you're saying
oh I've seen all this before
don't get up wait to the fourth or fifth
lecture and then the content will become
new
and this is because I want to teach
everything from first principles and get
everyone up to speed but it's that those
first few lectures are going to go very
fast so if you're lost in the first
three lectures which should be reviewed
then that's probably a bad in indicator
so we'll start off by talking about
architecture versus microarchitecture
and I wanted to say briefly what I mean
by architecture and I have in this slide
here a very large a4 what I'll sometimes
call Big Eight architecture so your
Patterson has he calls this instruction
set architecture and when I contrast
this with micro architecture or paracin
hennessy calls organization so big 8
architecture is an abstraction layer
provided to software or instruction set
architectures our abstraction layer
provided to software which is designed
to not change very much and it doesn't
say it says how a theoretical
fundamental sort of machine execute
programs
it does not say exactly the size of
different structures how fast those
things will run the exact implementation
issues that falls into organization and
one of the things I wanted to emphasize
is that computer architecture is all
about trade-offs so when I say it's all
about trade-offs you can make different
design decisions up here in the big a
architecture or the instruction set
architecture
that'll influence the application it'll
influence the microarchitecture but also
you can make different design decisions
down here and make a lot of different
trade-offs on how to go about
implementing a particular instruction
set architecture and largely when you go
to look at computer architecture and
computer architecture implementation the
design space is relatively flat there's
sort of an optimum point where you you
want to be but the other points around
it are many times not horribly horribly
bad though there are you know at the at
extremes probably horribly bad design
decisions but you know a lot of
different design points are equally good
or close to the optimal and the job of
computer architect is to make the very
subtle design decisions around how do
you move around this point to make it
both easier to program lives on for many
years there's a little power and the
sort of other a little bit of aesthetic
characteristics mixed together with just
making your computer and processor go
fast we'll say and these trade-offs I
will reiterate this over and over again
in this class that because there's
multiple different metrics so for
instance speed energy cost and they
trade off against each other many times
and there is no necessarily optimal
point it depends on you know if are you
more cost driven in or energy driven or
speed driven and within that point
there's sort of sometimes Pareto optimal
curves where all the points are are
equally good if you're trying to trade
off these different things for different
cost models okay so let's let's talk
about what is a instruction set
architecture and what is a
microarchitecture so a instruction set
architecture or big a architecture is
trying to provide the programmer some
abstract machine model and many times
what it really boils down to is it's all
the programmer visible state so for
instance how does the machine have
memory doesn't have registers so that's
the that's the programmer visible state
it also encompasses the fundamental
operation
that the computer can run so these are
called instructions and it defines the
instructions and how they operate so for
instance ad ad might be a fundamental
instruction or fundamental operation in
your computer instruction set
architecture and it says the exact
semantics on how to take one word in a
register and add it to another word
register and where it ends ends up then
there's more complicated execution
semantics so what'll be my execution
semantics well if you just say ads take
two numbers and add them together and
put them in another register that many
times does not encompass all of the
instruction set architecture you'll have
other things going on
for instance IO interrupts and you have
to define in your instruction set
architecture or your big a computer
architecture what is these X semantics
of an interrupt or a instruction or a
piece of data coming in on Io how does
that interact with the rest of the
processor so many times the instruction
execution semantics is only half of it
and we have to worry about is the the
rest of the machine execution semantics
Big Eight architecture has to define how
the inputs and the outputs work and
finally we has to define the data types
and the sizes of the fundamental data
words that you operate on so for
instance do you operate on a bytes at a
time
four bytes at a time two bytes at a time
how big is a byte do you actually have
bytes so this is gets into sizes and
then data types here might mean that you
have other types of fundamental data so
for instance the most basic one is you
have just some bits sitting on on you
know in a register in your processor but
it could be much more complex so you
could have for instance something like
floating-point numbers where it's not
just a bunch of bits it's it's formatted
in a particular way and has very
specific meanings it's a floating-point
number that can range over
let's say most of the the real numbers
okay so in today's lecture we're going
to step through all these different
characteristics and requirements of
building an instruction set architecture
and I wanted to and we'll talk about how
it's different than microarchitecture or
organization so let's take out some
examples of microarchitecture and
organization
so what microarchitecture and
organization is really thinking about
here is the trade-offs as you're going
to implement a fixed instruction set
architecture so for instance something
like Intel's x86 is an instruction set
architecture and there's many different
micro architectures or implementations
there is the AMD versions of the chips
and then there's the Intel versions of
the chips and even inside of let's say
the Intel versions of the chips they
have their high performance version for
the laptop which looks one way or high
performance personal info I'd say a
server or or high-end laptop which looks
one way and there's another chip for our
tablets Intel's trying to make chips for
tablets these days and they have their
Atom processors and internally they look
very different because they have very
different speed energy cost trade-offs
but they will all execute the same code
and they all implement the same
instruction set architecture so let's
look at some examples of things that you
might trade off in a microarchitecture
so you might have different pipeline
depth numbers of pipelines so you might
have one processor pipeline or you might
have six like something like the core
i7s today cache sizes how big the chip
is the silicon area how what's your peak
power execution ordering well does the
code run in order or can you execute the
code out of order that's right
it is possible to take a sequential
program and actually execute later
portions of the program before earlier
portions of the program and that's kind
of mind-boggling but it's a way to go
about getting parallelism and if you
keep your ordering correct things things
work out
the Swift's ALU whiffs you if you have a
say a 64-bit machine you can actually go
and implement that as a bunch of one bit
adders for instance and people have done
things like that in the
microarchitecture and this allows you to
build more expensive or less expensive
versions of the same processor so let's
talk about the history of why we came up
with these two differentiations between
architecture and microarchitecture and
it came about because software sort of
pushed it on us and ended up being a
nice abstraction layer so back in the
early 50s late 40s
you had software that people mostly
programmed either in assembly language
or machine code language so yeah right
ones and zeros or you had to write
assembly code and sometime in the the
mid 50s we started to see libraries show
up so these are sort of floating point
operations were made easier we had
transcendentals as the sine cosine
libraries you had some matrix and
equation solvers and he started to see
some libraries that people who call but
people were not necessarily writing code
by themselves or any large bodies of
code in assembly programming because it
was pretty painful and then at some
point there was the invention of
higher-level languages so a good example
this was Fortran I came out in 1956 and
a lot of things came along with this we
had assemblers loaders linkers compilers
a bunch of other software to track how
your software is being used even and
because we started to see these
higher-level languages this started to
give some portability to programming it
wasn't that you had to write your
program and have it only mapped to one
Pro one processor ever and back in the
50s even 60s time frame here machines
required experienced operators
who could write the programs and you
know you you've got these machines and
they had to be sold with a lot of
software along with them so you had to
basically run only the software that was
given because it was yet to be a master
programmer or someone who worked for the
company too even that built the machine
to even build a program these machines
back in the day and the idea of
instruction set architectures and these
breaking the microarchitecture from the
architecture didn't really exist back
then and back in the early 60s IBM had
four different product lines and they
were all incompatible so you couldn't
run code that you ran on one on the
other so to give you an example here the
IBM 701 was for scientific computing the
1401 was mostly for business computation
and I think they even had a second one
that was sort of for business but
different types of business computation
and people sort of bought into a line
and then as you as the line matured and
developed they had either rewrite their
code or they had to stick into one line
but IBM had some and some crazy insights
here is that they didn't want to have to
when they went to the next generation of
processor they wouldn't want to
propagate these four lines they wanted
to try to unify the four lines but one
of the problems was these different
lines had very different implementations
and different cost points so the thing
you were building for scientific
computing wasn't necessarily the thing
you want to build for business computing
and the one that you built for business
computing let's say didn't you wanted to
not have it have very good
floating-point performance so how do how
do they go about solving this and their
solution was they came up with something
called the IBM 360 and the IBM 360 is
probably the first true instruction set
architecture that was implemented to be
an instruction set architecture and the
idea here was they wanted to unify all
of these products
into one platform but then implement
different versions that were specialized
for the different market niches so they
could build they could unify a lot of
their software systems unify a lot of
what they built but still build
different versions so let's let's take a
look at the IBM 360 instruction set
architecture and then talk about
different micro architectures that have
been built of the IBM 360 so the IBM 360
is a general purpose register machine
and we'll talk more about that later in
this lecture but to give you an idea
this is what the programmer saw or what
the software system saw this isn't what
was actually built in the hardware
because that would be a
microarchitecture constraint but the
processor state had 16 general-purpose 3
two-bit registers it had four
floating-point registers had control
flags if you will had a condition codes
and control flags and it was a 24-bit
address machine at the time that was
huge so to the 24 was a very large
number nowadays it's not so large and
they've since expanded that on the IBM
360 successors but they thought it was
good for many many years and it was good
for many many years and they defined a
bunch of different data formats so there
was 8-bit bytes 16-bit half words 32-bit
words 64-bit double words and these were
the fundamental data types that you
could work on and you can name these
different fundamental data types and it
was actually the IBM 360 that came up
with this idea that bytes should be 8
bits long and that's lived on on for
today because before that we had lots of
different choices there was binary-coded
decimal systems where the you actually
would encode a number between 0 and 9
and then you had the each digits and
this is sometimes good for sort of
spreadsheet calculations or business
calculations we want to be very
sice on your rounding to the penny and
sometimes bit based things don't
actually round appropriately oh they'll
do the you lose pennies off the end and
so you had these binary coded decimal
systems and well-nigh BM 360 they they
unified it all and said well no we're
gonna throw out certain things and make
make choices now they of course because
it's the IBM 360 and they did have
business applications they still support
it binary coded decimal in a certain way
and let's look at the microarchitecture
implementations of this first
instruction set architecture so at in
this is in the same timeframe the same
generation here there is the model 30 in
the model 70 and this was very very
different performance characteristics so
if we we look at the machine let's start
off by looking at the storage the the
low-end model here had between 8 and 64
kilobytes and the high-end model had
between 256 and 512 kilobytes so very
very different sizes and this is what
I'm trying to get across here is the
microarchitecture can actually change
quite a bit even though the architecture
supports 64-bit and ads and additions
you can actually implement different
size data paths so in the low-end
machine they had an 8 bit data path and
for one to do a 64-bit operation it had
to do eight sapin operations to make up
a 64-bit operation and probably it
actually even had to do more than that
to handle all the carries correctly
versus the high-end implementation had a
full adder there and it can actually do
a 64-bit ad by itself without having to
do lots of micro sequence operations and
oh yes with minor modifications it lives
on today so this was designed in the 60s
and even today we still have system/360
derivative machines and a piece of code
you ran or you wrote back in 1965 will
still run on these machine
today which is pretty pretty amazing
natively so how does this survive on
today so here's actually the IBM 360 47
years later as in the Z 11
microprocessor so the IBM 360 has since
been renamed to the IBM 370 and then it
has been renamed to the IBM 370 e^x
which was in the 80s there was never a
IBM 380 strangely enough
and then later on they just changed the
name to the Z series so have a cooler
bottling model numbers here so we had
the IBM z series processors and this
lives on today so going back to that
8-bit processor which had a 1
microsecond control store read which is
forever we now have the z11 which is
running at 5.2 gigahertz has 1.4 billion
transistors they they have updated the
addressing so it's no longer 24-bit
addressing but it still supports the
original 360 addressing has four cores
out of order issue out of order memory
system big caches on on chip 24
megabytes of your l3 cache and you can
even put multiple these together to
build a multiprocessor system out of
lots and lots of multi course and what
I'm trying to get across here is that if
you go forward over time and you build
your instructions set architecture
correct it can live on and you have many
different microarchitecture
implementations and still leverage the
same software and a few few more
examples just to reinforce this a little
bit more let's take a look at an example
of something where you have the same
architecture but different micro
architectures
so here we have the AMD phenom x4 and
here we have the Adam Intel Atom
processor the first Intel Atom processor
and what you'll notice actually is that
they have the exact same instruction set
architecture they prefer on x86 code and
that is sign implementations and this is
just to point out here these are the
same time frames so this is modern
modern roughly modern-day processors
this one has four cores 125 watts here
we have single core 2 watts so there's
design trade-offs so you want to build
different processors in the same design
technology will say but with very
different cost power performance
trade-offs this one can decode 3
instructions this one can decode 2
instructions so it's a different
microarchitecture difference this one
has 64 kilobyte cache l1 this one as a
32 kilobytes l1 I cache very different
cache sizes even though they're
employing the same architecture or big a
architecture strangely enough they have
the same l2 size you know things happen
this one's out of order versus in order
and clock speeds are very different and
I want to contrast this with different
architecture or different Begay
architecture and different
microarchitecture so if we think about
some different examples of instruction
set architectures there's x86 there's
PowerPC there's IBM 360 there's alpha
there's arm you've probably heard all
these different names and these are
different instruction set architectures
so you can't run the same software on
those two different instruction set
architectures so here we have an example
of two different instruction set
architectures with two different
microarchitectures so we have the phenom
x4 here versus the IBM power 7 and we
already talked about the x4 here but the
power 7 has
our instruction set which is different
than the x86 instruction set so you
can't run one piece of code that's
compiled for this over here and vice
versa and the microarchitecture is are
different so here we have eight core 200
watts and decode six instructions per
cycle while this is a pretty beefy
processor it's also out of order and has
the same clock frequency something that
I that can also happen is you can end up
with architectures where you have
different instruction set architecture a
different big a architecture but almost
the same microarchitecture and this this
does this does happen so you end up with
let's say two processors that are both
three wide issue same calf sizes but
let's say one of them implements PowerPC
and the other one implements x86 and
things things like that do happen that's
more of a coincidence but I'm trying to
get across the idea that many times the
that the microarchitecture could be the
same and those are more trade-off
considerations versus the instruction
set architecture which is more of a
software programming design constraint
you
