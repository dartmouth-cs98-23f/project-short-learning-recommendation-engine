second,duration,transcript
2.21,4.35,[Music]
4.24,4.72,the carnegie mellon vaccination database
6.56,4.8,talks are made possible by autotune
8.96,3.36,learn how to automatically optimize your
11.36,3.56,mysql
12.32,4.24,and postgres configurations at
14.92,3.56,autotune.com
16.56,3.92,and by the stephen moye foundation for
18.48,2.719,keeping it real find out how best to
20.48,3.84,keep it real
21.199,6.481,at stevenmoyefoundation.org
24.32,5.52,hi guys uh welcome to the last
27.68,3.04,vaccination seminar talk for the
29.84,2.8,semester
30.72,3.76,we're super excited to finish off with
32.64,4.88,the professor eugene wu
34.48,6.239,uh he is an associate sorry so serious
37.52,6.24,assistant professor without tenure uh
40.719,3.84,at columbia university um he did a phd
43.76,3.36,uh under
44.559,4.32,um sam madman and mit um so he's gonna
47.12,3.36,talk about his his research on
48.879,3.041,human data interaction and building
50.48,3.36,systems around that space
51.92,3.68,so as always if you have a question for
53.84,3.76,eugene as he's giving the talk
55.6,3.279,uh please don't meet yourself say who
57.6,3.279,you are and where you're coming from and
58.879,3.601,feel free to interrupt him at any time
60.879,3.041,we want him you know want this to be a
62.48,3.679,conversation and not him
63.92,3.44,talking by himself and eugene hopefully
66.159,3.441,you will introduce the
67.36,3.36,uh the museum ps behind you before you
69.6,3.76,talk
70.72,4.48,okay sure yeah so thanks andy for uh
73.36,2.799,inviting me to close out the vaccination
75.2,4.239,season
76.159,6.801,uh and this museum piece um you know
79.439,4.481,is a a a prized um part of my art
82.96,3.76,collection
83.92,4.4,it's um a t-shirt signed by mike
86.72,3.92,stonebreaker who's uh
88.32,4.159,you know one of the the pioneers and
90.64,5.36,illustrious researchers and uh
92.479,6.561,in our field so with that um let me
96.0,5.28,get started i also noticed by the way
99.04,5.359,that andy added to my bio that i
101.28,3.92,wear pants and i wanted to clarify that
104.399,3.441,it
105.2,5.12,depends on the temperature and situation
107.84,4.48,uh whether or not it's needed
110.32,3.759,i also just want to clarify that you
112.32,2.56,know in contrast to the rest of the
114.079,3.201,series
114.88,4.08,i'm not going to talk about a particular
117.28,2.4,database system but instead share the
118.96,2.159,vision that
119.68,3.439,you know my students and collaborators
121.119,4.481,have been working on uh in this area of
123.119,5.92,system for human data interaction
125.6,5.6,um so as we all know programming is
129.039,3.601,powerful because users don't need a
131.2,2.64,program right they could use human
132.64,3.679,computer interfaces
133.84,4.56,that we all use today but the premise of
136.319,3.841,course of this entire seminar
138.4,3.68,is that the center of gravity is
140.16,4.159,shifting from compute to data
142.08,4.159,to the point where data rolls everything
144.319,3.681,around us
146.239,3.761,and so there's correspondingly shift
148.0,3.84,towards human data interfaces right
150.0,3.84,they're a center around visualizing and
151.84,2.64,interactively analyzing and manipulating
153.84,3.28,data
154.48,4.72,and we're seeing this kind of like trend
157.12,3.28,across nearly every discipline and every
159.2,4.48,task right across
160.4,6.0,monitoring finance marketing science and
163.68,3.839,industry as well as data tasks such as
166.4,3.76,data wrangling
167.519,3.521,data modeling data exploration analysis
170.16,2.88,and so on
171.04,3.919,and in fact if you think about databases
173.04,2.64,themselves the reason why i have this
174.959,2.801,seminar
175.68,4.0,you know in this field at all is because
177.76,4.08,they represented a leap in human data
179.68,5.279,interaction from imperative programming
181.84,5.2,to declarative specification and now
184.959,3.841,the demand for better interfaces is not
187.04,3.36,just from programmers but really from
188.8,3.12,everyone
190.4,3.52,and you can think of human data
191.92,2.88,interfaces as both the front end
193.92,2.88,interface
194.8,3.439,right that renders data as pixels on the
196.8,2.88,screen and let users point and
198.239,3.521,manipulate this
199.68,4.24,and underlying systems that transform
201.76,5.119,and process the data in response
203.92,4.64,and yet despite the active research in
206.879,3.681,both of these areas
208.56,3.52,right it's still very difficult if you
210.56,4.16,think about it to build
212.08,3.68,and design data interfaces today and i
214.72,3.36,wanted to start with
215.76,4.24,two of the major reasons why which are a
218.08,4.4,combination of scale and what i call
220.0,5.28,design dependence
222.48,3.679,so if you think about scale if your data
225.28,2.48,set is small
226.159,3.121,and you can just process it in the in
227.76,3.44,the browser and the client
229.28,4.159,then the problem is arguably solved and
231.2,3.759,there's many many great solutions today
233.439,3.44,but as the data size grows your
234.959,2.801,architecture necessarily becomes more
236.879,2.241,complex
237.76,2.88,for instance you might need to shift
239.12,2.24,processing out of the browser to your
240.64,2.799,laptop
241.36,4.0,and if the data gets any larger then you
243.439,2.88,might have to use a remote server and
245.36,3.36,database or
246.319,4.161,even the cloud right and all of this
248.72,3.76,introduces latency at every
250.48,4.319,system boundary as well as network
252.48,3.599,bottlenecks cloud api calls and so on
254.799,2.801,and the fact that you're now kind of
256.079,3.201,like implementing and running a
257.6,3.919,distributed system
259.28,4.24,but in addition to that right the
261.519,3.841,interface itself hasn't really changed
263.52,2.959,the user still expects the same amount
265.36,2.96,of responsiveness
266.479,4.16,because you know they don't really see
268.32,3.52,any of this and in order to kind of like
270.639,3.28,provide that
271.84,4.0,then we often end up adding caches the
273.919,3.84,high latency ever in the system
275.84,3.12,and if the caches become quite smart
277.759,2.241,right because you might want to query
278.96,3.28,the data in a cache
280.0,3.919,then they start looking like databases
282.24,3.92,and it's not to say that at
283.919,3.681,every level of this kind of architecture
286.16,2.72,there aren't great libraries right
287.6,2.08,there's really good libraries and
288.88,2.64,systems
289.68,3.92,to solve each of these individual
291.52,2.48,problems but optimizing and combining
293.6,3.039,them
294.0,4.56,together is still non-trivial in fact if
296.639,3.761,you squint this is kind of akin to the
298.56,3.52,memory hierarchy and we kind of know
300.4,3.359,programming efficiently against such a
302.08,3.36,hierarchy is one of the fundamental
303.759,4.0,challenges of computer science
305.44,4.16,however in this particular case we're
307.759,3.841,asking designers to actually
309.6,3.68,manually program and optimize against
311.6,3.84,this hierarchy
313.28,4.16,and combine disparate software systems
315.44,3.039,and part of this signals a lack of great
317.44,3.12,abstractions
318.479,3.361,for specifying and describing the
320.56,3.04,interfaces right
321.84,3.359,and enabling this kind of optimization
323.6,3.599,that we know and love
325.199,4.241,now you might say well there's a lot of
327.199,2.641,fast like and responsive visualizations
329.44,2.08,out there
329.84,3.04,so clearly if you know exactly what you
331.52,3.84,want to build you can hire
332.88,3.92,a crack team of developers and designers
335.36,3.679,and just build and optimize it
336.8,4.32,but for most cases actually interface
339.039,4.16,design is an iterative process
341.12,4.16,and the problem is that design choices
343.199,3.84,affect the system architecture as well
345.28,3.84,so let's consider a very very simple
347.039,3.44,example we'll look at different designs
349.12,3.2,of the left interface
350.479,3.521,that that is just you know analyzing
352.32,2.48,legislative votes from chambers of
354.0,2.24,congress
354.8,3.6,and then on the right we'll have a
356.24,2.48,trivial architecture and just look at
358.4,1.76,how
358.72,3.039,what kinds of data structures you might
360.16,3.759,pre-compute
361.759,3.921,so if you want to add two buttons to
363.919,4.4,provide interactivity to choose
365.68,4.72,the decade then we it's pretty simple
368.319,4.0,right we can pre-compute both decades
370.4,3.76,and then when the user clicks on one of
372.319,3.121,them then we can send the pre-computed
374.16,3.28,results back to the user
375.44,3.44,so that's very simple but what if we
377.44,3.52,change the design slightly
378.88,4.159,to a range slider well this would then
380.96,3.04,require pre-computing a quadratic number
383.039,2.561,of views
384.0,3.44,and so you would need a different data
385.6,2.48,structure maybe a data cube or something
387.44,2.16,else
388.08,3.839,you might even consider another
389.6,4.4,optimization to push that to the browser
391.919,3.12,and then cache and process it in in
394.0,3.44,place
395.039,4.241,right but then maybe maybe the designer
397.44,2.64,wants to try adding a radio button or
399.28,2.88,something else
400.08,3.04,and that requires yet another type of
402.16,3.12,optimization
403.12,4.4,right and this is just for a very simple
405.28,4.479,example but the bottom line is that any
407.52,4.0,minor change in the interface design
409.759,3.28,directly affects the architecture and
411.52,2.72,the types of optimizations that are
413.039,4.321,needed
414.24,5.679,and so we see here is that the trend in
417.36,4.0,most application development today on
419.919,3.521,web and on mobile
421.36,4.08,is veering towards no code levels of
423.44,5.12,simplicity when data is not really an
425.44,4.879,iss issue yet the combination of scale
428.56,4.4,and design dependence makes this
430.319,4.401,increasingly harder for data intensive
432.96,3.84,interfaces
434.72,3.68,so what our lab has been focused
436.8,3.76,focusing on over the past
438.4,3.84,you know several years are three classes
440.56,3.759,of problems under the umbrella of the
442.24,4.16,data visualization management system
444.319,3.761,at the foundations level we're thinking
446.4,3.68,about identifying
448.08,4.0,system primitives that can more easily
450.08,3.92,express and build data interfaces and
452.08,3.839,enable optimization
454.0,4.4,on top of that we're also developing
455.919,5.441,systems algorithms to more easily design
458.4,3.68,interfaces themselves and then at the
461.36,2.08,very top
462.08,3.519,we've been thinking about if we can
463.44,4.56,design interfaces easily and we can
465.599,4.72,implement them easily then what other
468.0,3.44,capabilities beyond displaying data and
470.319,3.44,clicking on widgets
471.44,4.08,could we think about right and so
473.759,2.641,there's many projects at each of these
475.52,2.72,different layers
476.4,5.28,but what i wanted to do today is focus
478.24,4.799,on one slice through this architecture
481.68,3.84,two of these projects are going to
483.039,3.44,showcase a decades-old concept called
485.52,2.799,data lineage
486.479,3.28,helps us innovate at the systems and
488.319,3.361,interaction levels
489.759,4.0,and then the third project shows how we
491.68,4.88,might expand the range of interfaces
493.759,4.72,that are designed and created today so
496.56,4.0,i'll start with smoke which reframes
498.479,3.921,interaction as lineage operations
500.56,3.199,this is work uh initially led by
502.4,2.88,photosellidus
503.759,3.361,and it's now continued by hanyin and
505.28,3.919,charlie so
507.12,3.12,what is fine grain lineage given a
509.199,2.56,workflow such as
510.24,3.919,you know for example here i have two
511.759,5.041,tables i want to join them by id or
514.159,3.36,color and i want to aggregate them by id
516.8,3.599,or color
517.519,5.041,right so fine grain lineage corresponds
520.399,4.88,to the record level dependencies
522.56,3.92,between operator inputs and outputs
525.279,3.841,concretely
526.48,3.84,if we look at output 1 the orange record
529.12,4.48,then it depends
530.32,5.04,on the join results j1 and j2 and j1
533.6,4.96,course finally then depends
535.36,4.96,on a1 and b1 in the base tables and this
538.56,2.08,forms a graph that can tell you well
540.32,2.88,which
540.64,3.52,inputs contributed to any output records
543.2,2.4,and vice versa
544.16,3.119,and it's very useful in terms of
545.6,4.16,debugging privacy
547.279,4.081,fixing distributed uh protocols
549.76,3.6,incremental view main and some more
551.36,4.8,right so it's been around for several
553.36,5.12,decades and so it's very useful
556.16,4.08,however actually materializing and using
558.48,4.08,this lineage graph today is
560.24,3.92,very very expensive on even recent
562.56,3.36,papers and systems
564.16,4.08,on analytical queries the existing
565.92,4.56,overheads can be between 10 to over a
568.24,3.92,thousand x slowdown of the query
570.48,3.68,and it kind of makes sense because a
572.16,4.16,very very optimized read query
574.16,3.44,has now transformed into a massive write
576.32,3.36,operation right
577.6,3.6,and in addition lineage is often
579.68,3.04,inefficiently represented
581.2,3.44,uh for instance you know i'll i'll
582.72,3.76,describe this next
584.64,4.08,and so to give you a sense there here
586.48,4.08,are two common approaches today
588.72,3.44,the first is what we call the logical
590.56,2.8,approach and we stay within the
592.16,2.96,relational model
593.36,3.68,and the goal is to just rewrite the base
595.12,3.36,query so that output is annotated with
597.04,3.12,this lineage information
598.48,3.76,for example here in the output it would
600.16,4.239,be the gray attributes right a
602.24,4.32,and b now the nice thing is this is
604.399,4.88,compatible with any database system
606.56,4.8,but as you can see the output 101 has
609.279,3.921,now been replicated for each combination
611.36,2.8,of input records it depends on from the
613.2,2.8,base tables
614.16,3.44,and the query now needs to do a lot more
616.0,2.64,work to actually compute these
617.6,2.32,annotations
618.64,2.96,because of this denormalized
619.92,3.84,representation there's a kind of some
621.6,4.88,inherent overheads in this
623.76,4.4,approach now alternatively a physical
626.48,2.4,approach which is popular in big data
628.16,3.6,systems
628.88,3.92,like spark is to modify each operator
631.76,3.28,implementation
632.8,4.08,to write pointers out to some external
635.04,3.12,linear subsystem like a graph or a key
636.88,3.44,value store
638.16,4.32,um but it turns out that you know even
640.32,4.24,just making these virtual function calls
642.48,3.76,can be very expensive in any fast
644.56,3.44,database system
646.24,3.76,we experimentally see that just making
648.0,4.959,empty virtual function calls
650.0,3.6,can slow things down by over 2x in
652.959,2.721,addition to
653.6,4.64,the subsystem also replicates a lot of
655.68,5.52,functionality that database provides
658.24,5.68,and so in both cases you know like it's
661.2,4.72,it's quite expensive
663.92,3.599,now the reason we care about this and
665.92,3.919,i'm harping on performance
667.519,3.281,is because lineage is actually a natural
669.839,3.841,way to express
670.8,3.279,interactions and and define interfaces
673.68,2.24,if we
674.079,3.361,think about everything that you see on
675.92,3.28,the screen that's data
677.44,3.2,and you point to any pixel that
679.2,3.44,represents data what you're really
680.64,4.0,referring to is its lineage
682.64,3.04,for instance if i select points in the
684.64,3.04,scatter plot
685.68,3.68,what i'm really selecting is the data
687.68,4.32,that backs it or it's lineage
689.36,4.08,and similarly if this base data has been
692.0,4.16,rendered in a different way
693.44,4.56,for example like in a bar chart then we
696.16,3.6,typically will see that the bar chart
698.0,2.399,changes when we select data in another
699.76,2.48,chart right
700.399,4.56,this corresponds directly to either
702.24,4.24,forward lineage or view refresh
704.959,3.681,and so ultimately all of this is
706.48,5.039,declarative right what's happening here
708.64,3.84,uh is the user interaction is data that
711.519,2.88,we're joining
712.48,3.84,with what's rendered in the scatter plot
714.399,3.921,and we're then getting its
716.32,4.319,lineage and then refreshing the other
718.32,3.92,views in other words if you think about
720.639,4.0,interactive visualizations
722.24,4.48,the initial charts are the output of sql
724.639,3.76,and the interactions is then lineage and
726.72,4.239,more sql
728.399,4.641,beyond just visualization right we can
730.959,3.12,data is manipulated and rendered in many
733.04,4.56,other forms
734.079,4.241,yifon wu's uh with 2020 work explored
737.6,2.239,how ref
738.32,3.6,how you might want to for example
739.839,2.881,reference lineage and code for instance
741.92,2.96,you might want to
742.72,4.239,query against the lineage that you
744.88,3.36,selected and pointed to in some other
746.959,3.12,visualization or chart
748.24,3.279,or you might want to fit a model against
750.079,3.601,it right so this is all
751.519,3.681,programming at this point and it makes
753.68,3.68,sense because what lineage really
755.2,3.199,represents is the correspondence between
757.36,2.96,your input data
758.399,3.601,and what you see on the screen so
760.32,3.84,ultimately lineage is great
762.0,3.36,however existing systems are super super
764.16,3.2,slow right it's just
765.36,3.68,unrealistic to use them to drive
767.36,3.919,interactive applications
769.04,3.84,and yet we know that fast visualization
771.279,3.36,implementations do exist
772.88,4.16,and so what smoke is trying to do is
774.639,4.481,bridge this gap
777.04,4.0,so what smoke is it's a row-based
779.12,4.24,in-memory query engine
781.04,4.239,during query execution right as you
783.36,3.52,execute each operator it materializes
785.279,4.481,the lineage information
786.88,3.519,for each operator the idea is really to
789.76,3.199,overlap
790.399,4.641,lineage capture and operator execution
792.959,3.281,by reusing data structures built such as
795.04,3.76,hash tables
796.24,4.08,and use it for lineage capture and what
798.8,3.76,we do is we're going to instrument
800.32,5.6,physically these operators and use query
802.56,6.16,compilation to remove that overhead
805.92,4.56,uh if you know that you only care about
808.72,3.52,end-to-end lineage information
810.48,3.919,we can actually then propagate this
812.24,4.399,information as we generate the lineage
814.399,3.201,so that you end up with just uh kind of
816.639,3.121,like end to end
817.6,3.44,information and avoid storing this per
819.76,2.8,operator
821.04,3.2,all right so this is an overview of
822.56,3.68,smoke and what i wanted to do is give
824.24,2.88,you two examples of how lineage capture
826.24,2.0,works
827.12,3.76,in the system and then you can
828.24,4.32,extrapolate for something like filter
830.88,3.6,what we're going to do is populate the
832.56,4.0,lineage information which is represented
834.48,3.84,as this red integer array
836.56,3.92,so for example let's take a look at the
838.32,3.519,first row it's going to pass the filter
840.48,4.64,because 40 is greater than
841.839,4.481,20. in addition we're going to store the
845.12,3.2,input rows id
846.32,3.44,in the corresponding offset in the in
848.32,3.92,the integer array
849.76,4.16,right the second row fails the filter
852.24,3.279,but then the third row passes and so
853.92,3.68,we're going to store its corresponding
855.519,3.601,record id as well so that's pretty much
857.6,3.12,all we have to do
859.12,3.2,lineage in this case is just a simple
860.72,3.359,integer rate it's cheap to create and
862.32,3.759,populate
864.079,3.921,now for something more complicated like
866.079,3.921,group by it works in two phases
868.0,4.079,during the build phase we're going to
870.0,3.76,augment each bucket for example here
872.079,3.76,when i look at row one i'm going to
873.76,4.8,create the bucket and then
875.839,4.401,in addition uh augment it to also store
878.56,3.76,a list of record ids
880.24,3.44,right so then when i go to record two
882.32,2.56,and i update that bucket i'm going to
883.68,3.2,store its information
884.88,3.199,and similarly for record 3 when i create
886.88,2.8,the new bucket
888.079,4.32,i'm going to also allocate this
889.68,5.2,information and store its record id
892.399,4.321,now in the scan phase all we do is just
894.88,3.759,emit the output table as normal
896.72,3.119,and for the lineage we simply create a
898.639,3.281,top level array
899.839,3.12,which we know the exact size of and it
901.92,3.44,just points to the
902.959,3.44,rid lists that i've already constructed
905.36,3.039,right so all of this
906.399,4.161,ends up being super cheap too and none
908.399,3.841,of this is really additional work and
910.56,3.279,additionally scanning the data
912.24,3.12,to generate lineage information and
913.839,4.481,piggybacks as much as it can
915.36,4.159,off of query execution so rather than
918.32,2.959,showing you like you know like
919.519,2.641,performance graphs i just wanted to show
921.279,2.881,this in action
922.16,3.039,that it can actually power interactive
924.16,3.44,applications
925.199,4.241,so this is a cross filter visualization
927.6,4.56,over 14.5
929.44,4.399,million rows of flight data and it's
932.16,3.679,going to be rendered as four charts each
933.839,4.56,one is just a query result right
935.839,4.161,now when you click on a state or a bar
938.399,2.88,we filter the input table for its
940.0,3.36,corresponding subset
941.279,3.601,and then re-aggregate and re-render each
943.36,3.2,of these other charts
944.88,3.199,and the benchmark will build whatever
946.56,3.44,data structures it needs
948.079,3.361,and then load these initial charts and
950.0,6.079,then simulate every
951.44,7.759,uh every one of the 18 uh you know 1800
956.079,5.041,possible interactions now the one
959.199,3.681,popular approach that's dominate
961.12,3.839,that's dominant today is to build
962.88,3.84,visualization specific cube structures
964.959,3.68,to accelerate these interactions
966.72,3.119,however recent papers end up taking
968.639,3.841,between four minutes
969.839,4.481,to one hour to build a data cube for
972.48,2.719,this data set right so it's really not
974.32,3.92,realistic
975.199,4.64,for in ad-hoc cases and these data cubes
978.24,3.279,themselves limit the types of queries
979.839,3.68,that you can express
981.519,3.76,so we're going to show in this benchmark
983.519,3.68,is instead of waiting for four minutes
985.279,3.201,we design a custom cube it takes about
987.199,4.64,nine seconds to build
988.48,5.76,uh just for this benchmark in addition
991.839,4.56,here in the top right uh this is going
994.24,4.159,to show the cumulative time taken
996.399,4.0,for each interaction including the time
998.399,4.081,to load these initial charts
1000.399,3.041,all right so now the benchmark has
1002.48,2.719,started
1003.44,3.199,and what we're doing is waiting for the
1005.199,4.721,data cube to be built
1006.639,5.2,and once it is built we can see that
1009.92,3.279,every interaction is super fast right
1011.839,3.201,and so that's why in the cumulative
1013.199,2.721,chart it starts fairly high along the
1015.04,4.0,y-axis
1015.92,5.279,and then it's basically horizontal
1019.04,3.76,now to show you smoke in action what
1021.199,2.801,we're going to do is when we generate
1022.8,3.2,these initial charts
1024.0,3.039,we just instrument it to capture lineage
1026.0,2.88,information right
1027.039,3.841,so as if we created all these charts in
1028.88,4.079,an ad hoc manner
1030.88,3.919,now when you click on a state we can use
1032.959,4.24,this backward lineage information
1034.799,4.4,to help us find the input subset and we
1037.199,3.921,can use the forward lineage information
1039.199,3.84,to incrementally update all these other
1041.12,3.12,charts so you can think of lineage now
1043.039,4.721,as an optimization
1044.24,6.319,that comes for free it's helping us do
1047.76,4.0,selective view refresh so now the
1050.559,3.441,benchmark has started
1051.76,4.0,and you can see the dashboard basically
1054.0,3.679,loads very very quickly because
1055.76,3.039,lineage capture is actually very very
1057.679,2.561,fast right
1058.799,3.601,and it turns out that we end up
1060.24,4.319,finishing this particular benchmark
1062.4,3.68,faster than it took to build the cube
1064.559,4.161,and so what that suggests
1066.08,4.08,right is that lineage uh has the
1068.72,3.68,possibility of being
1070.16,4.72,fully interactive and practical for
1072.4,4.639,developing these interactive interfaces
1074.88,4.4,in addition we can capture and use this
1077.039,4.0,information on the fly
1079.28,3.12,so this is work that we did several
1081.039,3.681,years ago
1082.4,3.92,and the big question that everyone often
1084.72,2.8,asks is like that you know this is kind
1086.32,3.28,of a toy engine
1087.52,3.84,and no one in real life is going to
1089.6,4.0,instrument their their engines
1091.36,3.84,to actually do this right and who uses a
1093.6,2.319,road based query compiled engine for
1095.2,3.2,analytics
1095.919,4.161,blah blah blah so what about real
1098.4,2.639,engines and can you do it with minimal
1100.08,2.8,surgery
1101.039,3.121,so the idea that we've taken here is
1102.88,2.88,we're looking now
1104.16,3.519,at polymer engines that are actually
1105.76,2.24,used for analytics and if you think
1107.679,2.801,about
1108.0,3.679,how something like filter works uh the
1110.48,2.8,idea is the following
1111.679,3.441,right so if you have something like
1113.28,3.36,quantity and you have a filter
1115.12,3.6,then the output ends up being a
1116.64,3.68,selection vector right where each bit is
1118.72,4.72,set depending on whether or not the row
1120.32,3.599,passed the filter if we stare at what
1123.44,2.16,this is
1123.919,3.601,as compared to the lineage that i showed
1125.6,3.92,you earlier then it turns out that
1127.52,3.84,they're basically equivalent a selection
1129.52,3.84,vector is a dense representation
1131.36,3.28,of the same information that lineage was
1133.36,3.439,encoding as well
1134.64,4.0,and so what we've basically found at
1136.799,2.481,least in some late materialization
1138.64,3.52,engines
1139.28,3.2,is that query execution itself is not
1142.16,2.399,just
1142.48,4.4,easy to piggyback off of it is literally
1144.559,4.321,computing lineage in many cases
1146.88,3.919,and so what we're doing actively right
1148.88,3.76,now and so this is unpublished work and
1150.799,3.841,we're kind of like still working on it
1152.64,3.12,is we're in instrumenting systems like
1154.64,2.56,duckdb
1155.76,3.919,which is an embedded column or
1157.2,2.88,vectorized engine to see how far we can
1159.679,2.721,get
1160.08,4.88,using this kind of idea so i wanted to
1162.4,4.8,show you is just like very early numbers
1164.96,3.04,of lineage capture on tpch with scale
1167.2,3.44,factor one
1168.0,4.799,for four of the queries these blue bars
1170.64,3.44,are just the smoke numbers copied from
1172.799,3.601,the original paper
1174.08,4.4,and so it all of these are relative
1176.4,3.84,right in terms of overhead to
1178.48,3.04,get the compiled queries essentially you
1180.24,2.319,can think of it as handwritten tight
1181.52,4.159,loops
1182.559,3.921,now smokeduck is duckdb with lineage
1185.679,3.281,capture
1186.48,4.319,the numbers now are relative to duckdb
1188.96,3.44,right so it's not apples to apples
1190.799,4.801,but we end up seeing is that the
1192.4,4.0,overhead varies between 1.8 to 4.8
1195.6,3.199,percent
1196.4,4.24,overhead in addition it turns out that
1198.799,4.081,the lineage instrumentation
1200.64,4.24,took about four to 20 lines of code per
1202.88,2.96,operator and because a lot of the code
1204.88,4.0,is just pinning
1205.84,5.04,existing arrays in memory and overall in
1208.88,2.32,terms of memory overhead it's about 20
1210.88,4.48,to
1211.2,6.64,40 megabytes on tpch scale one right
1215.36,4.48,so what all of this means is that
1217.84,3.92,lineage is a critical piece for
1219.84,2.64,expressing interactive applications and
1221.76,2.399,interfaces
1222.48,3.36,but it's got to be fast right and what
1224.159,4.481,we've shown is that lineage
1225.84,4.4,is interactive and is practical and so
1228.64,3.279,what we're doing right now is studying
1230.24,3.04,the extent that these ideas can
1231.919,3.361,uh can apply to other late
1233.28,4.16,materialization engines and how to
1235.28,4.48,cleanly integrate lineage management
1237.44,4.0,into these engines as well and it turns
1239.76,3.84,and what we seem to see
1241.44,3.68,is that many aero based uh analytics
1243.6,3.92,engines like data fusion
1245.12,4.32,and aquaro and javascript are also
1247.52,4.08,amenable to some of these ideas
1249.44,4.32,so we're very excited about this um and
1251.6,5.28,so this is kind of like how
1253.76,4.159,something from database theory can be
1256.88,4.159,applied to something
1257.919,5.76,in hci so now i want to shift to
1261.039,4.401,a usage of lineage and this is work led
1263.679,4.561,by lampreus focus
1265.44,4.239,young woo with collaborators janon and
1268.24,4.72,knuckle
1269.679,6.081,so this this animation is from the kai
1272.96,4.48,17 paper same stats different graphs
1275.76,3.039,all of them have the same summary
1277.44,3.44,statistics on the right
1278.799,4.161,but obviously they're very different
1280.88,3.679,right and visualization is exactly
1282.96,4.079,powerful because it shows you what a
1284.559,5.12,priori statistics cannot
1287.039,4.721,now our work seeks to empower users to
1289.679,2.801,identify unexpected patterns in the
1291.76,4.0,interface
1292.48,5.679,and be able to ask why these exist right
1295.76,4.32,and then to be presented with sensible
1298.159,3.76,explanations and this hopefully can help
1300.08,3.12,them debug data errors or simply better
1301.919,3.601,understand what's going on
1303.2,4.24,so i want to just share two examples via
1305.52,5.039,demos of our work
1307.44,4.08,the first demo is this idea of query
1310.559,4.0,explanations
1311.52,4.56,that we introduced in 2012 through the
1314.559,2.801,scorpion paper
1316.08,3.28,and so here like you can imagine a
1317.36,2.72,sensor deployment collecting a bunch of
1319.36,2.4,data
1320.08,3.76,um per minute right across like an
1321.76,3.12,entire deployment uh and we might want
1323.84,2.64,to group by hour
1324.88,2.96,and then compute the average sanitation
1326.48,2.4,temperatures and then plot on a
1327.84,3.28,visualization
1328.88,3.76,now the user might immediately then ask
1331.12,3.439,well like all of this looks kind of like
1332.64,3.84,periodic and it might look pretty good
1334.559,3.36,but why is this region look so high
1336.48,3.439,right what's going on there
1337.919,3.521,and we'd like some explanation as to
1339.919,3.041,what's going on
1341.44,3.52,so this is kind of what i wanted to
1342.96,4.8,first demo if you can see
1344.96,4.719,my uh screen so this is the exact same
1347.76,4.0,data so the blue corresponds to the
1349.679,3.441,average temperature on an hourly basis
1351.76,3.12,and you can see there's kind of some
1353.12,3.28,daily periodic pattern right
1354.88,3.36,so what we'd like to be able to do is
1356.4,4.399,literally just like in the slides ask
1358.24,3.84,what is going on here and specify them
1360.799,3.12,as anomalies
1362.08,3.76,and then say hey you know i thought they
1363.919,3.841,would look closer to these other
1365.84,4.0,points that i just selected and then i
1367.76,4.0,can run the system called scorpion
1369.84,3.6,and what we're going to do is look for
1371.76,4.64,potential explanations
1373.44,3.92,as to why this might be the case um and
1376.4,4.32,so what we'll see
1377.36,5.679,here is uh uh you know i think i screwed
1380.72,4.64,up some demo no i didn't screw up a demo
1383.039,5.601,but i need to show you more information
1385.36,5.439,uh so
1388.64,4.96,you know what screw it i don't care um
1390.799,4.721,so here uh if we look at mode 18 and you
1393.6,4.959,re-visualize just the data from mo
1395.52,5.519,18 we can see that like the data is just
1398.559,3.441,totally crazy right and it turns out
1401.039,3.041,that if you actually
1402.0,3.679,rerun this which i'll actually do right
1404.08,4.0,now um
1405.679,3.12,because this is a little bit better um
1408.08,4.24,is if you do
1408.799,5.281,exactly the same kind of like uh
1412.32,3.92,uh thing sorry i'm just gonna do this
1414.08,2.959,again because i can't show you all the
1416.24,3.04,coolness
1417.039,3.601,uh if i'm missing some of the interviews
1419.28,3.92,good keep going
1420.64,4.639,you got it all right so we're gonna like
1423.2,4.16,re-execute this right and we're going to
1425.279,4.081,look at different rules and see their
1427.36,4.0,effects if we remove the data
1429.36,4.16,so what that means is earlier we saw
1431.36,3.36,that sensor 18 is a potential kind of
1433.52,3.519,like explanation
1434.72,3.52,and if i hover over this now what i'm
1437.039,2.961,going to do is remove
1438.24,3.84,all of its readings and then
1440.0,3.76,re-visualize the visualization
1442.08,4.079,and so we can see here is like the
1443.76,5.12,anomalies we specified disappeared
1446.159,4.561,and so this can be a useful heuristic uh
1448.88,2.96,for an analyst and try to understand
1450.72,3.52,what's going on
1451.84,4.319,right and so what the semantics are here
1454.24,2.4,is that we've generated this predicate
1456.159,2.481,rule
1456.64,3.919,that says centers with low voltage or
1458.64,3.84,you know sensor 18 and so on
1460.559,3.921,and what we mean is if we ignore all
1462.48,4.88,that data that matches the predicate and
1464.48,4.799,and re-execute the query then it would
1467.36,4.0,help address the user's question right
1469.279,4.161,their complaint and there's been really
1471.36,4.0,great follow-up work by peter bayless by
1473.44,2.479,sudbury roy alexandra and many other
1475.36,3.36,areas
1475.919,4.24,of people in this particular area but
1478.72,3.92,what i wanted to focus
1480.159,3.841,show you another demo is a different
1482.64,2.8,example of explanation
1484.0,3.919,in the context of machine learning
1485.44,5.359,analytics in our recent rain work
1487.919,4.561,and the setup is very similar right
1490.799,3.681,however what we know is that machine
1492.48,2.96,learning is not only used for end user
1494.48,3.76,recommendations
1495.44,4.64,but it's also often used in one step of
1498.24,3.679,a data analytics workflow
1500.08,4.32,for example here maybe what i want to do
1501.919,4.0,is first filter to just get the readings
1504.4,3.68,for faulty sensors
1505.919,3.841,right and i have some model that
1508.08,2.32,predicts whether or not a sensor is
1509.76,2.08,faulty
1510.4,3.279,and then i want to group them by hour
1511.84,4.24,and just count it so maybe this is for a
1513.679,5.441,dashboard or a monitoring system
1516.08,4.4,now here the user might see that there's
1519.12,3.84,been a drop
1520.48,3.679,in hours three and four and want to ask
1522.96,3.599,questions why
1524.159,4.88,now existing explanation approaches will
1526.559,5.441,help us find issues in the readings
1529.039,3.841,in the readings data set but even if
1532.0,3.52,that
1532.88,4.64,that data is fully correct we can still
1535.52,3.519,have these errors due to errors in the
1537.52,3.759,training data right because that can
1539.039,4.321,cause the model to mispredict in a way
1541.279,3.041,that ultimately causes what the user is
1543.36,2.559,asking about
1544.32,3.839,and there's not many good solutions for
1545.919,3.841,this problem normal data cleaning looks
1548.159,3.12,for errors in the training data but
1549.76,3.36,ignores kind of how the model or the
1551.279,3.52,downstream analysis is used
1553.12,3.84,and influence analysis techniques for
1554.799,4.0,machine learning relies on labeling
1556.96,4.079,individual model mispredictions
1558.799,4.0,but that doesn't really work if if
1561.039,3.76,prediction is just one step in this
1562.799,4.721,larger analytics process
1564.799,3.281,and so what rain is is the first work to
1567.52,3.12,perform
1568.08,4.959,training data debugging based on user
1570.64,3.68,questions of the analysis outputs
1573.039,3.52,and specifically what we're doing is
1574.32,4.08,we're estimating how much deleting
1576.559,3.681,different training records will affect
1578.4,2.879,what the user has asked about the user's
1580.24,3.039,complaint
1581.279,3.361,so i just want to show you a quick demo
1583.279,3.441,of this in action
1584.64,3.68,so what i have here is just a very
1586.72,3.36,popular data set mnist
1588.32,3.359,and i'm going to group by its predicted
1590.08,3.52,label and it's just going to count
1591.679,3.441,so this is kind of the visualization and
1593.6,3.439,we can see that for the most part we
1595.12,2.64,expect a uniform distribution in this
1597.039,2.961,training
1597.76,3.2,in this data set right but we flip some
1600.0,2.48,of the labels
1600.96,3.04,and so we like to be able to do you can
1602.48,4.0,imagine the user asks well
1604.0,3.2,why is seven so high so i'm gonna just
1606.48,2.24,specify
1607.2,3.2,that i think it's higher than what i
1608.72,2.8,expected and i'd like to see what
1610.4,3.519,training data kind of
1611.52,3.36,might be the reason and so here i've
1613.919,2.801,returned the top
1614.88,3.679,20 training records where if you remove
1616.72,2.64,it from the training set it would help
1618.559,3.921,it would most
1619.36,4.72,decrease this particular output value
1622.48,3.6,and you can see that all of these kind
1624.08,4.079,of highlighted in red correspond
1626.08,3.12,to one digits that have been mislabeled
1628.159,3.52,as seven
1629.2,3.28,right you can similarly click on the bar
1631.679,3.441,for one
1632.48,3.6,and say why is it so low and we would
1635.12,2.72,then identify
1636.08,3.599,is that oh actually you know like
1637.84,3.839,removing all of these missed labels
1639.679,3.441,is you know will help you with this
1641.679,2.88,particular question
1643.12,3.439,right so you can see that depending on
1644.559,3.761,the kind of questions you ask you'll get
1646.559,3.041,kind of like better or worse results
1648.32,3.2,because they may be better
1649.6,3.6,more or less aligned with the type of
1651.52,2.639,error that actually affects what the
1653.2,2.719,user sees
1654.159,3.441,in fact you know an interesting thing is
1655.919,3.681,you can ask nonsen
1657.6,3.12,seemingly nonsensical questions for
1659.6,3.28,example you might ask
1660.72,3.439,you know what kind of data can i delete
1662.88,3.519,from my training set
1664.159,3.041,so that four actually is increased right
1666.399,2.961,the count of
1667.2,3.839,four predictions and what you'll end up
1669.36,4.16,getting is a bunch of
1671.039,3.841,uh digits that look pretty much you know
1673.52,3.92,like closer to fours and
1674.88,3.279,uh than uh than other digits and if you
1677.44,3.119,delete them
1678.159,3.52,then that would help the model predict
1680.559,3.201,more force
1681.679,3.281,right and so it's kind of nonsensical
1683.76,3.6,and so you can see how
1684.96,3.52,visualization and interfaces are an
1687.36,3.199,important component
1688.48,4.0,to trying to understand and interpret
1690.559,4.321,explanations
1692.48,4.16,all right uh this itself of course is
1694.88,2.88,not like a full or complete solution to
1696.64,2.8,this problem but hopefully it
1697.76,3.36,demonstrates the value of not just
1699.44,3.44,the algorithmic side but also the
1701.12,3.919,interface side
1702.88,3.2,now the reason why i talk about this at
1705.039,3.041,all
1706.08,3.839,is because these explanations that we're
1708.08,3.68,talking about right
1709.919,3.601,end up being a function of lineage
1711.76,4.159,information because what we need
1713.52,3.36,is to know for what the user is asking
1715.919,3.76,questions about
1716.88,4.24,what data was it derived from and also
1719.679,3.841,how was it computed
1721.12,3.2,right and so that is precisely lineage
1723.52,2.72,and what
1724.32,3.52,is commonly called data provenance and
1726.24,3.6,so that's why smoke is
1727.84,3.76,useful right it's not just for building
1729.84,3.6,and specifying interfaces
1731.6,5.12,but also for enabling these kinds of
1733.44,5.28,capabilities efficiently
1736.72,3.04,all right so i'm done kind of talking
1738.72,3.04,about the use of
1739.76,3.519,lineage and i wanted to switch gears and
1741.76,2.799,talk about this third project called
1743.279,3.441,precision interfaces
1744.559,3.12,that's led by guru chan with early
1746.72,5.28,versions
1747.679,6.641,led by tebow owen and haochi
1752.0,3.039,so we focus so far on building
1754.32,3.12,interfaces
1755.039,4.64,and expanding their capabilities but
1757.44,4.64,interface design itself is ultimately
1759.679,5.681,dictated by the analysis task right
1762.08,5.28,analyses typically start off very ad hoc
1765.36,3.12,you might be programming or like writing
1767.36,2.88,ad hoc queries
1768.48,3.439,and then we ultimately want to design an
1770.24,3.2,interface once we settle on the
1771.919,3.521,set of queries that would be actually
1773.44,3.76,useful for an analysis
1775.44,3.2,and yet if we think about how interface
1777.2,2.88,creation tools work
1778.64,3.44,they actually work in the reverse
1780.08,4.4,fashion right they limit themselves to a
1782.08,4.8,particular class of queries or analyses
1784.48,3.919,and then make creating interfaces for
1786.88,3.679,those easy to build
1788.399,3.681,so here if we think about the tools for
1790.559,3.521,creating interfaces
1792.08,4.079,at the x-axis here corresponds to the
1794.08,4.0,expressiveness of the analysis task
1796.159,3.041,and the y-axis is how easy it is to
1798.08,4.16,create interfaces
1799.2,4.959,using them now tools like metabase and
1802.24,4.24,tableau and excel and so on
1804.159,3.681,make it very easy to build interfaces
1806.48,3.439,that are essentially parameterized
1807.84,4.0,queries or data cube operations right
1809.919,4.321,so you can say that for these very very
1811.84,4.079,common classes of analyses
1814.24,3.12,they're fairly limited but they're very
1815.919,3.36,easy to use
1817.36,3.679,but if you want anything more complex
1819.279,3.841,towards the right then you basically
1821.039,3.52,enter the world of writing lots of code
1823.12,3.6,or paying someone
1824.559,3.36,and although there's engineering kind of
1826.72,3.6,like programmatic
1827.919,4.161,libraries to help with this it's still
1830.32,3.359,just too difficult or expensive
1832.08,4.0,for the vast majority of potential
1833.679,4.641,interfaces right to be creative so
1836.08,3.28,oftentimes they just simply will not and
1838.32,2.64,so the the
1839.36,3.76,kind of like the long-term goal that we
1840.96,3.839,have for this project is to basically
1843.12,3.439,place present interfaces at the top
1844.799,2.24,right for any analysis test how can we
1846.559,2.641,make it
1847.039,4.961,you know nearly trivial to actually
1849.2,4.959,create the corresponding interfaces
1852.0,3.279,and the philosophy that we take is the
1854.159,3.12,following
1855.279,3.921,and this is you know just one approach
1857.279,2.321,if you think about what an interface is
1859.2,2.079,there's
1859.6,4.16,really two components there's a
1861.279,2.801,visualization that renders the output of
1863.76,2.639,some
1864.08,4.4,queries or programs and then there's
1866.399,3.52,interactions that let users change those
1868.48,3.039,queries right
1869.919,3.201,and when you change them then the
1871.519,3.76,interface updates
1873.12,3.6,now if you imagine listing all the
1875.279,3.12,queries that result from
1876.72,3.679,all possible combinations of
1878.399,3.921,interactions with the interface
1880.399,4.0,you could call this the expressiveness
1882.32,3.199,of the interface in other words the
1884.399,3.28,interface itself
1885.519,4.241,is a compact representation of the set
1887.679,4.561,of queries that it can produce
1889.76,4.48,and we we would ideally hope is that
1892.24,4.559,that set includes what we need for an
1894.24,4.64,analysis task
1896.799,4.88,all right so what our work is trying to
1898.88,4.799,do is given a sample of the analysis
1901.679,4.0,task that you would like we want to
1903.679,4.321,derive the latent interface right
1905.679,4.24,and the core challenge here is kind of
1908.0,3.76,uh you know actually took us a long time
1909.919,4.0,to figure out something reasonable
1911.76,3.12,which is how do you map query strings
1913.919,2.801,from the input
1914.88,3.519,to interactive fully interactive
1916.72,3.439,interfaces right
1918.399,3.12,we have a series of papers that look at
1920.159,3.281,different approaches and so what i'll
1921.519,4.0,give you is just kind of a demo
1923.44,3.599,a walkthrough of the four main steps and
1925.519,3.52,what we're currently thinking is a
1927.039,4.321,reasonable approach
1929.039,3.441,uh first we're going to model queries as
1931.36,2.72,their parse trees
1932.48,3.439,so here i'm going to focus on just the
1934.08,3.36,highlighted parts of query one and query
1935.919,3.041,two right because that's the part that's
1937.44,3.76,different
1938.96,4.0,and we can see that these two parse
1941.2,2.719,trees are rooted with equals and have
1942.96,2.719,two children
1943.919,3.36,now the corresponding interface is going
1945.679,2.961,to be simple right because
1947.279,3.041,ultimately we have to execute these
1948.64,3.759,queries and render them
1950.32,4.079,so the simplest interface would be just
1952.399,4.801,render the output of these queries
1954.399,4.801,and then just visualize them but we want
1957.2,4.24,interactive interfaces sometimes
1959.2,4.079,and so we introduced a new class of
1961.44,3.359,nodes called choice nodes to encode
1963.279,3.441,subtree variations
1964.799,4.0,for instance here we can add a choice
1966.72,4.48,node to choose between these two
1968.799,3.12,subtrees right and so what that means is
1971.2,3.12,you can choose
1971.919,3.281,one of its k children and parameterizing
1974.32,2.64,it
1975.2,3.52,will result in a standard parse tree
1976.96,2.319,that you can execute so you can think of
1978.72,2.88,this as
1979.279,3.361,generalizing sergible kind of like
1981.6,3.12,queries that we
1982.64,4.08,that we know and love today the nice
1984.72,3.76,thing about this is choice nodes can be
1986.72,4.24,directly mapped to interactions
1988.48,3.919,for instance here clicking on the second
1990.96,3.28,button would correspond to
1992.399,3.681,choosing the second child of this choice
1994.24,3.84,note right and of course
1996.08,4.079,the buttons are not the only types of
1998.08,4.0,interactions you could map this to you
2000.159,4.321,radio buttons can also choose one of
2002.08,4.319,many and so we can rank the different
2004.48,3.199,candidates by borrowing from existing
2006.399,2.481,interface cost models
2007.679,3.36,that can account for things like
2008.88,5.36,usability complexity
2011.039,4.801,screen size and so on so that's the
2014.24,3.6,third step is costing
2015.84,3.439,and then the fourth step is to recognize
2017.84,3.52,that the middle tree here
2019.279,3.921,is the result of merging the initial
2021.36,2.64,pairs of trees right by adding this
2023.2,3.28,choice node
2024.0,3.12,so it went from two trees to one these
2026.48,2.079,types of
2027.12,2.88,tree transformations allow us to
2028.559,2.561,generate structurally different
2030.0,3.6,interfaces as well
2031.12,3.039,like we saw here now we could also
2033.6,2.959,imagine
2034.159,4.721,refactoring the highlighted equalities
2036.559,4.641,out right so that we have a tree
2038.88,4.24,rooted at equality but then now you can
2041.2,3.68,actually make independent choices
2043.12,3.84,for the left and right operands and so
2044.88,4.32,this ends up generalizing beyond the
2046.96,4.159,input two queries that we had
2049.2,3.04,this also maps to a different interface
2051.119,2.72,right because now we have two
2052.24,3.28,interactions instead of one
2053.839,3.361,and in practice of course you know we
2055.52,3.119,have many different types of
2057.2,2.479,transformation rules and types of
2058.639,3.04,choices
2059.679,3.281,choice nodes that we can express beyond
2061.679,3.361,this trivial example
2062.96,4.32,but hopefully this gives you kind of a a
2065.04,2.96,sense so to put these steps together you
2067.28,2.799,can imagine
2068.0,3.28,initializing the system by parsing the
2070.079,4.721,initial query
2071.28,6.079,input queries into a sequence of trees
2074.8,4.4,and then mapping both the tree execution
2077.359,3.681,results to visualizations
2079.2,3.36,the choice nodes to interactions and
2081.04,4.48,then the tree structure
2082.56,4.96,to a particular layout you can cost the
2085.52,2.48,output interface and then we can either
2087.52,3.2,return
2088.0,4.399,it or then transform the trees further
2090.72,3.76,and so this is the problem statement as
2092.399,5.041,well given a query log we want to search
2094.48,4.72,the space of possible trees and mappings
2097.44,2.8,for the lowest cost interface that
2099.2,4.159,expresses all of them
2100.24,4.56,and potentially more and you may just
2103.359,2.801,said this but what is what is the cost
2104.8,3.44,function here like what
2106.16,3.6,the cost function uh you know we borrow
2108.24,3.2,from existing ui literature
2109.76,4.24,you can you can think of things like
2111.44,5.04,personal preference usability
2114.0,4.48,how easy is it to express the analysis
2116.48,4.16,you know like the workload and so on
2118.48,4.08,uh how you know like whether or not like
2120.64,2.64,there's too many options in a radio
2122.56,3.68,button
2123.28,3.36,uh list and so on right um so you know
2126.24,2.24,there's
2126.64,3.76,different ways that you can cost it and
2128.48,4.72,what we kind of like use is both
2130.4,4.64,per interaction like cost as well as you
2133.2,2.96,know what's the expected effort that the
2135.04,3.52,user needs to take
2136.16,3.199,to express the input queries in sequence
2138.56,2.559,so like
2139.359,2.961,this is stuff you can compute offline
2141.119,3.041,you don't need to put humans in front of
2142.32,4.24,us and test it
2144.16,3.919,uh yeah so you could put humans in front
2146.56,3.44,of uh
2148.079,3.841,different can interfaces offline and
2150.0,5.599,then train some model and then use that
2151.92,5.679,right okay correct yeah
2155.599,3.841,and you know implementation wise we use
2157.599,3.441,monte carlo research it's basically
2159.44,2.96,randomly searching the space
2161.04,3.12,and it's a little bit better than that
2162.4,2.4,because it uses some reinforcement
2164.16,2.88,learning
2164.8,3.76,kind of ideas okay but you know the cool
2167.04,2.72,thing is a demo right so let's take a
2168.56,2.64,look at a demo
2169.76,3.92,uh here hopefully you can see the
2171.2,4.32,queries um so i'll zoom in and here i
2173.68,4.08,just have a simple cars data set
2175.52,3.12,and maybe here initially i want to just
2177.76,2.64,uh
2178.64,4.0,look at you know different miles per
2180.4,6.24,gallon and uh and
2182.64,5.92,uh for a different horsepower
2186.64,3.52,and then maybe now the analysis kind of
2188.56,3.36,like we've changed this we want to see a
2190.16,4.0,different range for the horsepower
2191.92,4.0,right so this is fairly simple uh and
2194.16,3.28,what we're going to do is kind of like
2195.92,3.199,run the interface a little bit and we
2197.44,3.52,can see that it kind of like immediately
2199.119,4.401,generates like an interactive interface
2200.96,4.24,that you can use to basically filter uh
2203.52,3.76,and avoid writing queries
2205.2,4.399,but then what if i actually have kind of
2207.28,2.96,a more complicated query structure for
2209.599,2.0,example
2210.24,3.04,now i want to actually change the
2211.599,2.721,subquery here i'm going to use a very
2213.28,4.16,simple example
2214.32,4.96,for um uh for demo purposes but let's
2217.44,4.56,say i just care about uh
2219.28,3.2,cars from the usa because you know we're
2222.0,3.599,like
2222.48,5.76,super uh i'll stop there
2225.599,4.161,um and so here you know what we can see
2228.24,2.56,is that we've actually generated a weird
2229.76,2.88,interface right
2230.8,3.44,it turns out that you know like for this
2232.64,3.68,particular three queries
2234.24,4.32,you know it's actually might be best to
2236.32,3.6,just allow you to specify each of these
2238.56,3.92,queries individually
2239.92,3.76,um and maybe that's totally nonsensical
2242.48,3.359,right
2243.68,3.919,but if i now say i actually care about
2245.839,4.24,kind of like europe
2247.599,4.721,then uh then present interfaces in the
2250.079,4.081,background will crunch for a little bit
2252.32,3.6,and it'll actually generate a different
2254.16,2.56,type of interface so you still have the
2255.92,2.56,slider as
2256.72,4.08,normal right this range slider but you
2258.48,4.56,can now select either just the full cars
2260.8,3.6,or you can manipulate the sub query
2263.04,2.96,structure itself
2264.4,3.6,right so what this basically does is
2266.0,2.96,when you click on europe it switches to
2268.0,3.2,the subquery
2268.96,3.2,that it corresponds to and then
2271.2,4.8,manipulates
2272.16,3.84,this this text string here
2276.079,2.961,and then now maybe you want to do
2277.68,3.2,something else right maybe you want to
2279.04,3.92,also look at horsepower and look at the
2280.88,5.44,average miles per gallon
2282.96,5.36,from this data set grouped by horsepower
2286.32,3.92,and if you run something like this then
2288.32,3.279,precision interfaces will chug for you
2290.24,2.96,know a couple of seconds
2291.599,3.281,and what it'll end up generating is a
2293.2,4.399,multi-view visualization
2294.88,3.92,where it actually visualizes both the
2297.599,3.681,horsepower versus
2298.8,4.72,miles per gallon here right and it
2301.28,4.64,allows you to interact with it directly
2303.52,4.559,and so you can use this visualization to
2305.92,4.88,then interact and see kind of like
2308.079,3.921,what's going on uh in the initial query
2310.8,3.76,right and you can also of course
2312.0,3.119,use these other kind of controls as well
2314.56,2.88,and so
2315.119,5.041,by just writing a few queries or you can
2317.44,4.88,imagine mining some existing query log
2320.16,3.919,we can identify and fully generate a
2322.32,2.799,fully interactive multi-view
2324.079,4.0,visualization
2325.119,3.281,that you can use in lieu of programming
2328.079,3.841,right
2328.4,5.52,if it turns out to work well so that's a
2331.92,3.84,a demo of kind of like the types of
2333.92,2.56,functionality to show that it is
2335.76,2.72,possible
2336.48,3.92,to uh to do this right and the nice
2338.48,3.76,thing here is that you can have
2340.4,3.84,arbitrarily complicated queries
2342.24,3.52,as well as transformations of its
2344.24,3.359,substructures
2345.76,3.599,because what we're doing is we're just
2347.599,3.601,encoding all of this as transformations
2349.359,4.321,in these trees
2351.2,3.919,so just to kind of wrap things up i've
2353.68,3.04,talked about these three projects in
2355.119,2.561,this data visualization management
2356.72,3.119,system
2357.68,3.52,and hopefully you know i've convinced
2359.839,2.881,you that it's pretty interesting
2361.2,3.36,i want to connect it now with the rest
2362.72,4.0,of our projects to see how
2364.56,4.24,all kinds of pieces together the
2366.72,2.639,interfaces that we generate in this last
2368.8,2.24,part
2369.359,3.521,are in this internal declarative
2371.04,3.52,representation it's very similar to the
2372.88,3.28,trees and choice nodes that we saw
2374.56,3.12,earlier right because what we want to
2376.16,3.679,capture in interfaces
2377.68,4.24,is not really the front end rendering
2379.839,3.841,but the data flows right that back it
2381.92,2.72,because that's the hard part in a lot of
2383.68,4.08,these
2384.64,4.4,in modern interfaces physical
2387.76,2.88,visualization design
2389.04,3.84,is another project that i didn't talk
2390.64,4.199,about and it consumes its representation
2392.88,4.08,and its goal is to recommend a system
2394.839,3.0,architecture to optimize the
2396.96,3.36,interactions
2397.839,4.081,it's very similar to physical database
2400.32,2.799,design if you're familiar with it but
2401.92,3.36,the data structures
2403.119,3.601,are created and stored outside the
2405.28,3.92,database and we viewed
2406.72,3.28,contacting a database as a slow path the
2409.2,2.96,reason is because
2410.0,3.04,there's lots of work on new custom
2412.16,3.04,systems
2413.04,3.76,and data structures and papers out there
2415.2,4.0,today that are often
2416.8,4.08,external to the database system itself
2419.2,3.84,right and it also tries to account for
2420.88,4.479,the client and communication
2423.04,4.16,now so what this allows us do is to
2425.359,2.72,design an interface right either
2427.2,3.2,manually or
2428.079,4.481,using this you know present interfaces
2430.4,2.88,point it at a snowflake or some remote
2432.56,2.0,database
2433.28,3.6,and just fill in the rest of the
2434.56,4.48,architecture
2436.88,4.08,and and of course this can now execute
2439.04,3.52,and leverage a lot of the kind of system
2440.96,3.359,parameters that we've been developing
2442.56,4.0,such as smoke for a lineage and
2444.319,3.121,interaction or communication management
2446.56,3.36,in chameleon
2447.44,4.32,as well as kind of query optimization in
2449.92,4.159,addition because we're generating these
2451.76,3.599,interfaces we can imagine embedding
2454.079,3.121,these novel interactions and
2455.359,3.76,functionalities into the interfaces that
2457.2,3.28,we generate optimize and deploy
2459.119,2.881,and so in other words we think of
2460.48,2.32,precision interfaces and the reason i
2462.0,3.2,talk about it
2462.8,4.24,as a way of kind of like bootstrapping
2465.2,2.96,the use of a lot of these other projects
2467.04,4.0,that we have
2468.16,4.24,and that we're working on and so just if
2471.04,2.16,there's one thing you take away from
2472.4,2.48,this talk
2473.2,4.0,is that data management and
2474.88,4.64,visualization and hci
2477.2,3.84,you know are very interesting standalone
2479.52,3.28,right but really the inner
2481.04,3.76,intersection of it there's lots and lots
2482.8,2.64,of really interesting and rich research
2484.8,3.039,problems
2485.44,3.28,that can benefit both communities uh
2487.839,3.041,we've tried to
2488.72,4.08,study some of them in this dvms like
2490.88,4.08,data visualization management system
2492.8,3.12,at the levels of functionality interface
2494.96,2.96,design and
2495.92,3.28,system primitives so at this point this
2497.92,4.32,is my uh
2499.2,6.08,url and a a
2502.24,4.24,bunch of pictures of ninjas all right
2505.28,4.799,thanks everyone
2506.48,5.76,okay awesome i i will clap on behalf of
2510.079,3.121,everyone else for eugene um so we have
2512.24,2.32,time for questions if you have any
2513.2,4.56,questions for jadine please
2514.56,3.2,meet yourself and fire away
2521.68,6.08,okay so my question is about the um
2524.72,4.399,the precision interface stuff uh that
2527.76,4.4,seems super cool
2529.119,4.161,like but you're taking whatever the sql
2532.16,2.72,queries they throw at you and trying to
2533.28,2.88,turn into interface like
2534.88,3.76,and i understand there's a cost function
2536.16,4.24,and maybe i don't fully understand
2538.64,3.6,where they can handle this but like what
2540.4,2.64,happens if users like writing stupid
2542.24,2.64,queries they're like
2543.04,3.92,it's not necessarily stupid queries but
2544.88,2.88,like they're trying to figure out what
2546.96,2.72,the data
2547.76,4.16,even looks like to begin with without
2549.68,3.52,asking questions like how do you prevent
2551.92,2.88,them from polluting
2553.2,3.28,the interface and also because i can
2554.8,2.4,imagine also too what you really want to
2556.48,3.76,do
2557.2,4.32,is let a knowledgeable person write the
2560.24,3.28,sql queries
2561.52,3.599,and then the novice users don't get
2563.52,2.799,direct sql access they instead get the
2565.119,2.96,interview that's generated
2566.319,3.361,so how do you prevent it's not an
2568.079,3.121,adversarial thing as if they're trying
2569.68,2.639,to hurt you or hurt the interfaces
2571.2,3.04,they don't know what they're doing
2572.319,3.841,definitely definitely you know like
2574.24,4.32,i i think of precision interfaces as
2576.16,4.159,like the the underlying mechanism
2578.56,3.84,right it just takes a sequence of
2580.319,4.241,queries and it generates stuff
2582.4,3.12,um now there's you can imagine many ways
2584.56,3.6,of using this
2585.52,4.24,so one that i demonstrated here is a
2588.16,4.08,knowledgeable person writes perfect
2589.76,4.64,queries that are well crafted for a demo
2592.24,3.839,um but another could be you know you do
2594.4,3.439,this ad hoc analysis at the you know
2596.079,3.04,command line or using other kind of like
2597.839,2.881,complex tools
2599.119,3.361,and then once you've decided like this
2600.72,2.56,is the analysis i want to share with
2602.48,3.2,other people
2603.28,3.839,or that i think i'll do repeatedly then
2605.68,4.48,you want to basically say like
2607.119,4.881,those queries log those and generate
2610.16,3.6,something specialized
2612.0,3.119,right so that's another way that you can
2613.76,4.4,imagine using it
2615.119,4.401,um but you for for instance maybe like
2618.16,2.88,you're writing these queries and then
2619.52,3.12,you just mark the ones that you think
2621.04,3.6,are useful
2622.64,3.92,right or you could explicitly use it as
2624.64,5.36,like an interface generation tool
2626.56,5.2,by uh by directly uh writing queries
2630.0,3.119,that you know will be useful right so
2631.76,5.28,that is if you're using it
2633.119,6.081,specifically as a design tool um
2637.04,4.16,there's many kind of like limitations
2639.2,3.6,and opportunities too for example like
2641.2,3.36,we generate like one interface but
2642.8,3.6,there's actually like how much do you
2644.56,3.12,want to generalize beyond the queries
2646.4,2.88,that the user gave you
2647.68,3.84,is a parameter that you want to be able
2649.28,4.16,to control right and maybe you
2651.52,4.079,personally have like preferences on the
2653.44,3.04,layout or on the types of visualizations
2655.599,2.24,and so on
2656.48,3.599,and it turns out that like you'd like to
2657.839,3.841,be able to maybe specify that and then
2660.079,3.601,use those as kind of hard constraints
2661.68,4.48,let's say um so
2663.68,3.04,i i think of this as an optimization
2666.16,2.8,problem
2666.72,3.599,and then what you can use it for so we
2668.96,3.44,we we're kind of really like
2670.319,3.76,at the point where we think this is like
2672.4,4.24,a good formulation of the
2674.079,4.481,problem um and we're we're hoping to
2676.64,5.199,write it up like later this year yeah
2678.56,5.2,okay all right um
2681.839,3.041,and then sort of another question b is
2683.76,4.4,like
2684.88,3.28,you know sql there's
2688.319,3.28,you know you can write the same query in
2690.64,3.28,some in
2691.599,3.921,semantically the same queries in a bunch
2693.92,4.8,of ways in sql
2695.52,4.24,like does it how well it can handle that
2698.72,1.84,does it always generate the same
2699.76,3.92,interface or
2700.56,4.799,does it like if i use nested queries
2703.68,3.36,versus ctes but again
2705.359,3.361,the high level answer is the same thing
2707.04,2.72,like i asked my students
2708.72,2.879,for the first homework assignment they
2709.76,3.28,had to write queries they asked you know
2711.599,2.881,questions written in english
2713.04,3.12,and they come back with all sorts of
2714.48,3.44,crazy different ways to write it
2716.16,3.76,would your thing still generate the same
2717.92,2.88,interface or i think we probably
2719.92,4.159,generate something
2720.8,6.08,pretty um it it's like
2724.079,3.201,as you can see right where we actually
2726.88,2.479,uh
2727.28,3.68,just look at the syntax and some
2729.359,2.641,database statistics and schema
2730.96,3.28,information so we know
2732.0,3.839,nothing about the internals right we're
2734.24,4.4,not looking at the query plan or the
2735.839,4.0,logical plan or anything like that
2738.64,2.959,if you still look at the career plan
2739.839,3.201,what could you do so i think if we
2741.599,3.441,looked at the query plan it would allow
2743.04,4.319,us to do more canonicalization
2745.04,4.0,right so i think that would end up uh
2747.359,3.681,end up generating like equivalent
2749.04,3.12,interfaces if they have equivalent like
2751.04,3.279,you know the closer you are to the
2752.16,5.679,semantics the closer you are to
2754.319,5.601,kind of like canonicalizing um i i would
2757.839,3.921,say i imagine that you know like for
2759.92,2.64,like with any tool you can use it in
2761.76,3.359,like
2762.56,3.279,unintended ways and intended ways right
2765.119,2.801,um and
2765.839,3.76,and so i i would imagine that you
2767.92,2.08,probably don't want to use this as just
2769.599,1.921,like
2770.0,3.28,throw a bunch of random queries and
2771.52,4.799,generate something um
2773.28,5.36,you probably would end up using it um
2776.319,4.561,to either like mine for for example like
2778.64,4.08,you can i could imagine having like some
2780.88,3.84,interface complexity measure or some
2782.72,4.0,kind of like entropy measure
2784.72,4.0,where you can say oh this interface is
2786.72,4.399,actually reasonable
2788.72,3.359,with some criteria and then kind of like
2791.119,2.801,just uh
2792.079,3.52,scanning through like query logs and
2793.92,4.24,looking for like you know sequence
2795.599,4.72,sub sequences uh that kind of are
2798.16,3.919,self-consistent right so that's like one
2800.319,3.76,crazy thing that you can imagine doing
2802.079,4.721,but ultimately like people will use
2804.079,3.361,tools based on where it shines and
2806.8,3.76,probably
2807.44,6.08,not um uh you know
2810.56,3.36,not for the corner cases necessarily so
2813.52,3.2,um
2813.92,6.48,it probably isn't good for like uh the
2816.72,3.68,setting you described at least now
2820.56,5.279,i wonder if you take like tableau and
2823.92,3.28,you you know they you love some public
2825.839,3.52,dates that they have and then set up a
2827.2,5.919,basic visualization
2829.359,4.081,uh and then but capture the queries and
2833.119,3.281,then
2833.44,4.0,run the queries you capture yeah we've
2836.4,3.84,done that in the past
2837.44,3.28,yeah okay and it generates one of our
2840.24,3.44,goals
2840.72,4.32,is to be able to synthesize like the
2843.68,3.36,tableau
2845.04,3.519,interface right because like the primary
2847.04,3.36,like degrees of freedom
2848.559,3.201,is the the group i clause and the where
2850.4,3.6,clause yeah
2851.76,3.04,right and the project clause so um but
2854.0,2.88,you know like so
2854.8,3.44,it's really just degrees of freedom uh
2856.88,2.16,another way you can think about it right
2858.24,3.76,another
2859.04,4.4,like a baseline um would be if you if
2862.0,3.44,like how would you write in
2863.44,4.96,interfaces today you would literally
2865.44,5.84,write and and construct query strings
2868.4,3.76,yeah right and so at minimum here it
2871.28,3.12,kind of like
2872.16,4.159,generalizes sargeable things so for
2874.4,3.36,example we can generate only
2876.319,3.361,syntactically correct
2877.76,3.599,statements right and we could you can
2879.68,3.919,imagine doing some checks to make sure
2881.359,4.561,that you only execute queries
2883.599,3.361,that are not faulty right so those are
2885.92,2.8,things that you could do
2886.96,3.359,with this sort of functionality so the
2888.72,4.08,baseline i imagine is like
2890.319,4.081,the alternative to creating an interface
2892.8,3.279,which is writing a bunch of like query
2894.4,2.64,templates and then like filling in like
2896.079,5.681,query strings
2897.04,6.24,yeah yeah okay um
2901.76,3.12,i had a question about smoke too much
2903.28,4.72,pedals yeah so
2904.88,5.28,i mean smoke i guess if you i mean if
2908.0,3.28,you're running duck db
2910.16,3.76,it sort of answers my question but
2911.28,4.16,there's no there's no sort of level
2913.92,3.679,complexity of the query where you
2915.44,3.84,like when you would lose like how many
2917.599,3.76,like layers of nesting
2919.28,4.4,you know about embedded queries uh sub
2921.359,4.24,queries ctes where like you would lose
2923.68,3.919,when the information like all with feel
2925.599,2.801,accessible it's all at the physical
2927.599,3.361,level
2928.4,4.159,okay so you don't lose anything yeah
2930.96,4.639,okay
2932.559,6.241,okay cool good good okay uh any quite
2935.599,4.881,any other questions from the audience
2938.8,3.2,because eugene is a one-year-old and i'm
2940.48,2.96,a one-year-old old i'm gonna
2942.0,3.359,take care of them although he stands
2943.44,3.679,office so he doesn't have to oh i think
2945.359,4.881,the nanny leaves in ten minutes
2947.119,9.841,so okay you gotta keep going okay any
2950.24,8.8,last question for eugene
2956.96,2.08,you
