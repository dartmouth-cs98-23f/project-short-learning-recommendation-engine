second,duration,transcript
0.24,5.519,and masters from carnegie mellon and his
2.72,5.44,phd from ghand university he has over a
5.759,4.88,decade experience in computer computer
8.16,4.88,architecture both in industry as well as
10.639,4.801,academia and has received several awards
13.04,4.8,for his research in simulation sampling
15.44,5.04,and modeling today he will introduce us
17.84,4.8,to computer architecture research miss
20.48,5.2,talk make an impact how computer
22.64,5.52,architecture researchers design novel ai
25.68,5.28,accelerators processes and improved
28.16,4.399,security techniques let's warmly welcome
30.96,3.2,eric
32.559,2.881,thank you so much thanks very thanks for
34.16,5.12,the introduction
35.44,5.76,um so today what i'm going to do um
39.28,4.48,i'm going to talk a bit about what
41.2,5.039,computer architecture is uh and also
43.76,4.639,talk a little bit about uh what exactly
46.239,5.681,research is uh to me
48.399,5.441,um maybe some people are thinking about
51.92,5.04,a career in research but they don't know
53.84,4.8,all the uh what that entails so it can
56.96,2.64,be interesting to see
58.64,2.8,um
59.6,3.36,what i you know my vision of what
61.44,2.96,research is and then we'll talk a bit
62.96,3.839,about some of the work that we've been
64.4,6.16,doing in our in our lab
66.799,7.281,um one of the things that we do is we
70.56,5.76,cover a large num a large space of
74.08,3.2,um the computer architecture
76.32,3.439,i guess
77.28,4.4,research area and so if you see on the
79.759,3.841,left here we have high performance
81.68,4.32,client devices so this means your mobile
83.6,5.519,phones for example your drones
86.0,3.84,maybe building energy efficient servers
89.119,1.921,or
89.84,3.919,simulating
91.04,4.96,new future workloads for example so all
93.759,3.68,of these different pieces
96.0,2.96,fall into the umbrella of computer
97.439,4.161,architecture
98.96,4.64,but increasingly
101.6,4.559,what we've been seeing is more and more
103.6,4.479,work on processor security or security
106.159,3.441,in general especially
108.079,2.561,for all of our devices our connected
109.6,3.839,devices
110.64,4.479,and we also see
113.439,4.161,ai acceleration being extremely
115.119,4.64,important uh for example the work that
117.6,3.68,angela was talking about um she's
119.759,4.481,working on some of the algorithms and
121.28,6.08,next steps um
124.24,5.92,in the robotics area here but but using
127.36,4.32,the uh her new algorithms
130.16,6.079,and so when we want to deploy something
131.68,6.24,like that we need the hardware that can
136.239,4.801,take her algorithms
137.92,5.52,and you know so so that the robot can
141.04,5.12,execute them really quickly or
143.44,4.799,give feedback to the user quickly
146.16,4.799,so what i first wanted to do was just
148.239,4.881,give a little bit of my view on
150.959,3.601,the different stages of research
153.12,3.52,so
154.56,3.84,i define you know
156.64,3.12,there's many definitions but i define
158.4,3.68,engineering as sort of
159.76,4.0,the ability or the process of solving
162.08,3.12,complex problems
163.76,6.0,and so
165.2,6.08,in the daily work of a researcher where
169.76,4.479,you know building building things and
171.28,5.679,solving problems all the time
174.239,5.761,i define innovation as
176.959,4.081,applying the research
180.0,2.319,that
181.04,3.44,has been and
182.319,4.241,that's been occurring in academia
184.48,3.039,or or in other places
186.56,3.039,and
187.519,4.561,applying other people's research or
189.599,4.481,maybe in your own lab to solve
192.08,4.0,new engineering challenges that you have
194.08,2.96,so maybe for example
196.08,3.68,um
197.04,4.16,one of the processor designs uh is
199.76,2.479,slightly different from what you need
201.2,2.16,and so you'll
202.239,3.521,you're really interested in that
203.36,4.72,solution so you want to take that design
205.76,3.36,and maybe tweak it a little bit for your
208.08,3.04,um
209.12,3.679,for your use case
211.12,3.44,um but really
212.799,4.8,what i want to talk about today is the
214.56,4.959,research that we conduct in our lab
217.599,4.081,and you know research here at physical
219.519,4.0,computing and in u.s
221.68,3.279,and basically this is solving problems
223.519,3.36,in ways that
224.959,3.28,have never been done before
226.879,3.041,and so when you think about this
228.239,3.521,initially
229.92,4.08,you know how can we come up with this
231.76,4.08,new idea that no one's
234.0,4.0,no one's done before how's that even
235.84,4.0,possible but that's what we're doing
238.0,3.28,every day we're trying to think about
239.84,2.88,think about these things
241.28,2.4,and in fact
242.72,3.36,um
243.68,4.8,when you're re as a researcher you're
246.08,4.4,actually performing all of these tasks
248.48,3.28,um you're performing all these tasks
250.48,2.8,because
251.76,3.759,first as a researcher we're going to
253.28,5.04,build the latest state of the art
255.519,4.801,because we want to see
258.32,4.4,how that work is performing
260.32,3.52,then we potentially apply it to some new
262.72,4.24,problems
263.84,6.0,uh problems that we're interested in
266.96,4.959,but then the interesting part happens
269.84,3.76,we want to determine where the current
271.919,3.28,solutions
273.6,3.599,are unable to solve
275.199,5.041,your new problem
277.199,5.521,um where where are they lacking where is
280.24,3.76,there not enough efficiency um where
282.72,2.8,does it just not solve the problem
284.0,2.88,properly
285.52,4.0,and so now
286.88,5.2,our role as researchers is really to
289.52,4.32,work to find these novel solutions to
292.08,2.559,the problem at hand
293.84,3.359,so
294.639,4.641,you know coming up with a brand new way
297.199,4.0,um to do something that no one's really
299.28,3.12,thought of before or thought of in that
301.199,4.081,way
302.4,4.32,is really what we're working to do here
305.28,3.52,okay so now let's
306.72,4.319,switch switch
308.8,4.56,modes here and talk a little bit about
311.039,5.841,what we do in our in our group
313.36,6.08,um so what we're working on
316.88,4.08,is you can think of it as
319.44,2.72,trying to build
320.96,4.16,systems
322.16,4.56,that mimic a beehive for example we want
325.12,3.04,to build efficient
326.72,4.0,high performance
328.16,4.24,distributed and autonomous
330.72,3.52,systems
332.4,2.639,uh and you can see a beehive here as
334.24,2.32,being
335.039,3.841,you know many having many of these
336.56,4.079,qualities
338.88,4.879,and the other thing that we've noticed
340.639,6.241,in our in our work is that we're seeing
343.759,6.401,sensors and cameras being distributed
346.88,6.56,throughout all of the different layers
350.16,6.159,of you know society really today from
353.44,5.92,you know custom hardware and servers in
356.319,5.281,dedicated locations to maybe putting
359.36,4.48,um programmable
361.6,6.08,processors in lamp posts
363.84,6.88,um to help get uh your job done quicker
367.68,5.2,maybe definitely we see it in phones and
370.72,5.28,other devices um
372.88,4.879,in in uh around around everywhere
376.0,3.44,um one of the things that
377.759,4.241,we're trying to do is
379.44,5.44,think about how can we make our edge
382.0,6.4,devices also known as internet of things
384.88,6.159,or iot devices maybe these processors
388.4,4.88,in our systems how can we make them run
391.039,4.801,extremely fast
393.28,4.88,and provide these new capabilities
395.84,4.639,um like these new robots that
398.16,4.72,were talked about last
400.479,5.041,uh last presentation so how do we how do
402.88,6.48,we accomplish that
405.52,5.36,um and this is a
409.36,4.48,you know an example
410.88,6.08,of the kinds of edge devices or iot
413.84,4.479,devices that we want to be able to build
416.96,4.32,right we want to
418.319,5.28,uh in this case it's a swan this isn't
421.28,3.68,from our group but this is from uh ece
423.599,4.401,and nus
424.96,5.2,and what they were able to do was you
428.0,6.56,know have this autonomous platform
430.16,7.28,that would go and um in the uh in the
434.56,5.28,water and it would you know it could um
437.44,5.039,use its sensors to see the status
439.84,4.0,of of the of the water and basically
442.479,3.28,what's happening is now you can think of
443.84,3.52,this as one of the you know one of those
445.759,3.761,devices and it's doing
447.36,4.239,computation there and it's communicating
449.52,3.2,with other devices and things like that
451.599,4.241,so this is the kind of thing that we
452.72,5.28,want to enable with our work
455.84,4.799,one of the issues with
458.0,4.4,computers today is that they get hot
460.639,4.56,extremely hot
462.4,4.96,and really what one of the things to
465.199,3.12,think about is if we can
467.36,2.559,make
468.319,3.6,computing
469.919,3.761,more energy efficient
471.919,3.28,then maybe
473.68,4.4,we can
475.199,6.481,bridge the gap to a more sustainable
478.08,3.6,more sustainable solutions
482.16,3.28,data centers themselves is one of this
483.919,3.84,part of something called the iot
485.44,4.8,hierarchy basically of all of these
487.759,4.641,different components in the systems uh
490.24,4.399,all of these different components uh in
492.4,4.079,our in our environment today
494.639,3.921,uh and you have maybe your cameras and
496.479,4.0,sensors and your gateway devices and
498.56,3.68,data center servers but each each one of
500.479,3.84,these things has different performance
502.24,4.88,which is these mips numbers on the left
504.319,4.801,but also has different power output
507.12,3.68,and you need to be able to
509.12,3.12,um
510.8,3.52,when you're when you're doing compute
512.24,3.12,for example on your your phone
514.32,3.279,you know you want to make sure that your
515.36,4.479,phone's not getting too hot
517.599,4.641,and if it does if you don't you don't
519.839,4.401,want to break your phone right so uh we
522.24,3.44,want to make sure that the processors
524.24,3.2,are
525.68,4.88,able to provide a great great
527.44,4.399,capabilities but also be able to
530.56,3.04,um
531.839,3.201,you know do that within reasonable
533.6,3.359,reason
535.04,3.52,constraints
536.959,4.161,so now i'm going to talk a little bit
538.56,4.399,more about computer architecture some
541.12,3.52,computer architecture terms
542.959,3.921,um
544.64,4.08,what's happening today it's really we're
546.88,2.88,really at an interesting time
548.72,2.48,where
549.76,4.0,there are these rules there are these
551.2,4.639,laws uh or guidelines
553.76,5.28,one's called denard scaling on the left
555.839,5.361,one on the right uh is moore's law maybe
559.04,4.4,people might have heard of these two
561.2,5.04,sort of guidelines or laws or rules
563.44,4.16,but what's happening is denard scaling
566.24,2.8,over the years
567.6,3.66,have led us
569.04,3.44,to
571.26,4.019,[Music]
572.48,4.88,do more and more and more with our
575.279,3.281,machines with our laptops with our
577.36,3.12,phones
578.56,4.0,and we could you know activate more of
580.48,4.08,the transistors and do more all the same
582.56,3.44,time and this led to great performance
584.56,3.04,improvements
586.0,4.64,at the same time
587.6,5.28,we had the shrinking of transistors
590.64,4.4,which also helped us to pack more in the
592.88,4.48,same space and this actually we could do
595.04,5.76,that at a lower cost so now all of a
597.36,5.76,sudden we had more transistors smaller
600.8,4.159,um they don't get as hot and we have a
603.12,3.52,really low cost so that's great
604.959,4.241,everything's great there
606.64,5.52,um but it turns out that these
609.2,3.84,rules or these guidelines have really
612.16,2.32,not
613.04,3.68,um
614.48,3.919,you know at this point they're
616.72,2.96,not the same as they used to be we're
618.399,2.88,not getting
619.68,4.399,more affordable
621.279,4.641,transistors we're not getting we're not
624.079,3.281,no longer able to turn on all those
625.92,3.599,transistors and do all those things that
627.36,4.08,we want to do with them
629.519,3.681,uh and so what you can see here in the
631.44,3.68,lower right hand corner
633.2,4.16,um you know the numbers aren't as
635.12,4.08,important as the trend here so over the
637.36,3.36,years
639.2,3.12,we would have
640.72,4.559,more and more
642.32,4.639,cost reductions occurring with different
645.279,2.961,technology advances
646.959,2.88,but now
648.24,4.08,using the latest technology nodes
649.839,4.721,actually cost more than before
652.32,4.32,so this is a challenge uh for computer
654.56,4.8,architects how do we build new machines
656.64,4.4,that do more with less
659.36,4.32,and on the left it's a slightly
661.04,3.44,complicated diagram but the point is the
663.68,2.399,red
664.48,4.16,arrows are showing
666.079,5.281,that things have really dropped off
668.64,4.639,uh performance which is the blue
671.36,4.719,set of dots
673.279,4.481,and power which is the red triangles
676.079,3.2,they've sort of leveled off for our
677.76,3.199,common devices
679.279,4.0,so what does that mean how are we
680.959,3.361,supposed to continue to
683.279,3.68,improve
684.32,4.8,uh and do more with what we have
686.959,4.481,and so one of the examples of that is to
689.12,3.44,think differently and to think about you
691.44,2.88,know uh
692.56,3.2,the systems in a new way and i'll
694.32,3.519,explain a little bit about how we did
695.76,3.84,that in our research but we we developed
697.839,3.361,this new processor called core called
699.6,3.679,the load slice core
701.2,3.28,and what this allowed us to do was
703.279,2.321,improve
704.48,2.88,um
705.6,3.44,this metric called performance per watt
707.36,2.4,per dollar but basically what this says
709.04,1.84,is
709.76,2.8,you can
710.88,4.24,increase performance and do it in an
712.56,4.88,energy efficient and power efficient way
715.12,4.08,so by thinking about things in new ways
717.44,3.28,we're hoping that we can overcome some
719.2,3.6,of these limitations with transistor
720.72,3.919,costs going on
722.8,3.279,okay so i just wanted to give a little
724.639,2.64,bit of an overview
726.079,3.361,of
727.279,5.281,the
729.44,6.0,space at which we work in
732.56,4.079,and so there's always this foundation
735.44,3.36,um
736.639,3.841,that computer architects or any field
738.8,2.64,for that matter work with
740.48,4.08,and
741.44,5.36,in our work we are simulating
744.56,4.64,the processors of tomorrow but we
746.8,4.64,simulate them today on today's machines
749.2,4.4,and to do that we use tools like our
751.44,4.639,sniper simulator or other
753.6,4.479,models and analytical models
756.079,4.32,and then what we can do is use those
758.079,3.681,tools to build secure and efficient
760.399,3.281,processors
761.76,4.72,um and then put those processors and
763.68,5.92,accelerators together into platforms
766.48,5.2,which can then run your application
769.6,3.039,and so in this talk we're going to focus
771.68,2.56,on
772.639,3.841,a few of the different
774.24,3.68,types of
776.48,3.2,ideas in
777.92,4.4,improving the efficiency of your
779.68,2.64,processors
782.48,1.68,okay
783.279,2.081,so
784.16,3.44,one of the things that was really
785.36,3.52,interesting to me is when i started it
787.6,2.88,in us
788.88,4.959,i
790.48,4.799,was looking around we're bringing in phd
793.839,3.201,students to help on our projects and
795.279,3.601,also working with undergraduates and
797.04,4.08,math students
798.88,5.6,and
801.12,5.92,the project i'm about to talk about is a
804.48,2.56,um
807.44,4.639,ai accelerator
809.12,5.68,but the idea at least the beginning of
812.079,4.721,the idea was started and developed
814.8,3.039,by two undergraduate students here at
816.8,2.88,nus
817.839,4.8,and now we've taken this idea and we've
819.68,4.08,expanded it uh uh and and it's grown a
822.639,3.041,bit to
823.76,3.92,uh encompass uh
825.68,4.0,uh and and now we're working with number
827.68,2.959,of phd students and postdocs on this
829.68,3.76,project
830.639,4.401,um but the idea here is that
833.44,4.0,you know these ideas
835.04,4.08,it's really about your motivation your
837.44,3.6,interest in the topics
839.12,4.079,and these students were extremely
841.04,3.44,interested in and they they really
843.199,2.88,wanted to solve some interesting
844.48,3.44,problems and i said well let's see if we
846.079,3.76,can do this and this is the result of
847.92,3.919,their work
849.839,3.68,so if you look at
851.839,3.521,hardware accelerators something on the
853.519,4.481,left here is called the tpu
855.36,4.479,which is a google
858.0,3.519,ai accelerator
859.839,4.081,and then you look at the amount of power
861.519,4.56,it dissipates at 75 watts
863.92,4.4,now on the right you have a human brain
866.079,5.601,which displays 20 watts now the
868.32,4.8,capabilities of the tpu on the left
871.68,3.839,right are not
873.12,4.64,as as good as the capabilities of the
875.519,4.801,human brain right we're trying to get
877.76,4.4,there with new ai techniques but the the
880.32,4.4,point is that we're not there yet right
882.16,4.08,we do not we're unable to achieve all
884.72,4.64,the capabilities what we can do with the
886.24,5.2,human brain um but we still take a lot
889.36,4.719,more power to do that
891.44,3.839,and so one of the questions is can we
894.079,2.56,try to
895.279,4.481,solve
896.639,6.801,some of these open problems in ai
899.76,7.04,and with a much more efficient platform
903.44,4.639,um for those who are familiar with ai or
906.8,2.88,machine learning
908.079,4.641,um you might have seen something called
909.68,4.159,dense uh deep neural networks or dnns
912.72,2.16,and so on the left we have your
913.839,2.881,traditional
914.88,4.72,uh a ns which form
916.72,4.64,uh your your dnn components
919.6,3.039,now what we just we were looking at in
921.36,3.36,this work is something called
922.639,4.56,neuromorphic computing also known as
924.72,5.359,spiking neural networks on the right
927.199,4.401,and what we found is that it's possible
930.079,4.081,to
931.6,6.4,improve efficiency
934.16,7.679,by looking um at
938.0,3.839,how the system runs
942.16,4.72,at run time when you're using the the
944.079,5.44,hardware so what this means is
946.88,2.639,you might be
950.399,4.961,deploying a system
952.639,3.921,and typically you might want to when you
955.36,3.68,compute your
956.56,4.8,deep neural network answer
959.04,3.919,it might do lots of computations and the
961.36,3.12,point here is if you looked at the
962.959,4.481,network in a new way
964.48,4.58,maybe we can do many fewer
967.44,3.28,uh many fewer
969.06,3.899,[Music]
970.72,3.359,operations which means more efficient
972.959,3.521,result
974.079,4.241,and if we do that then we can
976.48,3.919,improve efficiency potentially improve
978.32,3.92,performance
980.399,3.601,i'm not going to go into details of what
982.24,3.839,spiking neural networks are and the
984.0,4.0,different types but what i do want to
986.079,3.44,say is that
988.0,4.639,um if you look at this graph on the
989.519,4.721,right uh you can see far on the right
992.639,2.64,there's this a n
994.24,3.279,marker
995.279,3.761,and it's a black star on the lower right
997.519,3.68,hand corner
999.04,4.239,um and so what's happening here is you
1001.199,4.56,can see the x-axis
1003.279,4.081,in this case is mega ops which is
1005.759,3.841,millions of operations per second but
1007.36,4.32,let's just call this compute power
1009.6,4.4,and so if you look at this black star
1011.68,4.24,for the a n you can see the number the
1014.0,3.44,amount of compute you have to do is just
1015.92,3.52,huge
1017.44,4.079,now in the lower left hand corner what
1019.44,3.68,you see with the uh this box here on the
1021.519,4.4,left the green and the blue and the red
1023.12,4.559,are some neuromorphic techniques
1025.919,2.721,that we looked at implementing and we
1027.679,4.321,were able to implement with our
1028.64,6.159,accelerator and they do a significantly
1032.0,5.439,lower number of operations
1034.799,4.961,but they're still able to have a fairly
1037.439,4.4,good accuracy result and so but you know
1039.76,4.24,you look at this and you say
1041.839,4.08,maybe we can maybe we can take advantage
1044.0,3.839,of this uh by building some hardware to
1045.919,4.64,do that and so that's what we did we
1047.839,5.041,built an accelerator an ai accelerator
1050.559,3.761,called yoso you only spike once and that
1052.88,2.72,has to do with the
1054.32,2.479,neuromorphic technique that we are
1055.6,3.439,accelerating
1056.799,4.481,uh it consists of a number of pes or
1059.039,4.161,processing elements and each processing
1061.28,3.36,element has some memory and processing
1063.2,4.64,core
1064.64,5.039,and inside the core um you access memory
1067.84,3.12,and you do the compute and then when you
1069.679,3.041,when you're done you store the result
1070.96,2.8,back
1072.72,2.4,um
1073.76,3.2,there's a couple of different things
1075.12,4.559,that we were enhancing i'm not going to
1076.96,4.32,go into details there but what what we
1079.679,3.761,were really surprised or at least really
1081.28,3.12,happy about was that
1083.44,3.04,given
1084.4,4.0,the accuracy we're able to show the
1086.48,3.36,energy consumption of our
1088.4,3.6,um
1089.84,3.76,the power consumption of our hardware is
1092.0,2.64,extremely low
1093.6,3.04,and so
1094.64,3.44,you know when we what we did was we we
1096.64,2.159,saw
1098.08,2.719,the
1098.799,3.361,potential for innovation
1100.799,3.281,and then we thought to ourselves can we
1102.16,4.16,solve this problem can we
1104.08,5.68,invent something new
1106.32,5.52,that allows us to take advantage of this
1109.76,4.96,and that's when we designed a new piece
1111.84,5.12,of hardware and we're able to
1114.72,3.839,um
1116.96,2.88,build build this new accelerator that
1118.559,3.681,can
1119.84,5.76,do a better job with respect to energy
1122.24,3.36,efficiency computer related work
1125.679,5.201,um so i just want to switch gears a
1128.4,5.68,little bit here so i started with one
1130.88,4.88,topic which was ai accelerators
1134.08,4.24,but processors are also extremely
1135.76,4.72,important for our group um the reason is
1138.32,4.16,because cpus
1140.48,4.8,form the basis of just about all
1142.48,5.6,computers that we use today
1145.28,4.24,we have a little schematic here of a cpu
1148.08,3.599,and the kinds of components that it's
1149.52,3.12,connected to the tram
1151.679,4.561,network
1152.64,5.44,and storage which maybe is disk or ssds
1156.24,3.92,uh typically our cpu is thought of as
1158.08,3.52,having large compute but
1160.16,4.879,tiny access
1161.6,4.88,to dram and networking storage
1165.039,4.0,and so what we've been doing over the
1166.48,4.24,years is we've been growing the cpu do
1169.039,3.76,more let's do more
1170.72,4.319,let's add more caches and add more
1172.799,4.161,techniques that
1175.039,4.88,in the end turned out to be
1176.96,4.959,very energy inefficient
1179.919,3.441,and so what we wanted to do was we
1181.919,3.12,wanted to say well maybe we can look at
1183.36,3.439,this in a new way
1185.039,3.52,and so this comes down to the research
1186.799,3.521,that we were doing we consult ourselves
1188.559,2.801,well how could we potentially solve this
1190.32,2.719,problem
1191.36,3.12,there's something called memory level
1193.039,3.52,parallelism
1194.48,4.0,and up to the point uh
1196.559,3.681,before we did this work memory level
1198.48,4.4,parallelism was
1200.24,4.88,uh investigated but people really didn't
1202.88,4.0,build processors that targeted
1205.12,3.679,memory level parallelism
1206.88,3.6,which and i'll explain what that means
1208.799,2.801,so memory level parallelism is the
1210.48,3.84,ability
1211.6,4.959,to talk to dram for example
1214.32,4.239,and instead of just requesting one
1216.559,4.24,piece of data at a time
1218.559,2.961,maybe you can request four
1220.799,1.841,or
1221.52,3.92,20
1222.64,4.88,or 100 items at a time
1225.44,4.8,uh so the point is that
1227.52,2.72,if we can
1230.32,4.88,the time it takes to access memory from
1232.159,5.601,dram is extremely long but if we can
1235.2,4.32,look at it and as a different problem
1237.76,4.0,and we can say well maybe we can do a
1239.52,4.88,lot of access in parallel
1241.76,5.12,maybe what this allows us to do is build
1244.4,4.32,a processor that in the end will be much
1246.88,2.88,more efficient
1248.72,2.16,and so
1249.76,2.399,um
1250.88,2.64,what we've been doing is we've been
1252.159,3.361,trying to
1253.52,4.159,take these in-order cores and make them
1255.52,4.639,higher performance and take out of order
1257.679,5.041,cores and and bring their efficiency and
1260.159,4.161,increase their efficiency um
1262.72,3.6,and that's what these two green arrows
1264.32,4.4,are showing basically can we can we
1266.32,4.8,improve the efficiency and performance
1268.72,5.199,of these processors
1271.12,4.559,um and we've we've been able to do that
1273.919,4.321,so one one of our processors the load
1275.679,5.201,slice core which i mentioned before
1278.24,4.799,was able to improve the energy
1280.88,3.2,efficiency and performance of an order
1283.039,2.64,design
1284.08,3.36,and then we've also been looking at out
1285.679,3.921,of order commit processors and high
1287.44,3.84,performance mlp processors
1289.6,3.12,but the idea
1291.28,3.759,started from
1292.72,3.92,its memory level parallelism idea
1295.039,3.281,and then we started looking at different
1296.64,3.519,areas and
1298.32,3.04,you know connected them and said well
1300.159,2.161,how can we
1301.36,2.08,you know
1302.32,3.68,how can we
1303.44,4.0,exploit this mlp to
1306.0,4.0,do a better job
1307.44,4.96,and that's what led us to these works
1310.0,3.76,um i think in the interest of time i'm
1312.4,4.08,going to skip
1313.76,6.48,some of these details but suffice is to
1316.48,5.439,say we built a learning mechanism inside
1320.24,3.52,the core to identify the key
1321.919,3.921,instructions and route them to the
1323.76,3.36,proper locations and by doing that we're
1325.84,3.36,able to improve
1327.12,4.32,the efficiency of the system not to skip
1329.2,4.08,this
1331.44,5.599,these slides
1333.28,5.92,uh for now but uh in the end um this new
1337.039,5.281,processor uh the performance was
1339.2,4.8,improved by 53 and we were within 25 of
1342.32,2.64,the performance of an out of order core
1344.0,3.2,which is
1344.96,3.76,a much faster but much more inefficient
1347.2,3.28,processor
1348.72,4.079,okay and the last topic just one last
1350.48,3.52,slide here um i wanted to talk a little
1352.799,2.721,bit about security so i mentioned
1354.0,4.0,security in the title
1355.52,4.639,and i wanted to mention a new a brand
1358.0,3.76,new publication that are recently
1360.159,4.321,released on archive
1361.76,4.48,um which is a sort of an open area where
1364.48,4.4,we release new ideas that haven't
1366.24,6.799,formally been published yet
1368.88,7.279,and the idea that we looked at with this
1373.039,4.321,security uh research was
1376.159,3.281,in the past
1377.36,4.319,there have been
1379.44,4.32,these very popular security
1381.679,4.081,well-known security exploits called
1383.76,4.159,spectre and meltdown
1385.76,4.32,and those use something in the processor
1387.919,6.081,called the branch predictor
1390.08,6.32,in order to leak as as one component to
1394.0,4.4,leak your private information so maybe
1396.4,4.88,your private key
1398.4,7.6,that keeps your computer secure
1401.28,4.72,so what we found was that by
1407.2,3.76,instead of the branch predictor we could
1409.12,3.52,use other structures
1410.96,3.52,in the processor
1412.64,3.919,that most people
1414.48,3.36,most processors have but aren't
1416.559,3.6,protected
1417.84,3.92,and so what we can do and you can see
1420.159,2.561,this with the
1421.76,3.919,um
1422.72,6.88,green the blue and green uh dots on this
1425.679,6.0,diagram but basically we're able to tell
1429.6,3.92,you know from uh we're able to basically
1431.679,4.641,leak the data
1433.52,3.84,from one process to another using the
1436.32,3.12,hardware
1437.36,3.52,where uh in the past
1439.44,3.119,um
1440.88,3.44,you know people when they're running
1442.559,3.761,applications they wouldn't expect their
1444.32,4.8,private data to be leaked and so this
1446.32,4.64,was a really interesting uh result
1449.12,4.4,and um
1450.96,5.839,you know this is an example of looking
1453.52,6.8,at things in a new way to try to see
1456.799,6.081,can we um
1460.32,4.4,in this case it's can we try to
1462.88,4.399,find issues
1464.72,4.16,with current hardware current processors
1467.279,4.4,um and then
1468.88,3.76,potentially provide solutions so that we
1471.679,3.12,make
1472.64,4.88,our processors and our
1474.799,4.961,hardware more secure
1477.52,5.68,okay so with that um
1479.76,3.44,i'll be glad to take any questions
1485.2,4.8,thank you professor carlson um
1487.76,3.519,now the floor is open for questions you
1490.0,4.64,can either
1491.279,5.28,uh type your questions on q and a or you
1494.64,5.639,can raise your hands and we will mute
1496.559,3.72,you to ask questions
1504.72,4.0,maybe i should i will start with a very
1507.76,2.399,um
1508.72,4.12,simple question
1510.159,4.321,so you were saying that
1512.84,3.8,um
1514.48,4.88,nowadays we are
1516.64,5.68,we are nearly at our limits and
1519.36,8.36,i hear that uh you are able to kind of
1522.32,5.4,use whatever you you um
