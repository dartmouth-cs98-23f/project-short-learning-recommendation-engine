okay so the last talk is a Ramona now a
moneys currently professor at the
weights money institute he received his
PhD in 1989 from the University of
California at Berkeley and the
interesting fact is that it was done
under the supervision of mono and bloom
he works in various fields of computer
science mainly the foundation of
cryptography and especially notable for
creating non-malay above cryptography
visual cryptography with adi shamir and
suggesting various methods for verifying
that users for computer systems are
human he was named an IAC are a fellow
in 2008 for fundamental contributions to
the scientific foundation of
cryptography and for sustained
educational leadership in cryptology so
this is what I found in Wikipedia thank
you so thank you for the invitation and
for the opportunity to speak in such a a
company so I'll talk as you heard i'll
talk about cryptography data structures
and match made in heaven so cryptography
is a very old subject but it really
started as an academic subject only in
the mid seventies of course we keep
papers of difficult and the RSA a insane
and I also started around that time is
like the earlier is computational
complexity theory and there is a very
tight relationship between the two
the key idea of the cryptography you can
say to use the intricate ability of some
problems to the adventure your advantage
the bad news of one area of the good
news of the other he really in order to
construct securities in based of that
and this theme there's been a great
great results the areas of complexity
and the cryptography is really
stimulated each other and there just to
mention the whole PCP a sprung from
started from a very from a question of
what happens when you want to get zero
knowledge without any conclusion you
won't have perfect zero knowledge
without any computational assumptions
and key results in one area and were
applied in the other in that played
against traffic old message in your
paper which is already pretty old by now
paper did an address which he gave to
Fox in Fox 97 to had the racer in the
subtitle of cryptography and complexity
match made in heaven so in homage to
this title we'll talk about a data
structure but before that news Shafie
Goldwasser and silver Macaulay are they
Turing Award winners of this year it was
just announced anyway and anyway the
fishes of this talk is that actually
cryptography data structures the area of
data structures are quite familiar they
really have enjoyed a very fertile a
connection now but I'm unlike the
computation completing the connection
with complexity which was usually
celebrated here are some how people hear
it and did not celebrate the fact that
you know i'm using this end and vice
versa and there are actually many
examples and then what I'll do in this
talk is give you some examples which of
course are very biased sample of a of
such developments
so let's start with the first example
it's not the first example that exists
but the first example I want to talk
about that's hellmann's time-space
trade-offs so a helmet a when other
another important development in the
mid-70s in terms of cryptography in
addition to the invention of public key
cryptography was the fact the
introduction of the d/s the data
encryption standard because there was
something that the standard of
encryption of shared key encryption that
was considered good and suddenly you
know this problem well not clear whether
it was all but at least was it something
to talk about however what was the
problem to have very short key 56 bits
today it's definitely very short but
even back then it sounded like
borderline in helmand but distilled to
256 if you want to do exhaustive search
who is a pretty high number so what
Hellman pointed out is that actually you
can do much better then spend two to the
56 all over again for each each time you
want to break a d/s and he asked the
question suppose I have a function and I
want to invert it how costly so if you
aware your allow pre-processing so your
pre processing and then you you're
looking at how the cost of the vision of
any additional breaking so if for
instance if you build a table a large
inversion table then of course it's a
roughly order 12 to invert it depending
how costly it is to access the table but
that requires a huge amount of storage
so we probably want to have less storage
and are willing to work a little anymore
and so we we have some sort of limited
space so then we are asking what is the
best we can do in terms of time with you
stay so what Hellman showed a 19 a key
is if you want to invert a permutation
then you need storage s and time T 3
times s which is the N and if you want
to invert functions it three times a
squared
n squared so we'll think of T&S being
let's say n to the two-thirds and your
capillaries their size is two to the
little and that is the capital n is the
size of their of the universe the number
of a total number of keys that you can
have so how did he work how did that
work so let's say we have a permutation
so then we have a permutation pile only
hint how you do it for a permutation so
we have a permutation pie you can let's
for simplicity also think of it as one
cyclic permutation doesn't really matter
and so you can definitely go forward
that's the advantage that you have you
can go forward so in order to invert the
permutation you can go all the way
around you can apply to itself many many
cups so if for instance instead of being
a cyclic permutation it had only small
cycles to do it would be very easy to
invert the problem tation so the hardest
case seems to be when there is a cyclic
permutation so what did he suggest he
suggested adding shortcuts ok so you add
every T steps you add a shortcut ok so
the shortcut tells you if you get him to
go back a n minus the x in order to
instead of going all this way this will
think this would be a shortcut so this
means that when you are going forward
you only have to get to these special
points so that you can make a shortcut
and then the time to invert would be by
going forward in using the shortcuts the
time to invert would only be T so what
you get is this sort of expression and
this is true for permutations for
functions things are a bit more complex
and we we have the worst times i'm
actually it's a very interesting open
problem to just to try to improve these
things there are some lower bound in
some models in
is these lower bounds today there is a
slightly different method the rainbow
rainbow table method which is very
popular but these are still very this is
that these things are the most probably
the most important thing a time memory
trade-offs style if you want to have
online real-time style is a attacks and
crypto system then probably you'll be
using something of that nature okay so
this is hellmann's the time-space
trade-offs what is what is the
connection to data structures okay so
let's talk about the problem suppose
that you have a bunch of books that you
more many books and you want to arrange
them on your on your shelf so that
you'll be able to search under both
under title and under offer so you don't
have any this is sort of an implicit
date it's an implicit data structure you
don't have any other storage except
their items themselves and you can
already access them using a comparisons
you cannot pay we're not talking about
Ashley at this point later on we'll talk
a lot about as you so we can only
compare to you can compare the author
and you see whether it's larger or
smaller you can compare the title so
definitely the best you can hope for is
order log in here and the issue is can
you arrange so of course if you want to
just offer it would be very easy if you
want to just titled it would be very
easy but the question is can you do both
and one of my first papers while I was
minerals Bradley student with fear and
super-g much meat email encino we we
came up with an order log in solution
and i'm not going to show it and
actually it's true from many of the
results just try to show the idea the
relationship between the crypto and
their data structure anyway so we came
up with an IDF so first you you split
the records into katie's if you have k
not just two but you have k
types of a split the records in 2k keys
in 2k sets and what you want is that
each set would be a nearly perfect
sample for that key so you split
according to let say title is some of
the books are considered title books
some of the books are considered off the
books and it's a very good sample so if
you know where where you the book is if
you say book if your book is not the
book you're looking for is not according
to it was not chosen as part of the
title bouquet according to the title
step you'll know what where it should
have been to within one or two locations
and you can do such a you can do such a
partitioning using whole sphere anyway
so now the problem is of course you do
you know roughly where it should be but
it's not sitting in the right place so
what you have among the other books you
have some sort of permutation of the
original layer order so you want to
search in this permutation hey now you
don't have you know you don't know
things exactly but that's okay you can
actually add a few bits and then show
how to store them so I'm not going to
talk about all these things at all I'll
just mention that you still have you
have you have the problem that you have
a permutation where where the books say
went with if your book was not in the
thing you are looking for is not in
there if you're looking for a book by
title in the book that you're looking
for is actually the author section so
it's it's a order in some since um
according to some permutation of what it
should be and you can actually compute
the permutation you can commute the
forward presentation and you're trying
to invert it and what did we use we use
this sort of whatever Hellman had
exactly the helmet Drake except that T
here should be constant and we we were
able to store a like some small constant
some small constant times and pointers
and then
then store them in then show how to so
we have exactly we could use exactly the
idea of fair helmet and come up with a
solution which took only where each
computer will reach forward computation
with its backward computation where it
could be done in actually long time so
we could search for the book all
together in a long time so here we see
an example an idea that came up in the
crypt of literature shona in the a data
structure one okay so let's move on and
ask so if we look back at hellmann's
work kiss his analysis the way he wrote
it assumed a lot of randomness on the
function the function that you are
trying to invert he assumed was very
random and even if you take various
projections of it it it still remains
random and it's better to to work in a
worst-case style i have a function f
maybe i am assuming some computer
tutorial properties that it's say either
permutation or it doesn't have too many
a doesn't have too high integrate things
like that but we don't want to assume
that we're trying to invert a random
function because it's not it's a
function related to das it's not a
random function so and what the question
was whether you can come up with them
with an analysis of hell hellmann's work
without assuming anything about it and
would work with amis fear we have a way
of composing of the function if with a
que ways independent a function G and
and of course now if you have to if you
want to invert f composed with G it's
right you'll get from it something very
similar to inverting if I mean in terms
of if you can invert F composed with G
you'll also be able to invert if and the
problem is that k now each time to
evaluate the function you also have to
value
gee okay what should kb k should be
roughly I mean I didn't show you the
actual helmand construction but Kate but
k is going to be pretty large it's going
to be something like a capital N to the
one third so it's going to be very large
value and we want to for each time we
have to spend if we'll have if you look
at the sort of traditional construction
of K words independence using
polynomials or whatever then that's very
expensive then each time you want to
evaluate the function you have to invest
time into the one third so we were faced
with this problem and I'm not going to
tell you how we solve it back then but
actually today there is a I will hint of
how you can solve it today today there
with relationship to data structures
there are actually solutions of K ways
independent functions that can be
evaluated very quickly in order one okay
so so let's switch to the dynamic
dictionary to Hashem problems so we we
have there and we want to come up with a
data structure for representing a set of
words s from universe you and I guess
the red you don't seem either or
something anyway so the size of the set
s will denote with red line and the size
of the universe is little you and we
want to be able to do look up in insert
and delete and the performance we we
look will consider look up time update
time and the space the amount of space
and so we want to actually constant time
operation and minimal space consumption
this is of course a very problem that's
been investigated for guess the first
analysis interesting analysis is clear
fluids of linear probing breaking news
but still the trade-offs are not
faithfully
this is closed from that time to the
time aerobic which i think in homes they
had a you mentioned the canoe from 66
but you had a picture of him from much
later and is closer in spirit anyway and
so in work with my students you are
between and Gil Segev we came up with a
solution with for any polynomial number
of sequence and look up insert and
delete all operations take a constant
time and the probability is over the
initial randomness and it this segment
is true that it all operations take
constant time so fix concern with some
probability 1 minus 1 over palm so again
I'm not going to show you the whole
thing I'm going to show you a few ideas
which are related to crypto so you so
first you may ask why are we so
interested in worst case and not
amortized or whatever so first if you
are have some sort of you're using it in
heart the hard way hardware type
environment it may be very important
because you're building it you don't
want to waste too much a you don't want
to waste the amount of hardware you need
to invest is connected to the worst case
so you don't want that another reason is
comes actually from cryptography suppose
you you somebody is trying to to perform
a timing attack on you so you have
clocked adversaries they look how long
it takes you to respond and act
accordingly so they can learn your
internal randomness ok so you they can
actually learn your return randomness
and reconstruct the hash function from
we saying which operations take a long
time in which operations take little chi
and there and therefore they can find
bad inputs so if you're in any sort of
adversarial environment it's bad to use
such such hash functions in general even
if you're less more benign environment
if it somehow inside an operating
according to the time it takes to
perform the operations Lee the next
operation is affected something like
that you're losing the fact that the
assumption that the adversary is
oblivious to your randomness so we want
to have the worst case type things all
operations take exactly the same okay so
in terms of space we may want now really
the minimal amount of space so you want
if you're storing every element out of
the universe of size you you don't see
some universe which I guess we can't see
so there is a universal size you you'll
have a set of size and infirm a few are
actually storing each element explicitly
it takes you and log you a bits but you
need we need less than that we need just
a log you choose n bits to represent the
set sign another out of you so you are
wasting roughly n log n bits in when you
is small when you is small polynomial
event then this will be significant and
for instance if you're doing bloom
filters so bloom filter not the blunt
filters you're doing a blood trail can
show you want to solve the proximate set
menu problem and so you have a subset
again same type of subset we don't see
the universe due to coloring problems
and so you want to say yes on elements
in the set you want to say no and I
edelman sudden the set but you're
willing to suffer some my error of gamma
if it's not in the same and here you can
show if gamma is a sub constant amount
of space you need is M blog 1 over gamma
we don't know exactly for the dynamic
case we don't know exactly when the set
can change dynamically
you don't know exactly how it behaves
when gamma is a constant but certainly
when when gamma sub constant and this
becomes very significant and blog a 1
over gamma so this is the famous say
they bloom data structure from 1970
solves this problem to a certain extent
and but we can actually use dictionaries
to solve it and get a slightly better
solution at least again when the case
for a gala which is constant simply by
hashing hashing too small said hashing
to a set of size n over gamma okay so
you started from University you actually
set of size n over gamma and you to
insert X you need to store G of X and
instead of a storing extra story Reggie
of x + m in order to check whether it's
in you check whether G of X is in the
dictionary so now the problem that you
have is during your universe is of size
n over gamma and you don't have enough
bits to to represent each element
separately that would be very way from
you'll be getting something which is you
wanna get getting such an expression the
other hand if you have an optimal
solution into optimal in terms of memory
to the dictionary problem then you would
have an expression like in may log 1
over gamma so just for comparison with a
original bloom filter that will be kind
another constant times they lost a loved
one of the blog eat a so so what's the
source of waste why how can you waste
space in the hash table what is if it's
not full and apparel is not full so
there are empty entries are really
wasted we're not going out going to
describe how we solve that problem the
other is you're using too much in order
to represent an element it's really if I
you're using to represent an element log
u bits but really there there is already
if I'm searching for an element in
location I there is a lot of information
on the fact that I mean location lie it
means that somehow the element led me to
location I so don't really need to store
all these things ok and we're going to
use this idea we're going to use the
idea that you we can get rid of some of
these days so hey I think for some some
of you will if you start the analogy if
I'm if I'm up if if I'm standing and the
fridges open it means that I'm hungry so
I don't need to remember that I'm hungry
right i can throw away this baby come
hungry so this is the same thing if i'm
looking at location if I i will music
will be using our hash functions will be
a permutation and we'll be using and a
PI of X is the new identity of things
and the prefix of the
the new name is going to be the identity
of the cell of where we're going to
search for me okay so when the cell is
being probed we know the prefix there
isn't any point in remembering you so
essentially and so if we're storing
elements and benzene let's say then
we're searching inside the bills it is
the second level level they're really
there isn't any point in storing all of
this information inside the bin instead
we can get rid of that part that tells
us that this is a lettuce to want to go
into point so too so we can store less
information M so let me talk about
cuckoo hashing because that will be
important both for this and for for the
next day application SoCo caching is a
wonderful a scheme if you don't know it
you should definitely you definitely
should I think it's one of the great
inventions in computer science of the
century it was suggested by your pine
Radler in 2001 and it's extremely simple
what they're suggesting is your you have
two tables he wanted me to each of size
but if roughly larger than in and you
have to hash functions h1 and h2 in
order to do look up you have to look up
in t1 and you have to look up in key to
so you compute h1 to search for X what
you do is you compute H 1 of X and woke
up in a t1 you compute H 2 of X and you
look up t to to see where it's you these
are the only two possible locations were
a or egg neck skin be okay so look up is
extremely simple to hash computations in
two air lockers and
and the nice trick is the insertion is
also pretty simple and hence the name a
Coco it comes from their hookah bird it
kicks away the eggs of other bird I
suppose a North Americans need this
explanation because it only happens in
Europe in this area not in the North
America the cuckoo birds don't behave
like that so that's perhaps why I'm
Ridley from Denmark anyway still are
anyway so in order to put a look you put
an X a location i h 1 of x if it's if
it's empty great it wasn't empty you
need to find a place for the guy that
was there why and your insert it into
the other table and again you kick out
whoever was there etc so just do a
simple example you're trying to insert a
you you go to h1 of a is equal to h1
okay so you kick out a a goes through
h2o it's h2 of a why was there we need
to find a place for NY h 1y was empty so
you put it there and that the fing
finishes so this is very simple though
of course the question is why does it
work and it doesn't always work but it
works with reasonably high probability
and it works if you look at the cook of
graph then you have a set s defining
such as you have here you have the you
have a bipartite graph each location
here corresponds to locations in the
memory their worlds corresponds to 2
locations of the memory the edges
correspond to elements and you have an
edge connecting a
edge connecting for each element X you
have an edge h 1 of X iconic HDX and now
the nice thing is the SS successfully
stored if and only if every connected
component in the cocoa graph has at most
one cycle okay and the insertion
algorithm achieves this so so this is
pretty good except that you're wasting
it well right you need a little more
than twice as many elements so it
roughly half for this thing to work
roughly half the locations will need to
be empty so there are various ways a
very getting it to be denser and denser
and in particular in our work we showed
how you can actually work in bins and
get improvable results but the point is
that that's not enough in order to get a
1 plus a little o of one of the
information theoretic now we need to get
to to to use these permutations with
image so in particular right you as I
said you use the permutation and your
partition you jump into part look at the
Pyxis partitioning compiles the first
part tells you a what build it should go
okay the left part tells you to what Ben
it should go and the second part is sort
of the new identity will incur the new
identity of the elements if it's going
to be in a certain bit there isn't any
point in story so if we know that we
know that it's going to be in this
billion been corresponding that we can
throw away this part and install just
fairness okay so we just scored this
valued and can get
so how do we get permutations so here we
use again crypto we look at the
construction of a feistel permutation
that was in the construction of des used
chrysler permutation they're more the
construction of mubarak of the pseudo
random permutations using feist
implementation and essentially what we
have here is we petition to left parking
right point we apply a function here
which should be pretty random we know
how to construct remember our problem is
we have good constructions of pseudo elf
ok where's independent functions but not
we don't have great constructions of the
gateways independent permutations so
what we do let's say is a step or or
this we can do this isn't for it's a
little bit more involved but let's think
of it as just pay one step you to apply
a carriage independent function X or it
with a left park and this tells us the
pin number and our can remain unchanged
this there's a new ID this is and what
we have here is some sort of a highly
independent cash for the blood to I so
that we can still represent it in sub
linear space and so how so how do we get
something that is close to okay wise
independent permutation so we do this
like so let me do it here we can get PI
1 and i 2 can be and just pairwise
independent communications but here
inside leave these two
to these two permutations are
constructed exactly as I showed before
okay in each one of these functions f1
and f2 are going to be highly
independent but there are functions or
irritation the whole thing the whole
result is a permutation and we get a we
this we can get a collection of Delta
dependent permutation where they'll
carry something like k squared over
square root with you and you can compose
a few of them and reduce the error so
here we've used herein a basic idea of
crypto of constructing pseudo random
permutations in order to come up with
the analog of the K was independent
permutation that we we still don't know
how to construct a so we still need so
this is both in the work that I told you
on making the helmets result rigorous
and here we still need the ability to
perform to come up with k wise
independent a functions which can be
evaluating the order one and have
reasonably synced a representation so eh
eh so let's go to our final application
and also the construction later they
still are you and that's hashing for
domain extension so suppose that we have
a pseudo-random function that operates
on a fixed domain site so let's say it
operates on n bits from n bits to embed
some it's like a super education so we
want to construct a certain oral
function on any domain size from M bits
to a so we have one and fixed it maps n
bits to n bits and we want to map am
bits to anything so what can we do and
we measure such construction by the
domain now how large a new domain is the
security is a simple random functions in
general a win
okay in general and we measure security
of a server amel function by the number
of queries you it can answer the time
the time they tackle can attack it
absolutely the distinguishing
probability so we have a construction
with Katie and epsilon and we want to
come up with a construction with k prime
keep riding epsilon prime which are as
good as possible ok so we measure the
construction by how the deterioration of
the security how worse ours are play
prime V prime minister on prime or ours
are compared to kten epsilon and the
number of calls made to the underlying
pseudo-random function so even if you
look at the original gold right world
vessel Macaulay paper pseudo-random
where functions construction of several
functions you can apply and get it in
such a reduction but it wouldn't be so
good in terms of the number of a calls
to the function wouldn't be a constant
number of calls to the underlying
pseudo-random function so what can we do
luckily a Levin had the idea and I think
it's already in the original paper paper
in the original GG or maybe all paper
but actually it's explicitly described
it in one of weddings paper much more so
than many other ideas that are only
hinted anyway so what you do is you in
order to do to extend the domain you
hash you use pairwise independent
hashing go on the older nude large
domain and you have to do the original
domain what's the problem the problem is
birthday so if you have few queries
after something like use you cannot use
it for more than Q squared over 2 to the
N applications because after a kiss
after this many the probability of a
collision is Kim's point of entry to the
end so
deterioration in terms of distinguish
ability is Q squared over 2 to the N the
question is whether so that's it's a
very good constructions in terms of the
number of applications right we applying
just one hash function one hash function
would you pay away so that could be very
efficient and then then we are applying
the original pseudo-random function so
that's great in these terms but in terms
of the security deterioration it doesn't
work and you cannot do apply to to you
cannot to do more than square root of 2
to the N name any queries so okay so
what a we saw there have been various
constructions trying to achieve it and
in recent work with a tiger Bearman the
heightened and the inner villain lair
Komarovsky we came up with a
construction that needed to call the
original function the underlying
function two times hey and this is of
course reversed right security number of
courses like this is the number of calls
and this is the security in any way ah
this also gives you suddenly strange
anyway and I can't even blame the fact
that it's not my computer in this case I
guess it's my own doing anyway so they
what happens in terms of security we can
get we can get the security this should
be here we can make the security they
distinguish anon security to be as small
as we which you can have two calls and
other work to call so the underlying
pseudo-random function plus other work
and the security can be open from q 0 /
2 to them but it can be even smaller if
you are willing to spend more work but
not cryptographic work so how did we get
it we did it by using other people's
work the best type of result you let
other people do the work and then you
just a snatch it in applied so the
people who did the work we're fine pop
against blam blam another only one zoo
could work together and they came up
with a construction of highly
independent functions that can be easily
evaluated in the spirit of very cuckoo
hashing so a then you need a happy well
you need that their point was this is
their construction so you have functions
f1 and f2 which are going to be
essentially a f1 and f2 are going to be
think of f1 and f2 is truly random
functions but where can you have to run
a random function if you have a table if
it's just a table lookup so their domain
is limited so so we will be applying h1
h1 is going to be something like login
or blog or in our notation here NY is
independent h2 is also going to be
something like anyways independent
remember anything the original
number of bids we're going to apply a h1
is going to map to a relatively small FF
one man maps to 22 it is whatever
independence we want so we're going to
bite so in order to evaluate the our
hash function you have to apply they
have to compute H 1 of X F to compute H
2 of X then apply f 10 to them if the pi
f 22 them X or the result then the whole
thing would be exhorted with another
something like anyways independent
function so n n is the number of bits
when they say ni need the number of bits
or in the rigid in whatever application
whether in your and sorry it makes sense
to talk about end when we're talking
about the crypto application and if
we're talking about they the data
structure application will talk about
login so Rogan is still pretty little
high but we can deal with that as well
and not virgin until know in half and so
so this is this is another way this is a
pictorial way of viewing it again you
have a large domain you apply the hash
function you get a small domain you
apply if you apply it from here you get
your ex or the two results plus you're
using another g for sort of those that
didn't make it in what we showed with
bypass road was a make sure this type of
result if H the H a G these a functions
these families if these families are a
que wise independent an F is truly
independent then the resulting family
that we get is K over 2 to the K
indistinguishable from random by any
cake query non-adaptive distinguish ok
so non-adaptive you seem so it's not
quite what we want we want if we're
trying to use it for whatever
application both in the hashing both in
the destruction occasion and in the
domain extension application
I think the adversary can be adaptive I
mean certainly if you think of of
adversaries in the context of silver and
the functions they are adaptable think
of them as a nap p so luckily the way
the proof is written can you can easily
get from it a stronger result and you
can actually show that it holds for
adaptive distinguishes as well again you
can use their work in and get a this
quite general statement that tells us
that if you prove it in a certain
combinatorial way you will be able to
translate it and obtain a result that is
good against a adaptive adversaries as
well so the the way the domain extension
would look like is something like what
we saw before we will get will use an F
would be the original children under
like pseudo random function will have G
and H which go which are k ways
independent and the result would be we
lose what don't lose anything in qu we
lose a little in the time because we
still need to evaluate Lee the hash
function and in terms of the
deterioration in the epsilon when we get
an expression of the form K over 2 2day
a Omega AQ over to today a to the K so
once once k is larger than log kill we
started to getting a reasonable results
and we can this is what I told you
before we can make it as small as we
wish okay so and this is it these are
roughly the examples I wanted to show
and I would end up with just one
question is there a general theory that
explains these tight relationship how
come we're getting so many were able to
you to go back and forth between crypto
and a data structure so easily is there
it's just a general explanation for the
way this phenomenal Thank You G takes
care that the probability isn't smaller
the probability of failure is something
like 1 over the table size G takes care
of failures makes the probability much
much smaller
oh then okay this film inger talking
about a okay digital finger got rid of
like Oh glory still the original its
finger fulfill your talking about that
okay you are talking about a very old
papers okay now that they're not a space
optimal but no but some of the work you
did for bigger and Volvo have a mean
that they extended the pine / result to
get rid of Tony you can get rid of the
the fact that you have law login
independence that you can actually get
it to order one independence you never
have to work more than one order one so
that's actually because it follows from
work of this with this will be involved
