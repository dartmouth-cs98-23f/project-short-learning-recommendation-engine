second,duration,transcript
0.0,2.879,[Music]
1.599,3.121,if you're looking for a machine learning
2.879,2.561,tutorial with python and jupyter
4.72,2.48,notebook
5.44,3.92,this tutorial is for you you're going to
7.2,4.24,learn how to solve a real world problem
9.36,3.199,using machine learning and python we're
11.44,2.64,going to start off with a brief
12.559,2.96,introduction to machine learning
14.08,3.039,then we're going to talk about the tools
15.519,3.121,you need and after that we're going to
17.119,2.401,jump straight into the problem we're
18.64,2.799,going to solve
19.52,3.919,you'll learn how to build a model that
21.439,3.201,can learn and predict the kind of music
23.439,3.201,people like
24.64,3.36,so by the end of this one hour tutorial
26.64,2.719,you will have a good understanding of
28.0,2.88,machine learning basics
29.359,3.761,and you'll be able to learn more
30.88,3.519,intermediate to advanced level concepts
33.12,2.8,you don't need any prior knowledge in
34.399,2.801,machine learning but you need to know
35.92,2.72,python fairly well
37.2,3.199,if you don't i've got a couple of
38.64,3.439,tutorials for you here on my channel the
40.399,3.441,links are below this video
42.079,3.761,i'm ashamed only and i'm super excited
43.84,3.76,to be your instructor on this channel i
45.84,3.039,have tons of programming tutorials that
47.6,3.52,you might find helpful
48.879,3.52,so be sure to subscribe as i upload new
51.12,8.72,tutorials every week
52.399,7.441,now let's jump in and get started
63.84,2.959,in this section you're going to learn
64.96,2.72,about machine learning which is a subset
66.799,2.961,of ai or
67.68,4.16,artificial intelligence it's one of the
69.76,3.359,trending topics in the world these days
71.84,2.72,and it's going to have a lot of
73.119,3.601,applications in the future
74.56,3.04,here's an example imagine i ask you to
76.72,3.6,write a program
77.6,3.839,to scan an image and tell if it's a cat
80.32,2.64,or a doc
81.439,3.281,if you want to build this program using
82.96,3.6,traditional programming techniques
84.72,3.759,your program is going to get overly
86.56,3.76,complex you will have to come up with
88.479,2.561,lots of rules to look for specific
90.32,3.28,curves
91.04,4.0,edges and colors in an image to tell if
93.6,2.879,it's a cat or a dog
95.04,3.039,but if i give you a black and white
96.479,3.041,photo your rules may not work
98.079,3.281,they may break then you'll have to
99.52,3.2,rewrite them or i might give you a
101.36,3.2,picture of a cat or a dog
102.72,3.039,from a different angle that you did not
104.56,2.72,predict before
105.759,3.04,so solving this problem using
107.28,2.159,traditional programming techniques is
108.799,3.68,going to get
109.439,4.96,overly complex or sometimes impossible
112.479,3.68,now to make the matter worse what if in
114.399,2.32,the future i ask you to extend this
116.159,2.401,program
116.719,3.521,such that it supports three kinds of
118.56,4.0,animals cats
120.24,4.08,dogs and horses once again you'll have
122.56,3.76,to rewrite all those rules
124.32,3.919,that's not gonna work so machine
126.32,2.88,learning is a technique to solve these
128.239,3.201,kind of problems
129.2,3.679,and this is how it works we build a
131.44,3.84,model or an engine
132.879,3.36,and give it lots and lots of data for
135.28,2.88,example we give you
136.239,3.921,thousands or tens of thousands of
138.16,4.0,pictures of cats and dogs
140.16,3.92,our model will then find and learn
142.16,3.92,patterns in the input data
144.08,3.519,so we can give it a new picture of a cat
146.08,3.44,that it hasn't seen before
147.599,3.761,and ask it is it a cat or a dog or a
149.52,3.28,horse and it will tell us with a certain
151.36,3.519,level of accuracy
152.8,3.2,the more input data we give it the more
154.879,3.601,accurate our model
156.0,3.2,is going to be so that was a very basic
158.48,2.08,example
159.2,3.84,but machine learning has other
160.56,5.36,applications in self-driving cars
163.04,3.839,robotics language processing vision
165.92,2.959,processing
166.879,3.44,forecasting things like stock market
168.879,3.921,trends and the weather
170.319,3.761,games and so on so that's the basic idea
172.8,2.799,about machine learning
174.08,3.92,next we'll look at machine learning in
175.599,2.401,action
182.159,3.841,a machine learning project involves a
183.68,4.479,number of steps the first step is to
186.0,3.599,import our data which often comes in the
188.159,3.281,form of a csv file
189.599,4.241,you might have a database with lots of
191.44,4.32,data we can simply export that data
193.84,4.16,and store it in a csv file for the
195.76,4.479,purpose of our machine learning project
198.0,4.08,so we import our data next we need to
200.239,4.0,clean it and this involves tasks
202.08,3.439,such as removing duplicated data if you
204.239,3.121,have duplicates in the data
205.519,3.601,we don't want to feed this to our model
207.36,3.36,because otherwise our model will learn
209.12,3.36,bad patterns in the data and it will
210.72,3.28,produce the wrong result
212.48,3.6,so we should make sure that our input
214.0,3.76,data is in a good and clean shape
216.08,3.04,if there are data that is irrelevant we
217.76,2.64,should remove them if they are
219.12,4.08,duplicated or
220.4,4.479,incomplete we can remove or modify them
223.2,4.24,if our data is text-based
224.879,3.041,like the name of countries or genres of
227.44,2.879,music
227.92,4.08,or cats and dogs we need to convert them
230.319,3.521,to numerical values
232.0,3.519,so this step really depends on the kind
233.84,3.84,of data we're working with
235.519,4.08,every project is different now that we
237.68,2.4,have a clean data set we need to split
239.599,3.36,it into
240.08,4.48,two segments one for training our model
242.959,4.0,and the other for testing it
244.56,3.679,to make sure that our model produces the
246.959,2.801,right result
248.239,3.041,for example if you have a thousand
249.76,3.199,pictures of cats and dogs
251.28,3.599,we can reserve eighty percent for
252.959,4.56,training and the other 20
254.879,3.36,for testing the next step is to create a
257.519,2.96,model
258.239,3.84,and this involves selecting an algorithm
260.479,2.881,to analyze the data
262.079,3.041,there are so many different machine
263.36,2.88,learning algorithms out there such as
265.12,3.6,decision trees
266.24,3.92,neural networks and so on each algorithm
268.72,3.84,has pros and cons
270.16,3.68,in terms of accuracy and performance so
272.56,2.88,the algorithm you choose
273.84,4.0,depends on the kind of problem you're
275.44,3.759,trying to solve and your input data
277.84,3.28,now the good news is that we don't have
279.199,3.921,to explicitly program an
281.12,3.68,algorithm there are libraries out there
283.12,3.359,that provide these algorithms
284.8,3.28,one of the most popular ones which we
286.479,4.401,are going to look at in this tutorial
288.08,4.24,is scikit-learn so we build a model
290.88,3.92,using an algorithm
292.32,4.319,next we need to train our model so we
294.8,3.2,fitted our training data
296.639,3.921,our model will then look for the
298.0,4.24,patterns in the data so next we can ask
300.56,3.44,it to make predictions
302.24,3.12,back to our example of cats and dogs we
304.0,3.759,can ask our model
305.36,4.08,is this a cat or a dog and our model
307.759,3.361,will make a prediction
309.44,3.759,now the prediction is not always
311.12,3.76,accurate in fact when you start out
313.199,3.84,it's very likely that your predictions
314.88,3.759,are inaccurate so we need to evaluate
317.039,3.921,the predictions and measure
318.639,3.28,their accuracy then we need to get back
320.96,3.2,to our model
321.919,3.441,and either select a different algorithm
324.16,3.039,that is going to produce
325.36,3.52,a more accurate result for the kind of
327.199,4.881,problem we're trying to solve
328.88,5.12,or fine-tune the parameters of our model
332.08,5.119,so each algorithm has parameters that we
334.0,4.639,can modify to optimize the accuracy
337.199,3.84,so these are the high level steps that
338.639,3.921,you follow in a machine learning project
341.039,4.72,next we'll look at the libraries and
342.56,3.199,tools for machine learning
350.16,3.36,in this lecture we're going to look at
351.199,3.921,the popular python libraries that we use
353.52,3.679,in machine learning projects
355.12,3.68,the first one is numpy which provides a
357.199,4.321,multi-dimensional array
358.8,4.88,very very popular library the second one
361.52,4.32,is pandas which is a data analysis
363.68,3.12,library that provides a concept called
365.84,3.04,data frame
366.8,3.839,a data frame is a two-dimensional data
368.88,2.72,structure similar to an excel
370.639,2.961,spreadsheet
371.6,4.159,so we have rows and columns we can
373.6,4.719,select data in a row or a column
375.759,4.401,or a range of rows and columns again
378.319,4.241,very very popular in machine learning
380.16,3.039,and data science projects the third
382.56,3.28,library
383.199,3.681,is matplotlib which is a two-dimensional
385.84,3.44,plotting library
386.88,4.319,for creating graphs and plots the next
389.28,3.52,library is scikit-learn which is one of
391.199,2.321,the most popular machine learning
392.8,2.239,libraries
393.52,3.6,that provides all these common
395.039,5.201,algorithms like decision trees
397.12,4.799,neural networks and so on now when
400.24,3.6,working with machine learning projects
401.919,3.201,we use an environment called jupiter for
403.84,3.12,writing our code
405.12,3.04,technically we can still use vs code or
406.96,2.959,any other code editors
408.16,3.039,but these editors are not ideal for
409.919,2.961,machine learning projects
411.199,3.521,because we frequently need to inspect
412.88,3.599,the data and that is really hard
414.72,3.759,in environments like vs code and
416.479,3.601,terminal if you're working with a table
418.479,3.28,of 10 or 20 columns
420.08,3.36,visualizing this data in a terminal
421.759,2.481,window is really really difficult and
423.44,2.879,messy
424.24,4.64,so that's why we use jupiter it makes it
426.319,4.081,really easy to inspect our data
428.88,4.159,now to install jupyter we're going to
430.4,6.0,use a platform called anaconda
433.039,5.681,so head over to anaconda.com
436.4,4.32,download on this page you can download
438.72,2.8,anaconda distribution for your operating
440.72,3.919,system
441.52,6.64,so we have distributions for windows mac
444.639,7.761,and linux so let's go ahead and
448.16,6.8,install anaconda for python 3.7
452.4,2.56,download
456.56,4.96,all right so here's anaconda downloaded
458.319,4.401,on my machine let's double click this
461.52,2.959,all right first it's going to run a
462.72,2.8,program to determine if the software can
464.479,3.761,be installed
465.52,3.679,so let's continue and once again
468.24,3.44,continue
469.199,3.201,continue pretty easy continue one more
471.68,4.16,time
472.4,5.04,i agree with the license agreement okay
475.84,3.44,you can use the default installation
477.44,4.96,location so don't worry about that
479.28,4.96,just click install give it a few seconds
482.4,3.68,now the beautiful thing about anaconda
484.24,4.079,is that it will install jupyter
486.08,4.08,as well as all those popular data
488.319,3.6,science libraries like numpy
490.16,5.36,pandas and so on so we don't have to
491.919,3.601,manually install this using pip
496.16,3.28,all right now as part of the next step
497.52,4.0,anaconda is suggesting to install
499.44,3.039,microsoft vs code we already have this
501.52,2.64,on our machine so
502.479,3.84,we don't have to install it we can go
504.16,4.319,with continue and
506.319,3.921,close the installation now finally we
508.479,5.12,can move this to trash because we don't
510.24,5.52,need this installer in the future
513.599,3.12,all right now open up a terminal window
515.76,4.959,and type
516.719,6.721,jupyter with a y space
520.719,3.921,notebook this will start the notebook
523.44,4.64,server on your machine
524.64,4.96,so enter there you go this will start
528.08,3.36,the notebook server on your machine you
529.6,3.52,can see these default messages here
531.44,4.399,don't worry about them now it
533.12,7.279,automatically opens a browser window
535.839,6.961,pointing to localhost port 888
540.399,4.0,this is what we call jupiter dashboard
542.8,2.32,on this dashboard we have a few tabs the
544.399,3.201,first tab
545.12,4.399,is the files tab and by default this
547.6,3.6,points to your home directory
549.519,3.681,so every user on your machine has a home
551.2,2.4,directory this is my home directory on
553.2,2.24,mac
553.6,3.6,you can see here we have a desktop
555.44,3.36,folder as well as documents
557.2,3.28,downloads and so on on your machine
558.8,2.96,you're going to see different folders
560.48,3.359,so someone on your machine you need to
561.76,4.32,create a jupyter notebook
563.839,4.161,i'm going to go to desktop here's my
566.08,5.68,desktop i don't have anything here
568.0,4.399,and then click new i want to create a
571.76,2.96,notebook
572.399,3.44,for python 3. in this notebook we can
574.72,3.04,write python code
575.839,3.761,and execute it line by line we can
577.76,3.759,easily visualize our data as you will
579.6,5.28,see over the next few videos
581.519,3.361,so let's go ahead with this
585.12,3.6,all right here's our first notebook you
587.2,4.96,can see by default it's called
588.72,4.0,untitled let's change that to hello
592.16,2.16,world
592.72,3.92,so this is going to be the hello world
594.32,5.199,of our machine learning project
596.64,4.84,let's rename this now if you look at
599.519,3.121,your desktop you can see this file
601.48,4.919,helloworld.i
602.64,5.6,pi nb this is a jupiter notebook
606.399,3.521,it's kind of similar to our pi files
608.24,3.44,where we write our python code
609.92,5.12,but it includes additional data that
611.68,6.399,jupiter uses to execute our code
615.04,7.44,so back to our notebook let's do a
618.079,7.521,print hello world and then
622.48,5.68,click this run button here and
625.6,4.239,here's the result printed in jupyter so
628.16,3.2,we don't have to navigate back and forth
629.839,4.481,between the terminal window
631.36,4.64,we can see all the result right here
634.32,6.0,next i'm going to show you how to load a
636.0,4.32,data set from a csv file in jupyter
644.8,3.52,all right in this lecture we're going to
646.0,3.48,download a data set from a very popular
648.32,3.84,website called
649.48,4.52,kaggle.com gaggle is basically a place
652.16,3.2,to do data science projects
654.0,3.2,so the first thing you need to do is to
655.36,4.4,create an account you can sign up with
657.2,3.6,facebook google or using a custom email
659.76,3.04,and password
660.8,3.2,once you sign up then come back here on
662.8,4.24,kaggle.com
664.0,6.48,here in the search bar search for
667.04,5.12,video game sales this is the name of a
670.48,3.12,very popular data set that we're going
672.16,3.76,to use in this lecture
673.6,3.359,so here in this list you can see the
675.92,3.599,first item
676.959,4.161,with this kind of reddish icon so let's
679.519,3.281,go with that
681.12,4.0,as you can see this data set includes
682.8,4.96,the sales data for more than 16
685.12,3.6,000 video games on this page you can see
687.76,2.88,the description
688.72,3.52,of various columns in this data set we
690.64,4.96,have rank
692.24,6.039,name platform year and so on so here's
695.6,4.16,our data source it's a csv file called
698.279,4.201,vgsales.csv
699.76,3.44,as you can see there are over 16 000
702.48,3.68,rows
703.2,4.56,and 11 columns in this data set right
706.16,2.239,below that you can see the first few
707.76,2.639,records
708.399,4.641,of this data set so here's our first
710.399,4.801,record the ranking for this game is one
713.04,3.76,it's the wii sports game for we as the
715.2,3.28,platform and it was released in year
716.8,4.479,2006
718.48,3.44,now what i want you to do is to go ahead
721.279,2.961,and
721.92,4.0,download this data set and as i told you
724.24,3.36,before you need to sign in before you
725.92,3.28,can download this
727.6,3.2,so this will give you a zip file as you
729.2,4.079,can see here
730.8,3.2,here's our csv file now i want you to
733.279,2.881,put this
734.0,4.079,right next to your jupyter notebook on
736.16,3.919,my machine that is on my desktop
738.079,4.081,so i'm going to drag and drop this onto
740.079,4.32,the desktop folder
742.16,3.28,now if you look at the desktop you can
744.399,3.68,see here is my
745.44,4.76,jupyter hello world notebook and right
748.079,4.961,next to that we have
750.2,5.16,vgsales.csv with that
753.04,3.44,we go back to our jupyter notebook let's
755.36,4.719,remove the first line
756.48,6.88,and instead import
760.079,5.281,pandas as pd
763.36,3.599,with this we're importing pandas module
765.36,3.68,and renaming it to pd
766.959,4.32,so we don't have to type pandas dot
769.04,5.44,several times in this code
771.279,7.041,now let's type pd dot read
774.48,5.039,underline csv and pass the name of our
778.32,4.72,csv file
779.519,5.44,that is vg sales.csv now because this
783.04,3.68,csv file is in the current folder
784.959,3.361,right next to our jupyter notebook we
786.72,4.48,can easily load it otherwise we'll have
788.32,6.639,to supply the full path to this file
791.2,5.92,so this returns a data frame object
794.959,3.841,which is like an excel spreadsheet let
797.12,4.24,me show you so
798.8,3.12,we store it here and then we can simply
801.36,3.599,type
801.92,4.719,df to inspect it so one more time let's
804.959,3.281,run this program
806.639,4.0,here's our data frame with these rows
808.24,5.12,and columns so we have rank
810.639,4.64,name platform and so on now this data
813.36,2.479,frame object has lots of attributes and
815.279,2.0,methods
815.839,3.12,that we're not going to cover in this
817.279,2.641,tutorial that's really beyond the scope
818.959,2.481,of what we're going to do
819.92,3.599,so i'll leave it up to you to read
821.44,4.0,panda's documentation or follow other
823.519,2.481,tutorials to learn about pandas data
825.44,1.68,frames
826.0,3.12,but in this lecture i'm going to show
827.12,5.279,you some of the most useful methods
829.12,6.0,and attributes the first one is shape so
832.399,4.56,shape let's run this one more time so
835.12,5.279,here's the shape of this data set
836.959,6.081,we have over 16 000 records and
840.399,3.841,11 columns technically this is a two
843.04,4.799,dimensional array
844.24,5.839,of sixteen thousand and eleven okay
847.839,3.761,now you can see here we have another
850.079,3.12,segment for writing code so we don't
851.6,2.479,have to write all the code in the first
853.199,2.32,segment
854.079,3.281,so here in the second segment we can
855.519,2.401,call one of the methods of the data
857.36,4.719,frame
857.92,7.44,that is df dot describe
862.079,5.281,now when we run this program we can see
865.36,3.919,the output for each segment
867.36,3.12,right next to it so here's our first
869.279,4.24,segment here we have
870.48,5.68,these three lines and this is the output
873.519,3.521,of the last line below that we have our
876.16,2.64,second segment
877.04,3.28,here we're calling the describe method
878.8,4.32,and right below that we have
880.32,4.16,the output of this segment so this is
883.12,3.839,the beauty of jupiter
884.48,4.24,we can easily visualize our data doing
886.959,3.841,this with vs code and terminal windows
888.72,3.52,is really tedious and clunky
890.8,3.44,so what is this describe method
892.24,4.24,returning basically it's returning some
894.24,4.32,basic information about each column
896.48,3.919,in this data set so as you saw earlier
898.56,4.32,we have columns like rank
900.399,4.0,year and so on these are the columns
902.88,4.16,with numerical values
904.399,4.161,now for each column we have the count
907.04,2.08,which is the number of records in that
908.56,4.2,column
909.12,7.12,you can see our rank column has 16
912.76,7.0,598 records whereas the year column has
916.24,5.36,16 327 records
919.76,4.56,so this shows that some of our records
921.6,5.12,don't have the value for the year column
924.32,3.04,we have no values so in a real data
926.72,2.08,science or
927.36,3.2,machine learning project we'll have to
928.8,2.399,use some techniques to clean up our data
930.56,2.719,set
931.199,4.401,one option is to remove the records that
933.279,4.881,don't have a value for the year column
935.6,4.64,or we can assign them a default value
938.16,4.32,that really depends on the project
940.24,3.839,now another attribute for each column is
942.48,3.76,mean so this is the average
944.079,4.161,of all the values now in the case of the
946.24,2.56,rank column this value doesn't really
948.24,3.519,matter
948.8,4.479,but look at the year so the average year
951.759,1.921,for all these video games in our data
953.279,2.721,set
953.68,4.159,is 2006 and this might be important in
956.0,4.639,the problem we're trying to solve
957.839,3.521,we also have standard deviation which is
960.639,3.12,a measure
961.36,3.839,to quantify the amount of variation in
963.759,4.401,our set of values
965.199,4.961,below that we have min as an example the
968.16,5.119,minimum value for the year column
970.16,4.239,is 1980. so quite often when we work
973.279,3.201,with a new data set
974.399,4.56,we call the describe method to get some
976.48,4.799,basic statistics about our data
978.959,5.721,let me show you another useful attribute
981.279,7.12,so in the next segment let's type
984.68,5.159,df.values let's run this
988.399,3.44,as you can see this returns a
989.839,3.041,two-dimensional array this square
991.839,4.321,bracket indicates
992.88,5.759,the outer array and the second one
996.16,3.2,represents the inner array so the first
998.639,4.161,element
999.36,5.839,in our outer array is an array itself
1002.8,4.32,these are the values in this array which
1005.199,4.161,basically represent the first row
1007.12,3.2,in our data set so the video game with
1009.36,3.919,ranking 1
1010.32,3.439,which is called wii sports so this was a
1013.279,2.881,basic
1013.759,3.76,overview of pando's data frames in the
1016.16,9.679,next lecture i'm going to show you some
1017.519,8.32,of the useful shortcuts of jupyter
1026.0,3.199,in this lecture i'm going to show you
1027.199,3.12,some of the most useful shortcuts in
1029.199,2.401,jupyter
1030.319,3.36,now the first thing i want you to pay
1031.6,4.4,attention to is this green bar
1033.679,4.64,on the left this indicates that this
1036.0,5.919,cell is currently in the edit mode so
1038.319,6.88,we can write code here now if we press
1041.919,5.12,the escape key green turns to blue and
1045.199,3.041,that means this cell is currently in the
1047.039,3.52,command mode
1048.24,4.16,so basically the activated cell can be
1050.559,4.161,either in the edit mode or
1052.4,4.24,the command mode depending on the mode
1054.72,3.36,we have different shortcuts
1056.64,3.36,so here we're currently in the command
1058.08,4.719,mode if we press
1060.0,3.6,h we can see the list of all the
1062.799,3.921,keyboard
1063.6,4.4,shortcuts right above this list you can
1066.72,4.319,see
1068.0,5.2,mac os modifier keys these are the extra
1071.039,3.76,keys that we have on a mac keyboard
1073.2,4.24,if you're a windows user you're not
1074.799,5.601,going to see this so as an example here
1077.44,4.08,is the shape of the command key this is
1080.4,3.84,control this is
1081.52,4.56,option and so on with this guideline you
1084.24,3.439,can easily understand the shortcut
1086.08,4.64,associated with each command
1087.679,3.841,let me show you so here we have all the
1090.72,2.88,commands
1091.52,4.159,when a cell is in the command mode for
1093.6,4.64,example we have this command
1095.679,4.321,open the command palette this is exactly
1098.24,2.88,like the command palette that we have in
1100.0,3.2,vs code
1101.12,3.52,here's a shortcut to execute this
1103.2,6.0,command that is
1104.64,6.56,command shift and f okay so here we have
1109.2,3.68,lots of shortcuts of course you're not
1111.2,3.12,going to use all of them all the time
1112.88,3.28,but it's good to have a quick look here
1114.32,3.359,to see what is available for you
1116.16,3.519,with this shortcuts you can write code
1117.679,3.921,much faster so let me show you some of
1119.679,5.12,the most useful ones
1121.6,4.24,i'm going to close this now with our
1124.799,4.561,first cell
1125.84,6.4,in the command mode i'm going to press b
1129.36,4.24,and this inserts a new cell below this
1132.24,3.439,cell
1133.6,3.6,we can also go back to our first cell
1135.679,3.441,press escape
1137.2,3.68,now the cell is in the command mode we
1139.12,4.799,can insert an empty cell
1140.88,6.08,above this cell by pressing a
1143.919,5.361,so either a or b a for above and b
1146.96,3.44,for below okay now if you don't want
1149.28,5.04,this cell you can press
1150.4,5.44,d twice to delete it like this
1154.32,4.08,now in the cell i'm going to print a
1155.84,6.16,hello world message so
1158.4,5.68,print hello world now
1162.0,5.2,to run the code in this cell we can
1164.08,6.16,click on the run button here
1167.2,4.56,so here's our print function and right
1170.24,4.24,below that you can see
1171.76,3.84,the output of this function but note
1174.48,3.92,that when you run a cell
1175.6,3.36,this will only execute the code in that
1178.4,2.88,cell
1178.96,4.24,in other words the code in other cells
1181.28,2.72,will not be executed let me show you
1183.2,3.12,what i mean
1184.0,3.44,so in the cell below this cell i'm going
1186.32,3.84,to delete the call
1187.44,4.08,to describe method instead i'm going to
1190.16,5.519,print
1191.52,6.399,ocean now i'm going to put the cursor
1195.679,3.681,back in this cell where we print the
1197.919,4.64,hello world message
1199.36,3.6,and run this cell so you can see hello
1202.559,3.041,world
1202.96,3.76,is displayed here but the cell below is
1205.6,3.439,still displaying
1206.72,3.839,the described table so we don't see the
1209.039,4.161,changes here
1210.559,4.24,now to solve this problem we can go to
1213.2,4.959,the cell menu on the top
1214.799,5.441,and run all cells together
1218.159,3.601,this can work for small projects but
1220.24,2.24,sometimes you're working with a large
1221.76,2.32,data set
1222.48,3.36,so if you want to run all these cells
1224.08,2.32,together it's going to take a lot of
1225.84,3.04,time
1226.4,4.08,that is the reason jupiter saves the
1228.88,2.72,output of itself so we don't have to
1230.48,3.76,rerun that code
1231.6,4.0,if it hasn't changed so this notebook
1234.24,3.84,file that we have here
1235.6,3.12,includes our source code organized in
1238.08,2.88,cells
1238.72,3.36,as well as the output for each cell that
1240.96,3.44,is why it's different
1242.08,4.24,from a regular pi file where we only
1244.4,4.48,have the source code
1246.32,3.599,here we also have autocompletion and
1248.88,4.08,intellisense
1249.919,6.081,so in the cell let's call
1252.96,5.44,df dataframe dot
1256.0,4.08,now if you press tab we can see all the
1258.4,4.88,attributes and methods
1260.08,5.839,in this object so let's call
1263.28,4.24,describe now with the cursor on the name
1265.919,4.561,of the method we can press
1267.52,3.68,shift and tab to see this tooltip that
1270.48,2.88,describes
1271.2,4.16,what this method does and what parameter
1273.36,2.88,it takes so here in front of signature
1275.36,3.04,you can see
1276.24,3.04,the describe method these are the
1278.4,3.2,parameters
1279.28,3.279,and their default value and right below
1281.6,3.52,that you can see
1282.559,4.0,the description of what this method does
1285.12,3.679,in this case it generates
1286.559,5.041,descriptive statistics that summarize
1288.799,4.801,the central tendency and so on
1291.6,3.28,similar to vs code we can also convert a
1293.6,4.319,line to comment
1294.88,5.12,by pressing command and slash on mac or
1297.919,4.88,control slash on windows
1300.0,4.0,like this now this line is a comment we
1302.799,4.401,can press the same shortcut
1304.0,4.72,one more time to remove the comment
1307.2,3.12,so these were some of the most useful
1308.72,2.959,shortcuts in jupyter
1310.32,3.44,now over the next few lectures we're
1311.679,2.641,going to work on a real machine learning
1313.76,2.64,project
1314.32,3.68,but before we get there let's delete all
1316.4,4.8,the cells here so we start with
1318.0,3.6,only a single empty cell so here in this
1321.2,2.08,cell
1321.6,3.84,first i'm going to press the escape
1323.28,4.08,button now the cell is blue
1325.44,3.68,so we are in the command mode and we can
1327.36,4.96,delete the cell by pressing d
1329.12,4.88,twice there you go now the next cell
1332.32,4.88,is activated and it's in the command
1334.0,5.2,mode so let's delete this as well
1337.2,4.56,we have two more cells to delete there
1339.2,4.959,you go and the last one
1341.76,5.84,like this so now we have an empty
1344.159,4.961,notebook with a single cell
1347.6,3.48,hey guys i just wanted to let you know
1349.12,3.679,that i have an online coding school at
1351.08,3.479,cordwindmarch.com where you can find
1352.799,2.481,plenty of courses on web and mobile
1354.559,2.48,development
1355.28,3.68,in fact i have a comprehensive python
1357.039,4.0,course that teaches you everything about
1358.96,2.719,python from the basics to more advanced
1361.039,2.561,concepts
1361.679,3.36,so after you watch this tutorial if you
1363.6,3.36,want to learn more you may want to look
1365.039,3.12,at my python course it comes with a 30
1366.96,2.8,day money back guarantee
1368.159,3.281,and a certificate of completion you can
1369.76,2.24,add to your resume in case you're
1371.44,4.4,interested
1372.0,3.84,the link is below this video
1378.0,3.039,over the next few lectures we're going
1379.28,2.72,to work on a real machine learning
1381.039,3.52,project
1382.0,4.799,imagine we have an online music store
1384.559,4.961,when our users sign up we ask their age
1386.799,3.441,and gender and based on their profile we
1389.52,2.72,recommend
1390.24,4.0,various music albums they're likely to
1392.24,3.12,buy so in this project we want to use
1394.24,3.6,machine learning to
1395.36,3.28,increase sales so we want to build a
1397.84,3.199,model
1398.64,4.64,we feed this model with some sample data
1401.039,4.241,based on the existing users
1403.28,3.68,our model will learn the patterns in our
1405.28,2.72,data so we can ask it to make
1406.96,3.28,predictions
1408.0,4.48,when a user signs up we tell our model
1410.24,4.08,hey we have a new user with this profile
1412.48,3.12,what is the kind of music that this user
1414.32,3.68,is interested in
1415.6,3.12,our model will say jazz or hip hop or
1418.0,1.919,whatever
1418.72,3.52,and based on that we can make
1419.919,4.161,suggestions to the user so this is the
1422.24,3.28,problem we're going to solve
1424.08,3.04,now back to the list of steps in a
1425.52,3.92,machine learning project
1427.12,4.0,first we need to import our data then we
1429.44,3.28,should prepare or clean it
1431.12,3.439,next we select a machine learning
1432.72,4.079,algorithm to build a model
1434.559,3.201,we train our model and ask it to make
1436.799,3.36,predictions
1437.76,3.6,and finally we evaluate our algorithm to
1440.159,3.52,see its accuracy
1441.36,3.04,if it's not accurate we either fine tune
1443.679,3.681,our model
1444.4,4.72,or select a different algorithm so let's
1447.36,3.919,focus on the first step
1449.12,3.919,download the csv file below this video
1451.279,3.121,this is a very basic csv that i've
1453.039,3.52,created for this project
1454.4,4.0,it's just some random made up data it's
1456.559,3.921,not real
1458.4,3.68,so we have a table with three columns
1460.48,4.799,age gender
1462.08,4.4,and genre gender can either be one which
1465.279,3.921,represents a male
1466.48,4.319,or zero which represents a female here
1469.2,4.56,i'm making a few assumptions
1470.799,4.24,i'm assuming that men between 20 and 25
1473.76,4.56,like hip-hop
1475.039,5.681,men between 26 and 30 like jazz
1478.32,4.239,and after the age of 30 they like
1480.72,4.0,classical music
1482.559,4.881,for women i'm assuming that if they're
1484.72,5.199,between 20 and 25 they like dance music
1487.44,3.68,if they're between 26 and 30 they like
1489.919,3.201,acoustic music
1491.12,3.76,and just like men after the age of 30
1493.12,3.6,they like classical music
1494.88,3.36,once again this is a made-up pattern
1496.72,2.64,it's not the representation of the
1498.24,3.6,reality
1499.36,3.76,so let's go ahead and download this csv
1501.84,5.839,click on this
1503.12,7.0,dot dot icon here and download this file
1507.679,3.921,in my downloads folder here we have this
1510.12,3.64,music.csv
1511.6,3.84,i'm going to drag and drop this onto
1513.76,4.32,desktop because that's where
1515.44,4.32,i've stored this hello world notebook so
1518.08,4.719,i want you to put the csv file
1519.76,4.88,right next to your jupyter notebook
1522.799,3.201,now back to our notebook we need to read
1524.64,3.36,the csv file
1526.0,4.0,so just like before first we need to
1528.0,6.0,import the pandas module
1530.0,7.2,so import pandas as pd
1534.0,4.64,and then we'll call pd that read analyze
1537.2,4.959,csv
1538.64,5.6,and the name of our file is music.csv
1542.159,4.081,as you saw earlier this returns a data
1544.24,4.4,frame which is a two-dimensional array
1546.24,3.28,similar to an excel spreadsheet so let's
1548.64,5.12,call that
1549.52,6.8,music underline data
1553.76,4.48,now let's inspect this music underline
1556.32,2.959,data to make sure we loaded everything
1558.24,4.08,properly
1559.279,5.361,so run so here's our data frame
1562.32,3.2,beautiful next minute to prepare or
1564.64,4.159,clean the data
1565.52,3.279,and that's the topic for the next
1568.84,3.0,lecture
1573.52,3.519,the second step in a machine learning
1575.039,2.64,project is cleaning or preparing the
1577.039,2.88,data
1577.679,3.201,and that involves tasks such as removing
1579.919,2.88,duplicates
1580.88,3.44,null values and so on now in this
1582.799,3.041,particular data set we don't have to do
1584.32,2.64,any kind of cleaning because we don't
1585.84,4.16,have any duplicates
1586.96,5.04,and as you can see all rows have values
1590.0,4.08,for all columns so we don't have null
1592.0,3.679,values but there is one thing we need to
1594.08,3.92,do
1595.679,3.921,we should split this data set into two
1598.0,3.52,separate data sets
1599.6,3.76,one with the first two columns which we
1601.52,3.759,refer to as the input set
1603.36,4.0,and the other with the last column which
1605.279,4.481,we refer to as the output set
1607.36,3.76,so when we train a model we give it two
1609.76,4.0,separate data sets
1611.12,3.6,the input set and the output set the
1613.76,3.44,output set
1614.72,3.28,which is in this case the genre column
1617.2,2.8,contains
1618.0,3.279,the predictions so we're telling our
1620.0,4.08,model that if we have
1621.279,3.441,a user who's 20 years old and is a male
1624.08,3.36,they like
1624.72,4.48,hip hop once we train our model then we
1627.44,3.599,give it a new input set
1629.2,4.079,for example we say hey we have a new
1631.039,4.561,user who is 21 years old
1633.279,4.64,and is a male what is the genre of the
1635.6,4.48,music that this user probably likes
1637.919,4.961,as you can see in our input set we don't
1640.08,4.64,have a sample for a 21 year old male
1642.88,3.039,so we're going to ask our model to
1644.72,3.12,predict that
1645.919,4.64,that is the reason we need to split this
1647.84,6.719,data set into two separate sets
1650.559,6.161,input and output so back to our code
1654.559,5.12,this data frame object has a method
1656.72,5.76,called drop
1659.679,3.841,now if you put the cursor under method
1662.48,4.48,name and press
1663.52,5.44,shift and tab you can see this tooltip
1666.96,3.92,so this is the signature of this drop
1668.96,3.04,method these are the parameters that we
1670.88,2.48,can pass here
1672.0,3.679,the parameter we're going to use in this
1673.36,3.52,lecture is columns which is set to none
1675.679,2.961,by default
1676.88,3.519,with this parameter we can specify the
1678.64,6.0,columns we want to drop
1680.399,8.16,so in this case we set columns
1684.64,6.159,to an array with one string genre
1688.559,3.761,now this method doesn't actually modify
1690.799,3.6,the original data set
1692.32,3.12,in fact it will create a new data set
1694.399,4.64,but without
1695.44,4.56,this column so by convention we use a
1699.039,4.24,capital x
1700.0,6.64,to represent that data set so capital x
1703.279,6.721,equals this expression now
1706.64,6.08,let's inspect x so as you can
1710.0,3.52,see our input set or x includes these
1712.72,2.72,two columns
1713.52,3.759,age and gender it doesn't have the
1715.44,5.599,output or predictions
1717.279,6.4,next we need to create our output set so
1721.039,4.081,once again we start with our data frame
1723.679,3.681,music data
1725.12,3.919,using square brackets we can get all the
1727.36,4.88,values in a given column
1729.039,4.0,in this case genre once again this
1732.24,3.52,returns
1733.039,3.921,a new data set by convention we use a
1735.76,3.6,lowercase y
1736.96,3.439,to represent that so that is our output
1739.36,4.48,data set
1740.399,6.16,let's inspect that as well
1743.84,3.76,so in this data set we only have the
1746.559,4.161,predictions or
1747.6,4.959,the answers so we have prepared our data
1750.72,4.4,next we need to create a model using an
1752.559,2.561,algorithm
1759.44,3.52,the next step is to build a model using
1761.36,3.28,a machine learning algorithm
1762.96,4.24,there are so many algorithms out there
1764.64,5.12,and each algorithm has its pros and cons
1767.2,3.76,in terms of the performance and accuracy
1769.76,2.799,in this lecture we're going to use a
1770.96,3.839,very simple algorithm called
1772.559,4.081,decision tree now the good news is that
1774.799,3.921,we don't have to explicitly
1776.64,4.32,program these algorithms they're already
1778.72,7.04,implemented for us in a library called
1780.96,8.24,scikit-learn so here on the top
1785.76,6.56,from sklearn.3
1789.2,7.04,let's import the decision
1792.32,5.76,tree classifier so sklearn
1796.24,3.76,is the package that comes with
1798.08,3.76,scikit-learn library this is the most
1800.0,2.96,popular machine learning library in
1801.84,3.199,python
1802.96,4.16,in this package we have a module called
1805.039,2.64,tree and in this module we have a class
1807.12,3.52,called
1807.679,3.6,decision tree classifier this class
1810.64,4.32,implements
1811.279,5.52,the decision tree algorithm okay so
1814.96,3.36,now we need to create a new instance of
1816.799,4.24,this class
1818.32,3.28,so at the end let's create an object
1821.039,3.76,called
1821.6,4.4,model and set it to a new instance of
1824.799,4.321,decision
1826.0,6.0,tree classifier
1829.12,4.48,like this so now we have a model next we
1832.0,3.679,need to train it so it learns
1833.6,3.52,patterns in the data and that is pretty
1835.679,4.961,easy we call
1837.12,4.32,model that fit this method takes two
1840.64,4.24,data sets
1841.44,7.52,the input set and the output set so
1844.88,5.84,they are capital x and y
1848.96,3.04,now finally we need to ask our model to
1850.72,3.04,make a prediction
1852.0,4.399,so we can ask it what is the kind of
1853.76,5.6,music that a 21 year old male likes
1856.399,3.921,now before we do that let's temporarily
1859.36,4.799,inspect
1860.32,6.959,our initial data set that is music data
1864.159,5.281,so look what we got here
1867.279,3.441,as i told you earlier i've assumed that
1869.44,4.4,men between 20
1870.72,3.839,and 25 like hip-hop music but here we
1873.84,3.839,only have
1874.559,5.921,three samples for men aged 20
1877.679,4.321,23 and 25 we don't have a sample for a
1880.48,3.36,21 year old male
1882.0,3.679,so if you ask our model to predict the
1883.84,3.6,kind of music that a 21 year old male
1885.679,5.12,likes we expect it to say
1887.44,5.119,hip hop similarly i've assumed that
1890.799,3.681,women between 20 and 25
1892.559,4.24,like dance music but we don't have a
1894.48,4.4,sample for a 22 year old female
1896.799,3.281,so once again if you ask our model to
1898.88,3.76,predict the kind of music
1900.08,3.28,that a 22 year old woman likes we expect
1902.64,3.919,it to say
1903.36,5.439,dance so with these assumptions
1906.559,3.441,let's go ahead and ask our model to make
1908.799,4.48,predictions
1910.0,6.08,so let's remove
1913.279,3.441,the last line and instead we're going to
1916.08,3.92,call
1916.72,6.4,model dot predict this method
1920.0,4.399,takes a two dimensional array so here's
1923.12,3.919,the outer array
1924.399,4.0,in this array each element is an array
1927.039,3.601,so i'm going to pass
1928.399,3.041,another array here and in this array i'm
1930.64,3.84,going to pass
1931.44,6.479,a new input set a 21 year old male
1934.48,4.4,so 21 comma one that is like a new
1937.919,4.24,record
1938.88,3.84,in this table okay so this is one input
1942.159,2.321,set
1942.72,3.439,let's pass another input set for a
1944.48,5.28,22-year female
1946.159,6.481,so here's another array here we add 22
1949.76,5.2,comma zero so we're asking our model to
1952.64,5.36,make two predictions at the same time
1954.96,4.959,we get the result and store it in a
1958.0,5.12,variable called predictions
1959.919,4.721,and finally let's inspect that in our
1963.12,5.039,notebook
1964.64,6.08,run look what we got
1968.159,3.201,our model is saying that a 21 year old
1970.72,3.199,male
1971.36,3.039,likes hip hop and a 22 year old female
1973.919,2.64,likes
1974.399,3.841,dance music so our model could
1976.559,4.081,successfully make predictions here
1978.24,4.319,beautiful but wait a second building a
1980.64,3.279,model that makes predictions accurately
1982.559,3.281,is not always that easy
1983.919,4.401,as i told you earlier after we build a
1985.84,4.319,model we need to measure its accuracy
1988.32,3.44,and if it's not accurate enough we
1990.159,3.76,should either fine tune it or build a
1991.76,3.44,model using a different algorithm
1993.919,5.681,so in the next lecture i'm going to show
1995.2,4.4,you how to measure the accuracy of a
2002.84,2.52,model
2004.32,3.12,in this lecture i'm going to show you
2005.36,2.88,how to measure the accuracy of your
2007.44,2.88,models
2008.24,3.2,now in order to do so first we need to
2010.32,3.68,split our data set
2011.44,3.839,into two sets one for training and the
2014.0,3.519,other for testing
2015.279,3.52,because right now we're passing the
2017.519,3.28,entire data set
2018.799,3.281,for training the model and we're using
2020.799,3.36,two samples
2022.08,4.079,for making predictions that is not
2024.159,2.64,enough to calculate the accuracy of a
2026.159,3.12,model
2026.799,4.561,a general rule of thumb is to allocate
2029.279,3.921,70 to 80 percent of our data
2031.36,3.6,for training and the other twenty to
2033.2,4.0,thirty percent for testing
2034.96,3.52,then instead of passing only two samples
2037.2,3.28,for making predictions
2038.48,4.079,we can pass the data set we have for
2040.48,3.28,testing we'll get the predictions
2042.559,3.441,and then we can compare these
2043.76,4.56,predictions with the actual values
2046.0,3.839,in the test set based on that we can
2048.32,3.519,calculate the accuracy
2049.839,3.681,that's really easy all we have to do is
2051.839,3.361,to import a couple of functions
2053.52,4.72,and call them in this code let me show
2055.2,6.24,you so first on the top
2058.24,6.56,from sklearn the model
2061.44,6.8,underline selection module we import
2064.8,5.279,a function called train test split
2068.24,3.839,with this function we can easily split
2070.079,5.52,our data set into two sets
2072.079,6.961,for training and testing now
2075.599,5.04,right here after we define x and y sets
2079.04,5.359,we call this function
2080.639,7.121,so train test split
2084.399,5.68,we give it three arguments x y
2087.76,4.48,and a keyboard argument that specifies
2090.079,6.961,the size of our test data set
2092.24,7.04,so test underline size we set it to 0.2
2097.04,3.52,so we are allocating 20 of our data for
2099.28,4.559,testing
2100.56,5.36,now this function returns a tuple so we
2103.839,5.841,can unpack it into four variables
2105.92,7.84,right here x underline train
2109.68,7.2,x underline test y underline train
2113.76,5.359,and y underline test
2116.88,3.52,so the first two variables are the input
2119.119,4.96,sets for training
2120.4,4.16,and testing and the other are the output
2124.079,3.681,sets
2124.56,4.96,for training and testing now when
2127.76,3.52,training our model
2129.52,3.12,instead of passing the entire data set
2131.28,4.88,we want to pass only
2132.64,6.56,the training data set so x
2136.16,6.16,underline train and y
2139.2,3.76,underline train also when making
2142.32,2.48,predictions
2142.96,3.36,instead of passing these two samples we
2144.8,4.48,pass x
2146.32,4.0,underline test so that is the data set
2149.28,4.4,that contains
2150.32,5.279,input values for testing now we get
2153.68,3.76,the predictions to calculate the
2155.599,2.801,accuracy we simply have to compare these
2157.44,3.84,predictions
2158.4,3.76,with the actual values we have in our
2161.28,3.76,output set
2162.16,4.08,for testing that is very easy first on
2165.04,5.039,the top we need to import
2166.24,5.68,a function so from sklearn.metrics
2170.079,6.241,metrics
2171.92,6.0,import accuracy underlying score
2176.32,3.759,now at the very end we call this
2177.92,5.76,function so accuracy
2180.079,6.481,score and
2183.68,3.84,give it two arguments y underline test
2186.56,5.2,which contains
2187.52,7.2,the expected values and predictions
2191.76,4.0,which contains the actual values now
2194.72,4.08,this function returns
2195.76,5.52,an accuracy score between zero to one so
2198.8,6.16,we can store it here
2201.28,6.96,and simply display it on the console
2204.96,6.0,so let's go ahead and run this program
2208.24,3.52,so the accuracy score is one or 100
2210.96,2.48,percent
2211.76,3.28,but if we run this one more time we're
2213.44,3.679,going to see a different result
2215.04,3.84,because every time we split our data set
2217.119,3.681,into training and test sets
2218.88,4.0,we'll have different data sets because
2220.8,4.88,this function randomly picks data
2222.88,4.0,for training and testing let me show you
2225.68,2.96,so put the cursor
2226.88,3.76,in the cell now you can see this cell is
2228.64,2.8,activated note that if you click this
2230.64,3.68,button here
2231.44,3.679,it will run this cell and also inserts a
2234.32,2.88,new cell
2235.119,4.0,below this cell let me show you so if i
2237.2,4.639,go to the second cell
2239.119,3.681,press escape button now we are in the
2241.839,4.321,command mode
2242.8,6.799,press d twice okay now it's deleted
2246.16,5.52,if we click the run button you can see
2249.599,3.361,this code was executed and now we have a
2251.68,2.56,new cell
2252.96,3.04,so if you want to run our first cell
2254.24,2.56,multiple times every time we have to
2256.0,2.88,click this
2256.8,3.92,and then run it and then click again and
2258.88,4.0,run it it's a little bit tedious
2260.72,3.359,so i'll show you a shortcut activate the
2262.88,4.479,first cell
2264.079,5.441,and press ctrl and enter
2267.359,3.441,this runs the current cell without
2269.52,4.079,adding a new cell
2270.8,3.68,below it so back here let's run it
2273.599,3.561,multiple times
2274.48,3.92,okay now look the accuracy dropped to
2277.16,3.32,0.75
2278.4,4.0,it's still good so the accuracy score
2280.48,5.76,here is somewhere between
2282.4,7.6,75 to 100 but let me show you something
2286.24,6.879,if i change the test size from 0.2
2290.0,3.599,to 0.8 so essentially we're using only
2293.119,2.881,20
2293.599,4.0,of our data for training this model and
2296.0,4.16,we're using the other 80
2297.599,4.641,for testing now let's see what happens
2300.16,5.36,when we run this cell multiple times
2302.24,5.44,so control and enter look the accuracy
2305.52,5.28,immediately dropped to 0.4
2307.68,7.76,one more time now 46 percent
2310.8,6.64,40 26 it's really really bad
2315.44,3.84,the reason this is happening is because
2317.44,4.0,we are using very little data
2319.28,4.4,for training this model this is one of
2321.44,4.08,the key concepts in machine learning
2323.68,3.28,the more data we give to our model and
2325.52,3.68,the cleaner the data is
2326.96,3.119,we get the better result so if we have
2329.2,3.6,duplicates
2330.079,3.52,irrelevant data or incomplete values our
2332.8,2.96,model will learn
2333.599,3.921,bad patterns in our data that is why
2335.76,4.48,it's really important to clean our data
2337.52,5.52,before training our model now let's
2340.24,5.2,change this back to 0.2
2343.04,3.76,run this one more time okay now the
2345.44,4.639,accuracy is one
2346.8,5.039,75 percent now we drop to 50
2350.079,3.921,again the reason this is happening is
2351.839,4.24,because we don't have enough data
2354.0,4.32,some machine learning problems require
2356.079,4.721,thousands or even millions of samples
2358.32,4.32,to train a model the more complex the
2360.8,3.52,problem is the more data we need
2362.64,3.439,for example here we're only dealing with
2364.32,3.68,a table of three columns
2366.079,3.921,but if you want to build a model to tell
2368.0,3.2,if a picture is a cat or a dog or a
2370.0,3.359,horse or a lion
2371.2,3.68,we'll need millions of pictures the more
2373.359,2.72,animals we want to support the more
2374.88,2.4,pictures we need
2376.079,7.76,in the next lecture we're going to talk
2377.28,6.559,about model persistence
2385.359,4.48,so this is a very basic implementation
2387.599,3.52,of building and training a model to make
2389.839,3.361,predictions
2391.119,3.521,now to simplify things i have removed
2393.2,2.399,all the code that we wrote in the last
2394.64,2.959,lecture for
2395.599,3.121,calculating the accuracy because in this
2397.599,4.081,lecture we're going to focus
2398.72,4.56,on a different topic so basically we
2401.68,4.72,import our data set
2403.28,5.68,create a model train it and then
2406.4,3.679,ask it to make predictions now this
2408.96,3.52,piece of code that you see
2410.079,4.481,here is not what we want to run every
2412.48,3.599,time we have a new user or every time we
2414.56,3.6,want to make recommendations
2416.079,3.76,to an existing user because training a
2418.16,2.64,model can sometimes be really time
2419.839,2.48,consuming
2420.8,3.039,in this example we're dealing with a
2422.319,4.081,very small data set that has
2423.839,3.841,only 20 records but in real applications
2426.4,3.76,we might have a data set
2427.68,4.08,with thousands or millions of samples
2430.16,2.32,training a model for that might take
2431.76,3.52,seconds
2432.48,5.04,minutes or even hours so that is why
2435.28,4.48,model persistence is important
2437.52,4.799,once in a while we build and train our
2439.76,3.68,model and then we'll save it to a file
2442.319,3.28,now next time we want to make
2443.44,3.28,predictions we simply load the model
2445.599,3.52,from the file and
2446.72,4.56,ask it to make predictions that model is
2449.119,2.641,already trained we don't need to retrain
2451.28,2.72,it
2451.76,4.079,it's like an intelligent person so let
2454.0,3.04,me show you how to do this it's very
2455.839,6.161,very easy
2457.04,8.319,on the top from sklearn.externals
2462.0,6.56,module we import
2465.359,3.921,lib this job live object has methods for
2468.56,3.84,saving
2469.28,6.16,and loading models so after
2472.4,6.16,we train our model we simply call
2475.44,6.159,joblib dot dump
2478.56,4.08,and give it two arguments our model and
2481.599,3.201,the name of the file
2482.64,3.199,in which we want to store this model
2484.8,4.08,let's call that
2485.839,7.28,music dash recommender
2488.88,6.0,dot job lib that's all we have to do
2493.119,3.361,now temporarily i'm going to comment out
2494.88,3.36,this line we don't want to make any
2496.48,3.599,predictions we just want to store our
2498.24,4.64,trained model in a file
2500.079,4.481,so let's run this cell with control and
2502.88,5.12,slash
2504.56,5.68,okay look in the output we have an array
2508.0,4.16,that contains the name of our model file
2510.24,3.359,so this is the return value of the dump
2512.16,3.6,method
2513.599,4.321,now back to our desktop right next to my
2515.76,4.0,notebook you can see our job live file
2517.92,3.84,this is where our model is stored it's
2519.76,4.24,simply a binary file
2521.76,4.0,now back to our jupyter notebook as i
2524.0,3.359,told you before in a real application we
2525.76,4.96,don't want to train a model
2527.359,5.121,every time so let's comment out
2530.72,4.08,these few lines so i've selected these
2532.48,4.8,few lines on mac we can press
2534.8,3.92,command and slash on windows control
2537.28,3.68,slash
2538.72,4.399,okay these lines are commented out now
2540.96,3.76,this time instead of dumping our model
2543.119,4.0,we're going to load it so we call the
2544.72,3.52,load method we don't have the model we
2547.119,3.921,simply pass
2548.24,3.839,the name of our model file this returns
2551.04,4.0,our trained
2552.079,3.76,model now with these two lines we can
2555.04,3.84,simply
2555.839,5.121,make predictions so earlier we assumed
2558.88,5.04,that men between 20 and 25
2560.96,4.879,like hip-hop music let's print
2563.92,3.76,predictions and see if our model is
2565.839,5.041,behaving correctly or not
2567.68,7.2,so control and enter there you go
2570.88,4.0,so this is how we persist and load
2576.839,3.0,models
2579.92,3.439,earlier in this section i told you that
2581.44,3.36,decision trees are the easiest to
2583.359,2.24,understand and that's why we started
2584.8,2.799,machine learning
2585.599,3.841,with decision trees in this lecture
2587.599,2.961,we're going to export our model in a
2589.44,3.52,visual format
2590.56,3.36,so you will see how this model makes
2592.96,2.72,predictions
2593.92,3.52,that is really really cool let me show
2595.68,4.0,you so
2597.44,3.679,once again i've simplified this code so
2599.68,4.96,we simply import
2601.119,4.401,our data set create input and output
2604.64,4.0,sets
2605.52,5.36,create a model and train it
2608.64,3.52,that's all we are doing now i want you
2610.88,3.52,to follow along with me
2612.16,3.679,type everything exactly as i show you in
2614.4,2.56,this lecture don't worry about
2615.839,3.361,what everything means we're going to
2616.96,5.44,come back to it shortly so
2619.2,6.72,on the top from sklearn
2622.4,5.6,import tree this object
2625.92,4.32,has a method for exporting our decision
2628.0,5.52,tree in a graphical format
2630.24,6.48,so after we train our model let's call
2633.52,6.24,tree dot export underline
2636.72,4.08,graph vis now here are a few arguments
2639.76,3.76,we need to pass
2640.8,4.88,the first argument is our model the
2643.52,3.68,second is the name of the output file
2645.68,3.36,so here we're going to use keyword
2647.2,3.119,arguments because this method takes so
2649.04,2.48,many parameters and we want to
2650.319,3.361,selectively pass
2651.52,3.36,keyword arguments without worrying about
2653.68,4.08,their order
2654.88,3.36,so the parameter we're going to set is
2657.76,3.599,out
2658.24,6.879,underline file let's set this to
2661.359,6.881,music dash recommender dot
2665.119,3.601,d o t this is the dot format which is a
2668.24,2.24,graph
2668.72,3.04,description language you'll see that
2670.48,3.839,shortly
2671.76,3.359,the other parameter we want to set is
2674.319,3.921,feature
2675.119,6.401,underline names we set this to an array
2678.24,5.68,of two strings age and
2681.52,3.04,gender these are the features or the
2683.92,2.64,columns
2684.56,4.16,of our data set so they are the
2686.56,6.16,properties or features of our data
2688.72,7.119,okay the other parameter is class names
2692.72,4.8,so class underline names we should set
2695.839,4.881,this to the list of classes
2697.52,6.559,or labels we have in our output data set
2700.72,6.24,like hip hop jazz classical and so on
2704.079,5.441,so this y data set includes all the
2706.96,4.32,genres or all the classes of our data
2709.52,3.68,but they're repeated a few times in this
2711.28,5.68,data set so
2713.2,6.159,here we call y dot unique this returns
2716.96,4.0,the unique list of classes now we should
2719.359,4.72,sort this alphabetically
2720.96,7.76,so we call the sorted function and
2724.079,8.321,pass the result a y dot unique
2728.72,4.8,the next parameter is label we set this
2732.4,3.439,to a string
2733.52,3.92,all once again don't worry about the
2735.839,3.28,details of these parameters we're going
2737.44,4.72,to come back to this shortly
2739.119,6.561,so set label to all then
2742.16,8.159,round it to true and finally
2745.68,6.399,filled to true so this is the end result
2750.319,3.52,now let's run this cell using control
2752.079,5.121,and enter
2753.839,5.841,okay here we have a new file
2757.2,3.76,music recommender dot dot that's a
2759.68,3.52,little bit funny
2760.96,4.32,so we want to open this file with vs
2763.2,5.36,code so drag and drop this
2765.28,3.28,into a vs code window
2770.0,5.359,okay here's a dot format it's a textual
2772.88,4.64,language for describing graphs
2775.359,4.401,now to visualize this graph we need to
2777.52,4.64,install an extension in vs code
2779.76,3.2,so on the left side click the extensions
2782.16,4.4,panel
2782.96,5.44,and search for dot dot
2786.56,3.6,look at the second extension here
2788.4,4.959,graphviz or dot
2790.16,5.28,language by staphon vs
2793.359,3.76,go ahead and install this extension and
2795.44,4.08,then reload vs code
2797.119,3.361,once you do that you can visualize this
2799.52,4.799,dot file
2800.48,5.599,so let me close this tab all right
2804.319,3.121,look at this dot dot here on the right
2806.079,3.52,side click this
2807.44,3.2,you should have a new menu open preview
2809.599,4.081,to the site
2810.64,4.16,so click that all right here's the
2813.68,3.52,visualization
2814.8,3.6,of our decision tree let's close the dot
2817.2,3.68,file
2818.4,4.24,there you go this is exactly how our
2820.88,4.0,model makes predictions
2822.64,3.52,so we have this binary tree which means
2824.88,4.239,every node can have
2826.16,4.0,a maximum of two children on top of each
2829.119,3.601,node we have
2830.16,4.64,a condition if this condition is true we
2832.72,4.0,go to the child node on the left side
2834.8,3.76,otherwise we go to the child node on the
2836.72,2.639,right side so let's see what's happening
2838.56,3.92,here
2839.359,4.72,the first condition is age less than or
2842.48,3.76,equal to 30.5
2844.079,4.321,if this condition is false that means
2846.24,3.839,that user is 30 years or older
2848.4,4.08,so the genre of the music that they're
2850.079,5.201,interested in is classical
2852.48,4.079,so here we're classifying people based
2855.28,3.12,on their profile
2856.559,4.56,that is the reason we have the word
2858.4,3.36,class here so a user who is 30 years or
2861.119,3.521,older
2861.76,3.76,belongs to the class of classical or
2864.64,3.04,people who like
2865.52,3.76,classical music now what if this
2867.68,4.72,condition is true
2869.28,6.079,that means that user is younger than 30.
2872.4,3.439,so now we check the gender if it's less
2875.359,3.601,than
2875.839,3.76,0.5 which basically means if it equals
2878.96,2.639,to 0
2879.599,3.76,then we're dealing with a female so we
2881.599,4.24,go to the child node here
2883.359,4.161,now once again we have another condition
2885.839,2.961,so we're dealing with a female who is
2887.52,3.68,younger than 30.
2888.8,3.519,once again we need to check their age so
2891.2,4.8,is the age
2892.319,6.481,less than 25.5 if that's the case then
2896.0,5.04,that user likes dance music otherwise
2898.8,4.0,they like acoustic music
2901.04,3.2,so this is the decision tree that our
2902.8,3.519,model uses to make
2904.24,3.839,predictions now if you're wondering why
2906.319,5.04,we have these floating point numbers
2908.079,4.721,like 25.5 these are basically the rules
2911.359,3.521,that our model generates
2912.8,3.2,based on the patterns that it finds in
2914.88,3.28,our data set
2916.0,4.079,as we give our model more data these
2918.16,2.959,rules will change so they're not always
2920.079,3.201,the same
2921.119,4.081,also the more columns or more features
2923.28,3.279,we have our decision tree is going to
2925.2,3.6,get more complex
2926.559,3.76,currently we have only two features age
2928.8,3.12,and gender
2930.319,2.881,now back to our code let me quickly
2931.92,2.24,explain the meaning of all these
2933.2,3.359,parameters
2934.16,4.48,we set fill to true so each box or each
2936.559,4.56,node is filled with a color
2938.64,4.479,we set rounded to true so they have
2941.119,4.801,rounded corners
2943.119,4.881,we set label to all so every node has
2945.92,4.32,labels that we can read
2948.0,3.2,we set class names to the unique list of
2950.24,2.48,genres
2951.2,3.359,and that's for displaying the class for
2952.72,4.24,each node right here
2954.559,3.121,and we set feature names to age and
2956.96,4.879,gender
2957.68,4.159,so we can see the rules in our notes
2962.8,3.039,hey thank you for watching my tutorial i
2964.64,2.56,hope you learned a lot and you're
2965.839,3.201,excited to learn more
2967.2,3.52,if you enjoyed this tutorial please like
2969.04,2.799,and share it with others and be sure to
2970.72,3.44,subscribe to my channel
2971.839,4.941,as i upload new videos every week once
2974.16,5.719,again thank you and i wish you all the
2976.78,3.099,[Music]
2981.559,3.0,best
