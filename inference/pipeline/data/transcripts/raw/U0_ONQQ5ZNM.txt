second,duration,transcript
0.44,6.27,"Your eyes see in 2D, the retina is a two dimensional
surface of cells that activate when photons"
6.71,5.24,"hit them. Whether those photons are bouncing
off of a physical object, or being produced"
11.95,5.18,"by your display there isn’t too much of
a difference to the neural circuitry that"
17.13,5.22,"makes up your vision system. So the brain
is already doing the hard part. It takes a"
22.35,5.58,"2 dimensional image as input, and on the other
end you somehow have a near instant understanding"
27.93,3.16,of the 3 dimensional objects you are seeing.
31.09,4.989,"We can create objects by constructing them
out of many triangles. To create an accurate"
36.079,5.471,"2d representation, we need to project each
of these triangles onto a flat plane from"
41.55,1.919,the perspective of a viewer.
43.469,6.901,"It can be helpful to think of a computer screen
as a window, where light bounces off an object,"
50.37,3.02,through the window and into your eye.
53.39,5.64,"So to generate an image it’s almost as if
we need to do the reverse operation. If you"
59.03,6.5,"shot a ray from your eye through each section
of the window, what color would you hit?"
65.53,6.45,"And this is the basic idea behind 3D graphics.
Each pixel of the display is like a little"
71.98,5.6,"window, and the more pixels the clearer the
image. And it is up to our graphics engine"
77.58,5.03,"to figure out what color of light would be
passing through that pixel as if the game"
82.61,3.09,world actually existed on the other side.
85.7,4.26,"The method I’ve explained, where rays are
projected into the world and collide with"
89.96,6.39,"objects, is the foundation behind ray tracing.
Ray tracing has only recently made its debut"
96.35,5.19,"into video games with the release of newer
graphics cards containing dedicated ray tracing"
101.54,1.28,hardware.
102.82,5.6,"On the other hand CPU-based ray tracing has
been around for a long time and has been used"
108.42,6.1,"extensively within the movie and animation
industries, but is much too slow to be used"
114.52,5.23,"in real-time applications.
A single frame in Toy story 4 could take anywhere"
119.75,6.27,"between 60 to 160 hours to render using CPU
based ray tracing."
126.02,5.97,"Ray tracing is known as image-order rendering,
since each pixel is first considered, and"
131.99,4.6,"then on a per pixel basis we find all the
objects that could influence it."
136.59,5.43,"The alternative is object-order rendering
which is much faster and what we have been"
142.02,5.62,"using. This is where we draw each object,
one after the other. This approach maps much"
147.64,5.4,"better to the gpu, since we can apply the
same instructions, but on different vertices"
153.04,1.28,in parallel.
154.32,6.23,"So we could find the location for each projected
position within a vertex shader by calculating"
160.55,5.56,"the line and plane intersection, and this
would work just fine! But a much more effective"
166.11,3.7,way to do this is with a matrix transformation!
169.81,4.23,"First though, I’ll start by explaining orthographic
projection."
174.04,5.74,"In the previous tutorial I talked about vulkan’s
canonical viewing volume. Only the objects"
179.78,4.93,"that are within this 2 by 2 by 1 region will
be displayed."
184.71,5.31,"Note that the positive y axis points down,
and positive z axis points into the screen."
190.02,1.0,"An orthographic projection is a generalization
of the view volume that keeps the view direction"
191.02,1.0,"and orientation fixed, but allows the view
volume to be an axis-aligned box with any"
192.02,1.0,dimensions and at any location we want.
193.02,3.7,"An orthographic projection is a generalization
of the view volume that allows us to specify"
196.72,5.81,"whatever dimensions and whatever location
we want, but maintains the overall shape of"
202.53,4.65,"the view volume, and keeps the view direction
and orientation fixed."
207.18,5.44,"The orthographic view volume is defined by
6 bounding planes, the left and right along"
212.62,8.6,"the x axis, the top and bottom along the y
axis, and the near and far along the z axis."
221.22,6.45,"So these 6 values, left bottom near, and right,
top, far, define the orthographic viewing"
227.67,1.31,volume
228.98,6.14,"So to construct an orthographic projection
matrix we need to solve the following problem:"
235.12,6.37,"how do you transform the orthographic view
volume to vulkan’s canonical view volume?"
241.49,6.29,"And the good news is we already know how to
do this. We can combine two basic transformations,"
247.78,6.98,"first translate the box so that the center
of the near plane is at the origin. And then"
254.76,5.93,"follow that with a scale transformation so
the boxes have the same dimensions."
260.69,4.89,"So the numerator will be the canonical view
volume’s dimensions, and the denominator"
265.58,3.64,"will be the dimensions of the orthographic
view volume."
269.22,5.52,"If we multiply the matrices and simplify,
we get the orthographic projection matrix."
274.74,5.51,"Note that this matrix differs slightly from
most other online resources. The canonical"
280.25,7.19,"openGL view volume is a cube, with a z range
of -1 to 1. Additionally openGL uses a left"
287.44,4.69,"handed coordinate system and looks down the
negative z axis, but we’re using a right"
292.13,4.44,"handed coordinate system and looking down
the positive z axis. So just keep this in"
296.57,3.78,"mind if you are following other resources
with different conventions."
300.35,5.08,"And that’s it. By applying this transformation
to our objects, the objects that are within"
305.43,5.81,"the region occupied by the orthographic view
volume, will be scaled and moved into the"
311.24,5.67,"region covered by canonical view volume, and
therefore the objects will be displayed!"
316.91,5.16,"But the orthographic view volume doesn’t
apply perspective, to do that we require a"
322.07,4.98,"viewing volume that is not box shaped, but
a shape known as a square frustum"
327.05,5.839,"A frustum is the shape that captures a viewer’s
line of sight as if they were looking through"
332.889,2.411,a rectangular window.
335.3,6.119,"So what we want is a perspective matrix that
transforms the frustum and any object it contains"
341.419,2.541,into the orthographic view volume.
343.96,5.83,"Doing so would apply perspective to all objects
within this space. The further away an object"
349.79,2.24,"is, the smaller it will appear!"
352.03,5.38,"To properly apply perspective, we need to
project each point onto the viewing plane."
357.41,5.37,"For example, to calculate the apparent height
of an object on the screen, we can use the"
362.78,5.07,"property that the side lengths of two similar
triangles are proportional to each other."
367.85,4.67,"We can rearrange this equation to show that
an object's apparent height on screen is equal"
372.52,5.69,"to distance to the screen over the distance
to the object, multiplied by the object's"
378.21,5.79,"true height. This equally applies for the
x direction when calculating an object's apparent"
384.0,1.86,width on the screen.
385.86,5.54,"Also note, that just as with the other viewing
volumes, anything outside of the frustum will"
391.4,1.109,be clipped.
392.509,5.501,"Ok so what we would like to do is come up
with some 4 by 4 matrix, that when applied"
398.01,6.95,"to a position vector, the resulting x and
y values equal the projected xs and ys coordinates"
404.96,1.489,on the viewing plane.
406.449,4.852,"But there is a problem. We have a division
by the z component, in the solution’s x"
411.301,6.319,"and y components, and a 4 by 4 matrix that
can move a z value from here to a division"
417.62,6.049,"here, simply does not exist. It is just not
possible with matrix multiplication alone."
423.669,7.071,"But what’s that, it is homogeneous coordinates
to the rescue! We have one more trick up our"
430.74,6.72,"sleeve. So far the 4th component of all position
vectors has been fixed, with w always equal"
437.46,5.15,"to 1, to allow for matrix multiplication to
implement translations."
442.61,6.529,"We will now additionally define w to be the
denominator of the x y and z components. This"
449.139,8.021,"means that the homogeneous vector [x, y, z,
w] corresponds to the point at [x/w, y/w,"
457.16,4.53,"z/w].
This also means that vector [1, 2, 3, 1],"
461.69,7.37,"is equal to the vector [10, 20, 30, 10] and
also equal to [2, 4, 6, 2]. These all represent"
469.06,3.75,"the exact same position at 1, 2, 3."
472.81,5.6,"This division is automatically applied on
the gl_Position variable output from the vertex"
478.41,6.43,"shader and has always been occurring. If I
go into the vertex shader and update the homogeneous"
484.84,4.889,"coordinate value to 2 and run my code, my
object becomes half the size because we now"
489.729,3.16,divide each position component by 2.
492.889,5.231,"Therefore if the solution’s w component
is equal to z, it will be possible to calculate"
498.12,4.6,"the projected coordinates of x and y onto
the viewing plane"
502.72,5.24,"With this knowledge, we can start to construct
the perspective matrix transformation."
507.96,5.4,"The first two rows have the distance to the
viewing plane on the main diagonal, and zeroes"
513.36,5.14,"elsewhere. This will have the effect of scaling
the x and y components by the distance to"
518.5,7.52,"the near plane. Next the final row must be
0, 0, 1, 0 to take the z component from the"
526.02,5.7,"input vector, and move it to the w component
of the solution vector."
531.72,4.55,"All that’s remaining is the third row, and
an easy mistake to make is to think this can"
536.27,7.36,"also just be 0, 0, 1, 0, to copy the z depth
value into the solution. The problem is, every"
543.63,4.36,"component will be divided by w including this
one."
547.99,6.36,"z over z is just 1 and now we’ve lost our
depth information and won’t know which objects"
554.35,2.53,should be drawn in front of others.
556.88,7.3,"So rewind, and in reality we need the solutions
z component to equal z squared, since z squared"
564.18,5.24,"over z is equal to z. But in our matrix we
only have two remaining unknown values to"
569.42,7.31,"use. If we multiply this out we get the equation
m1 times z plus m1 equals z squared. This"
576.73,5.87,"is a quadratic equation, meaning it has at
most two real solutions and can’t be true"
582.6,2.09,for other z values.
584.69,5.69,"Therefore we add two constraints that this
equation is only true when z equals n or z"
590.38,5.51,"equals f. This means that the transformation
will not change the z values for points on"
595.89,6.11,"the near and far planes, but all other z values
will be warped non-linearly."
602.0,6.63,"This results in two equations that we can
use to solve for m1 and m2. M1 times n + m2"
608.63,5.26,"equals n squared, and m1 times f plus m2 equals
f squared"
613.89,4.56,"Solving these equations
We get m1 is equal to f + n, and m2 is equal"
618.45,1.67,to negative fn.
620.12,6.55,"Let’s plug this in and the solution’s
z component becomes f + n times z - fn."
626.67,4.63,"So let's take a minute to go over what this
really means. We wanted to have a one to one"
631.3,4.53,"linear relationship between the input z value
and output z value."
635.83,5.71,"But the best we could do is make this true
for points at the near depth and far depth."
641.54,4.729,"The z depth values on the near and far planes
remain unchanged, but the relationship is"
646.269,1.971,no longer linear.
648.24,4.99,"However this is still useful because the relative
ordering of the z values between the near"
653.23,5.15,"and far planes is preserved! This means we
can still use z to determine the order of"
658.38,2.24,objects within our scene.
660.62,4.66,"An advantage to having the z depth values
be non-linear is that calculations at the"
665.28,6.78,"near plane will be higher precision then calculations
at the far plane, reducing observable Z fighting."
672.06,6.01,"Z fighting, also known as stitching or depth
fighting, occurs when two surfaces are very"
678.07,3.85,"close together.
This visual artifact is caused by the rounding"
681.92,5.57,"errors of floating point calculations and
can be avoided by reducing the distance between"
687.49,2.42,the near and far planes.
689.91,5.02,"Now back to the perspective matrix, if you
apply the perspective transform followed by"
694.93,5.23,"the orthographic projection transform, the
combined result is known as the perspective"
700.16,2.179,projection transformation.
702.339,4.781,"And this is what we’ve been after. This
matrix will transform objects contained by"
707.12,5.49,"the viewing frustum, into the canonical view
volume, and in doing so will make the objects"
712.61,2.039,appear in perspective.
714.649,5.901,"We define the perspective projection matrix
with the same values as used by the orthographic"
720.55,6.99,"view volume, the 6 values r, l, b, t, n and
f. But it’s often more convenient to use"
727.54,6.12,"a simpler system where we assume the frustum
is aligned along the z axis, meaning that"
733.66,2.78,we are looking through the center of the window.
736.44,9.09,"This implies that l = -r, and t = -b, which
can further simplify the matrix"
745.53,5.79,"Finally, it is common to specify a vertical
field of view rather than the values for the"
751.32,1.92,bottom and the right planes.
753.24,5.64,"The vertical field of view is the angle from
the bottom to the top of the near plane relative"
758.88,5.54,"to the viewer's line of sight. If we also
know the aspect ratio of the window, we can"
764.42,5.09,"easily calculate values for the bottom right
corner with some basic trigonometry."
769.51,5.61,"So the bottom value is equal to the near plane
distance times tan theta over two. And the"
775.12,4.57,"right value is equal to the windows aspect
ratio, times the bottom."
779.69,6.47,"Plug this in and simplify, and we get the
final form of the perspective projection matrix."
786.16,4.71,"If you enjoy computer graphics content like
this, please consider subscribing."
790.87,3.709,"Thanks for watching and keep on coding, cheers!"
