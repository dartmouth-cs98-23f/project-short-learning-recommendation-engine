so the top you agile behind the ilium
postback data analytics application to
talk about me alright I had started
anodized canonical and sort of sort of
as data into the areas classes
visualization engineer written books and
now I'm doing a training as well the
books this is sort of based on agile
data time 2.0 a thousand three really on
a relative are six thousand may exist
turn this into a video if you want to
learn with you what we talked about
tonight
that's one x where I'm a component may
be product and active because I've set
up an attorney so very briefly of cover
the theory of this sort of actually
science big most pimples on application
developers so data products are being
assigned I actually leave that building
at the fundamental skill for data
scientists and that everyone whether the
data scientist right should be a
tutorial on viewing that name and
everything you can then should be an
application to them you know that same
thing some of my over here is actually
questions and so I did a survey on
Twitter yesterday and so about half
bottles at least the missing amount
so some support for this idea and so why
do the science and big data I think if
you're a data scientist and you build a
model or a little app and you have to
the absolutely build is to deploy it to
get it into the business process to
really make change at the company work
yeah but you done something really wrong
that you should be using big data tools
as I'll show you they're not really less
efficient and you can use the money on a
computer so the goal of the methodology
is the document and God Explorer for
data analysis to discover at all of the
critical path to a compelling product so
what is a critical tab there's this
incredible task theory you might have
seen my aunt char her chart critical
path was like the next iteration of that
we're yet to sort of figure out how to
get we're not necessarily linear and so
that's very important when you're going
into X product there's a manifesto for
agile they at times but it won't so go
Chris it's about iteration a lot there's
a eat around experiments that sort of
structures top or the first thing to do
is to plug records through front end to
end from the way you're collecting them
onto the web and app and then you can
start with just enough people in chart
so you can start sort of clean a tiger
game visualizing project asking
questions
up next you sort of turn those into
report so you extract enemies which will
show you and for the roads between them
at search instead of got interactivity
in reports you can drill down spiral by
the way either order to end up that
order in which people pay for this so
people will take a bit about anymore
because that that's that and ultimately
what they want to do so up next
prediction during the command understand
love it when you predict the future
things that care a lot about and but
ultimately what people care about
anyway you actions
that's why AII machinery so the tools
that we used I used to be a fake fanatic
people that like ask you to take music
but archaeologic you ever played used in
general if you can be working on spark
you probably should most people watching
is you don't have to wait five minutes
or are simple you know the first line of
the next thing that you and pipe are to
me and your place page which is in the
first edition of the book because the
great API Python Python has really
powerful tools for manipulating data
versus your depth of growth but that's
not good enough for many be speaking of
the process is the way people are
collecting data it's also the way that
they're acting on data in real time and
really sometimes it can take a few
seconds to get work recently so what is
no more focus I miss Cassandra sort of
wish I had but I also used to LinkedIn
that where you could push a dataset from
beneath to Voldemort their in-house key
value store at in one operation that at
the time there was no way to do that in
any other database so I had to write the
ability to do that entomology it is so
simple actually could pull that off
because everything in model if you look
at the code it's like oh my god to do
that and so but as an optimist or like
incredibly capable any database in
existence including like the timing
sequel DB operation
yeah any of those can act as the
database for this app so I need to do it
research elasticsearch is sort of a
super spark occurs often really easy it
doesn't get in your way and then the
number of web frameworks sort of like
Ruby's the natural flash is one of them
I love it because
there's a plug in if you do anything you
don't have to reinvent the wheel but
that is not an easel budget small that
you have to learn to get something done
you just define your web after is simply
a network so the way the slowest data
processing is your work we collect
events with pasta we save them to a CSS
or if you're in the cloud something like
x3 we process the in match with the sign
language spark publish back to mommy be
be presentable flash and browser huge
key chef is amazing it's not on here but
people each dress everything I made is
really ugly now she's kind of it's not
my I mean my call I could get like a
style each draft plug-in is far as start
those the beautiful ecosystem because
you get spark and there's such people
which I'll talk about more you get
people now without having to do separate
tools like Pig and hi you get spark and
outlet which is very competitive with
scikit-learn
a lot of people use a single metal
contact and you get a spark stream you
have to share code between you things
which is incredibly valuable
yes in the book we do both and then that
so I got lines of code for each to
publish given tasks Egyptian but yeah if
you one chapter and boat and and move on
to like just feeling spark ability
because it became clear that the things
you have a explosion I find it's very
competitive and it works with many
machines for yet so I was a very dating
up people die because it has got to
eight people trying to do
in it it really bit and so you know
whether few people and those people in
the whole preservation was a very big
thing people when you get complex like
this it's really ugly and I can't follow
it I can only do like one sub select
before my brain box and but there's this
data file programming which is good if
you're doing something complex this is
like page and you can count the email
addresses between email addresses and so
good that it sort of broken out but with
spark to get you sequel and vehicle
program so beautiful for women so we
want to do select filter which is very
convenient and our using people and here
we do of how it's not everybody because
we're looking at all the data but it has
been bouncing that and vehicle program
uses plot a histogram on that Anita like
it's incredibly powerful to be able to
both I was in love with peak but when I
first used spark almost pride because
I've been waiting five minutes or my
life for five years and it was just joy
on the big plan hold that and the data
that we work with in this application is
online performance data in the data flow
select event so it was a great website
almost data where it's a rigorous
description of everything but 99% of
flights report Wester on time miss
choose FAA and why they really so once I
really analogy that gives it like why
are our planes late usually
and it's usually the carrier's fault but
there's a whole lot of categories in
there like I'm getting stick this is not
their competence mister probably most of
the time it's not very common accident
most likely reading apply plays because
of previous licenses so this is the
first three
but this date is really cool there's
tons of field analysis to do it but
these are cons of the bunch of sorties
and then there's the open file or
database they give you information on
Air Force Air Lines and route to be
employed and then we scrape the FAA
registry this data is on the website
so I actually get you put this script in
the code the code by the way for all
business freeze you can place it on the
agenda that's great if I did include
that in the script for the project that
didn't want the site to go down so I
just let you download the result but so
he's created a excel number data we use
Python upto module to pull in
descriptions of your lines that sort of
thing and I thought this was going to go
down and Chompy and presently till
there's nothing today because of climate
chief weather data is available in a
very convenient point through the last
decade or two decades somebody I love an
image I would export of the lower left
on this guy reclining if he's like
interviewed climbing his business at the
top of the mountain think that's awesome
don't question it
no reclining the stack so working our
way up the data by appearances for the
app start by plumbing systems inning to
end so what we do is to sort of to
collect the data
now we're processing and publishing data
to extra buted store which is mommies
publishing like isaac kamalii needy and
spark looks like this this is a helpful
modulating forward we look the part a
file to the grapes columnar format you
don't have to
you think but a blur which rigorously
defined fields you can just sort of
store things convert JSON to this comic
format which automatically compresses it
in the same way that you would have
probably like a star schema especially
monopoly because it's a great corner and
then you must be because a data frame is
the new singing but the old sitting is
an RDD you have to convert to that many
stores and publishing records to elastic
searches again two months behind two
lines of code 100 resolved I did have to
figure it as option alpha says it
overloaded rating the the copy idea is
one line but if you have like a hundreds
of spark cluster and Tunis MongoDB
cluster need to think before you use
these two months of code but in this
case they're all live also compare the
data set that option and so putting
those records on the web is some flat
import to the import time on where the
 client define a route on a
function for that route will appear on
the web
well rameters from weary strings get the
data after this JSON turn runcam the
plastic grid it looks like that but if
you get a date on plugin for chrome away
which i recommended for years so then
we're on to tables and charts this is
how do you make a data table in high pot
so we register the parkade bottle but
you know the party files register it for
people very direct are people you just
call smart people
when people that give us a data frame
back you know you lurk back to the old
format and stage tomorrow you have to be
there for charging the college gift
model and then make it plotting the data
size SS data communication on the chart
this is the controller and for flash
model is great it could actually be
quite complex and something like int and
restoring the data so that's why you
want to stand simple and we render the
template this is the template most HTML
we move through the flight and plot the
row of columns element room and then get
you this one others is very complex but
it forms the basis for the high level
this is the code for the chart this is
the same thing but we return JSON that
it when this template this looks complex
but copied this from an example from my
boss talked and edited three lines and
that's how everyone does everything in
d3 these people don't really talk about
it but 95% of the trucks out there in
the street start as an example of my
boss back in there very super fun so
that gives you this is highlighted one
mode July popular so beyond that and
start to build rapport with the explore
data to the interaction this hasn't
enough yet for my data button start with
a homepage search is a great way to get
started but no I think you should do
data science evidence you act so so
they're tagged every play they don't
want search and then you have pages per
individual like airplane flight 71
routes airline one will show
and they link between each other
providing drill down and interactive
there so this is the home page page
about Airlines activates be very
surprised of the name but these are the
airlock colors for all domestic airlines
in u.s. in a lot of that type the first
story today is that two month wife
doesn't do a lot of trees because this
is the airline MC page so as I said we
call descriptions on Wikipedia to make
extremely easy to do it innings -
airplane pages by calendar and those
internally flights by best airline it's
people providing their activities URL
the other thing that is great for a
portal search engine elasticsearch make
CD we do have to be a bit of how speedy
provide like previous and next I
couldn't find a good plug into flats I
actually have to implement it you could
use what I wrote with a little bit of
trouble and then so we also start care
for atomicity as a whole so this is that
the airplanes paid with terrorizing us
leads the first iteration anything any
is some to take iterations so here's the
second iteration where I got with a lot
of tiny values that didn't really care
about much more interested in who make
up a fleet as a whole you can see here
McDonnell Douglas
it appeared mobile times and I overlap
the other wheel also through iterations
gets rid of the overlap and then the
fourth iteration does any resolution to
remove the duplicate Ozma conferences
now any resolution is really hard in
general and really complicated and could
be a zone top or series of top but in
this case I got away with just
okay with the first 10 characters and
let's group on those and then projects
the most common tag so Patricia
unemployed and then we get a charge that
sort of is count blowing down the fleet
of aircraft is a bit second and the tons
of small things like all our gear prayer
and you don't have to select the empty
series so the next level is ridiculous
but if you teaching for fun and profit
or the curator so that architecture for
the back ends of it is let me s horrible
Dedra on the GFS or in the cloud is
actually on your computer and then you
start the match model to train the model
we predicted this and then these are
streaming earlier so that it respond in
real time to conjure funny model on real
foundation and so it works really well
actually
this is sort of the top are sparks Mike
after you will set a tool in another
system or something like that
reemployment your model or creating your
own wait absurd predictions from a model
is not a lot of fun it could be either
going to keep you quite bar but yeah
this up so make sure to be back and get
that lease of universal bottle is it it
is it's medium size LT delicious taking
water step in it there's a new type of
asset I forget the name of it but it
will you can Princeton pointed at a
place minus 3
and if new records come into the file to
make up that table so process them as a
priority and to square it
yeah that's a nice thing that I have to
use digital edge
I think it's brand-new I personally
haven't you I don't think it is part of
part 2.1 I put into context a lot of it
is the site right now so this would
still probably be the same because the
like it's possible to transfer data
columns in real time all active learning
but it's much harder and there's you
can't easily do it and so I think you
would still train a batch and so this
reviews there but definitely for many
applications or new interesting way to
process and so the client designs
they're your web page with a phone class
and you have three serious which when
you submit the form
yes a lot of you deals and it's a
conservative class
why ask me about jobs actually of adding
all the fields that are in the training
data that aren't in the form like for
instance the day a year the day upon
these are features that I've had and so
it then submits a request for a
prediction let's pop a message in JSON
everything in the JSON because I've
never read it using JSON ever and I
haven't read music
Avro thrift and all of the others who
might have ever used in some sort of
like it's something she doesn't fit into
a JSON message just put in a block and
you're like leave the fungal up and so
start reading reading from the cost of
you respond to make the prediction
distorted and monarchy in the meet
wildest I got a UUID from this end point
that points them out a new URL where he
holds every section or however long walk
and get it on with the prediction window
guys you need time to just hold and so I
think our building is model extreme
vectorization so you tend to start with
data that renders that feel
and there get a number or strength what
you need them into machine learning is
matrix for vector format so in vector
format each row is a record and each
column here is a number but yet it's
like carrier the shading for nominal
type Oracle you have to inform the
caching trick so every be thousand of
that field yet be called so Delta giving
long everything at the column but all
Americans is one two best method for
that row Delta look like and on Europe
Beijing for definition to the Atlantic
one for this record like that but
overworked therefore chirality so this
is 109 lines of code to trim them off
note that scikit-learn 166 line sources
24 lines to get the ability to run this
on as many machines as you want which is
I think a small tax credibility and I
think is at least as keen as I could
learn although it's not quite of
teachers so if a prediction worked if it
has a lot of value than your job becomes
often ended or become someone's job you
could be a whole team full time job like
with people you may know anything to
drive an anti-business and probably a
paper and so this is butter that one
person once it work and then I clear to
a huge team that authorized it this is
the performance of the model of
counterpoint
once I set or you have to then set up an
experiment so that you can make one
change to the model run the experiment
and then check if it helped them out and
so that is overhead us that in
approximately
here we'll add a lot of lanes and then
the rest is we had to teach gypsy models
so there's a lot of ways to improve a
mod you can also search for
hyperparameters things that aren't
optimized by the machine learning you
have a sort of search for them at random
essentially to figure out probably like
a PhD data find us with know what each
one means I have no idea that my
research look pretty much most people do
and but yeah so it gets more complex but
it feels not you know that much to do
like for instance I was able to build
labovick filter in squash MLS in 20
lines of code does that recommend
content based on history of
recommendation remember literally 25
good in some ways more powerful than
that doing Wow I got to do it okay ah
this is e and D question if you kind of
doing on this hot be made as a basis of
this the fundamentals on TV speaking in
an equal sign with a professor but for
running this is all day yes
so the book covers everything from
researching the algorithm to deployment
into production you could literally take
it try to tell to hear it doesn't
perform very well but yeah and all
Walla Valley Chicago oil day often open
oh you mean I even tie sparkles opposed
to now Jupiter I'm trying to integrate
deeper to notebook into this process to
they're circling class process and they
just released in I haven't gotten is
working that yes they definitely have
their place they aren't interactive and
you can't drill down and you can't
search and so there's some above it and
you can't serve predictions but for
report and like I fear something we use
them in the book actually like to create
the initial model now there's charts and
things where so that yet is they're
awesome but I'm trying to integrate them
into this whole stack that haven't each
other yeah they're off yeah and
ultimately if I just like sort of think
about how to build tools that enable
this process yeah that might be one the
ability to kind of take up something
from a cheaper another book and turn it
into something interesting I'm not sure
okay thank you very much
[Applause]
