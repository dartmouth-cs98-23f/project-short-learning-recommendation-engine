youre doing it right now youre listening   to the words and the sentences that im forming  and you are forming some sort of comprehension   from it and when we ask a computer to do that  that is nlp or natural language processing   my name is martin keen im  a master inventor at ibm   and ive utilized nlp in a good number of  my invention disclosures nlp really has a   really high utility value in all sorts of ai  applications now nlp starts with something called   unstructured text what is that well thats  just what you and i say thats how we speak   so for example some unstructured text is  add eggs and milk to my shopping list   now you and i understand exactly what that means  but it is unstructured at least to a computer so what we need to do is to have a structured  representation of that same information that   a computer can process now that might look  something a bit more like this where we have a   shopping list element and then it has sub  elements within it like an item for eggs and an item for milk that is an example of  something that is structured now the job of natural language processing  is to translate between these two things   so nlp sits right in the middle here translating  between unstructured and structured data and when   we go from structure from unstructured here  to structured this way thats called nlu or   natural language understanding and when we  go this way from structured to unstructured   thats called natural language generation  or nlg were going to focus today primarily   on going from unstructured to structured in  natural language processing now lets think of   some use cases where nlp might be quite handy  first of all weve got machine translation now when we translate from one language to  another we need to understand the context of   that sentence its not just a case of taking  each individual word from say english and   then translating it into another language we  need to understand the overall structure   and context of whats being said and my  favorite example of this going horribly wrong   is if you take the phrase the spirit is willing  but the flesh is weak and you translate that from   english to russian and then you translate  that russian translation back into english   youre going to go from the spirit is willing  but the flesh is weak to something a bit more   like the vodka is good but the meat is  rotten which is really not the intended   context of that sentence whatsoever so  nlp can help with situations like that now   the the second kind of use case that i like  to mention relates to virtual assistants   and also to things like chatbots now a virtual  assistant thats something like siri or alexa   on your phone that is taking human utterances and  deriving a command to execute based upon that and   a chatbot is something similar except in written  language and thats taking written language and   then using it to traverse a decision tree in order  to take an action nlp is very helpful there   another use case is for sentiment analysis now  this is taking some text perhaps an email message   or a product review and trying to derive  the sentiment thats expressed within it   so for example is this product review a positive  sentiment or a negative sentiment is it written   as a serious statement or is it being sarcastic  we can use nlp to tell us and then finally   another good example is spam detection so this  is a case of looking at a given email message   and trying to drive is this a real email  message or is it spam and we can look for   pointers within the content of the message so  things like overused words or poor grammar or an   inappropriate claim of urgency can all indicate  that this is actually perhaps spam so those are   some of the things that nlp can provide but how  does it work well the thing with nlp is its not like one algorithm its actually more like a  bag of tools and you can apply these bag of tools   to be able to resolve some of these use cases  now the input to nlp is some unstructured text   so either some written text or spoken text that  has been converted to written text through a   speech to text algorithm once weve got that  the first stage of nlp is called tokenization this is about taking a string and breaking  it down into chunks so if we consider the   unstructured text weve got here add  eggs and milk to my shopping list   thats eight words that can be eight tokens   and from here on in we are going to work one  token at a time as we traverse through this now   the first stage once weve got things down into  tokens that we can perform is called stemming and this is all about deriving the word stem  for a given token so for example running   runs and ran the word stem for all three of  those is run were just kind of removing the   prefix and the suffixes and normalizing the  tense and were getting to the word stem   but stemming doesnt work well for every  token for example universal and university   well they dont really stem down to  universe for situations like that   there is another tool that we have  available and that is called lemmatization   and lemmatization takes a given token and learns  its meaning through a dictionary definition   and from there it can derive its root or its lem  so take better for example better is derived from   good so the root or the lem of better is good  the stem of better would be bet so you can see   that it is significant whether we use stemming  or we use lemmatization for a given token   now next thing we can do is we can do a  process called part of speech tagging and what this is doing is for a given token  its looking where that token is used within the   context of a sentence so take the word make for  example if i say im going to make dinner make   is a verb but if i ask you what make is your  laptop well make is now a noun so where that   token is used in the sentence matters part of  speech tagging can help us derive that context   and then finally another stage  is named entity recognition   and what this is asking is for a given token  is there an entity associated with it so   for example a token of arizona has an entity of a  us state whereas a token of ralph has an entity   of a persons name and these are some of the  tools that we can apply in this big bag of tools   that we have for nlp in order to get from this  unstructured human speech through to something   structured that a computer can understand and  once weve done that then we can apply that   structured data to all sorts of ai applications  now theres obviously a lot more to it than this   and ive included some links in the description if  youd like to know more but hopefully this made   some sense and that you were able to process some  of the natural language that ive shared today   thanks for watching if you have questions  please drop us a line below and if you want   to see more videos like this in the  future please like and subscribe 