we animate physical phenomena like cloth and fluids but animating characters remains a manual and tedious process traditional animation techniques tend to  produce stiff and unresponsive behaviors we are using reinforcement learning to develop more lifelike and responsive physically simulated characters our character learns to perform lifelike motions by imitating human motion data such as walking running and sword swings our character is put through an intense training regimen for 10 years in simulation thanks to nvidiaâ€™s massively parallel gpu simulator this just takes 3 days of real world time  the character then learns to perform a large variety of motor skills once the character has been trained it can use those skills  that it has learned to perform more complex tasks here the character is trained to run to a target object and knock it over we can also steer the character to walk in different directions like you would with a game character our model allows the character to automatically synthesize lifelike responsive behaviors to new situations we can also control the character using natural language commands for example we can tell the character to do a shield bash or swing its sword we hope this technology will eventually make animating simulated characters  as easy and seamless as talking to a real actor 