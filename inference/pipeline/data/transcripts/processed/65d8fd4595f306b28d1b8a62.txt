if youre looking for a machine learning tutorial with python and jupyter notebook this tutorial is for you youre going to learn how to solve a real world problem using machine learning and python were going to start off with a brief introduction to machine learning then were going to talk about the tools you need and after that were going to jump straight into the problem were going to solve youll learn how to build a model that can learn and predict the kind of music people like so by the end of this one hour tutorial you will have a good understanding of machine learning basics and youll be able to learn more intermediate to advanced level concepts you dont need any prior knowledge in machine learning but you need to know python fairly well if you dont ive got a couple of tutorials for you here on my channel the links are below this video im ashamed only and im super excited to be your instructor on this channel i have tons of programming tutorials that you might find helpful so be sure to subscribe as i upload new tutorials every week now lets jump in and get started in this section youre going to learn about machine learning which is a subset of ai or artificial intelligence its one of the trending topics in the world these days and its going to have a lot of applications in the future heres an example imagine i ask you to write a program to scan an image and tell if its a cat or a doc if you want to build this program using traditional programming techniques your program is going to get overly complex you will have to come up with lots of rules to look for specific curves edges and colors in an image to tell if its a cat or a dog but if i give you a black and white photo your rules may not work they may break then youll have to rewrite them or i might give you a picture of a cat or a dog from a different angle that you did not predict before so solving this problem using traditional programming techniques is going to get overly complex or sometimes impossible now to make the matter worse what if in the future i ask you to extend this program such that it supports three kinds of animals cats dogs and horses once again youll have to rewrite all those rules thats not gonna work so machine learning is a technique to solve these kind of problems and this is how it works we build a model or an engine and give it lots and lots of data for example we give you thousands or tens of thousands of pictures of cats and dogs our model will then find and learn patterns in the input data so we can give it a new picture of a cat that it hasnt seen before and ask it is it a cat or a dog or a horse and it will tell us with a certain level of accuracy the more input data we give it the more accurate our model is going to be so that was a very basic example but machine learning has other applications in selfdriving cars robotics language processing vision processing forecasting things like stock market trends and the weather games and so on so thats the basic idea about machine learning next well look at machine learning in action a machine learning project involves a number of steps the first step is to import our data which often comes in the form of a csv file you might have a database with lots of data we can simply export that data and store it in a csv file for the purpose of our machine learning project so we import our data next we need to clean it and this involves tasks such as removing duplicated data if you have duplicates in the data we dont want to feed this to our model because otherwise our model will learn bad patterns in the data and it will produce the wrong result so we should make sure that our input data is in a good and clean shape if there are data that is irrelevant we should remove them if they are duplicated or incomplete we can remove or modify them if our data is textbased like the name of countries or genres of music or cats and dogs we need to convert them to numerical values so this step really depends on the kind of data were working with every project is different now that we have a clean data set we need to split it into two segments one for training our model and the other for testing it to make sure that our model produces the right result for example if you have a thousand pictures of cats and dogs we can reserve eighty percent for training and the other 20 for testing the next step is to create a model and this involves selecting an algorithm to analyze the data there are so many different machine learning algorithms out there such as decision trees neural networks and so on each algorithm has pros and cons in terms of accuracy and performance so the algorithm you choose depends on the kind of problem youre trying to solve and your input data now the good news is that we dont have to explicitly program an algorithm there are libraries out there that provide these algorithms one of the most popular ones which we are going to look at in this tutorial is scikitlearn so we build a model using an algorithm next we need to train our model so we fitted our training data our model will then look for the patterns in the data so next we can ask it to make predictions back to our example of cats and dogs we can ask our model is this a cat or a dog and our model will make a prediction now the prediction is not always accurate in fact when you start out its very likely that your predictions are inaccurate so we need to evaluate the predictions and measure their accuracy then we need to get back to our model and either select a different algorithm that is going to produce a more accurate result for the kind of problem were trying to solve or finetune the parameters of our model so each algorithm has parameters that we can modify to optimize the accuracy so these are the high level steps that you follow in a machine learning project next well look at the libraries and tools for machine learning in this lecture were going to look at the popular python libraries that we use in machine learning projects the first one is numpy which provides a multidimensional array very very popular library the second one is pandas which is a data analysis library that provides a concept called data frame a data frame is a twodimensional data structure similar to an excel spreadsheet so we have rows and columns we can select data in a row or a column or a range of rows and columns again very very popular in machine learning and data science projects the third library is matplotlib which is a twodimensional plotting library for creating graphs and plots the next library is scikitlearn which is one of the most popular machine learning libraries that provides all these common algorithms like decision trees neural networks and so on now when working with machine learning projects we use an environment called jupiter for writing our code technically we can still use vs code or any other code editors but these editors are not ideal for machine learning projects because we frequently need to inspect the data and that is really hard in environments like vs code and terminal if youre working with a table of 10 or 20 columns visualizing this data in a terminal window is really really difficult and messy so thats why we use jupiter it makes it really easy to inspect our data now to install jupyter were going to use a platform called anaconda so head over to anacondacom download on this page you can download anaconda distribution for your operating system so we have distributions for windows mac and linux so lets go ahead and install anaconda for python 37 download all right so heres anaconda downloaded on my machine lets double click this all right first its going to run a program to determine if the software can be installed so lets continue and once again continue continue pretty easy continue one more time i agree with the license agreement okay you can use the default installation location so dont worry about that just click install give it a few seconds now the beautiful thing about anaconda is that it will install jupyter as well as all those popular data science libraries like numpy pandas and so on so we dont have to manually install this using pip all right now as part of the next step anaconda is suggesting to install microsoft vs code we already have this on our machine so we dont have to install it we can go with continue and close the installation now finally we can move this to trash because we dont need this installer in the future all right now open up a terminal window and type jupyter with a y space notebook this will start the notebook server on your machine so enter there you go this will start the notebook server on your machine you can see these default messages here dont worry about them now it automatically opens a browser window pointing to localhost port 888 this is what we call jupiter dashboard on this dashboard we have a few tabs the first tab is the files tab and by default this points to your home directory so every user on your machine has a home directory this is my home directory on mac you can see here we have a desktop folder as well as documents downloads and so on on your machine youre going to see different folders so someone on your machine you need to create a jupyter notebook im going to go to desktop heres my desktop i dont have anything here and then click new i want to create a notebook for python 3 in this notebook we can write python code and execute it line by line we can easily visualize our data as you will see over the next few videos so lets go ahead with this all right heres our first notebook you can see by default its called untitled lets change that to hello world so this is going to be the hello world of our machine learning project lets rename this now if you look at your desktop you can see this file helloworldi pi nb this is a jupiter notebook its kind of similar to our pi files where we write our python code but it includes additional data that jupiter uses to execute our code so back to our notebook lets do a print hello world and then click this run button here and heres the result printed in jupyter so we dont have to navigate back and forth between the terminal window we can see all the result right here next im going to show you how to load a data set from a csv file in jupyter all right in this lecture were going to download a data set from a very popular website called kagglecom gaggle is basically a place to do data science projects so the first thing you need to do is to create an account you can sign up with facebook google or using a custom email and password once you sign up then come back here on kagglecom here in the search bar search for video game sales this is the name of a very popular data set that were going to use in this lecture so here in this list you can see the first item with this kind of reddish icon so lets go with that as you can see this data set includes the sales data for more than 16 000 video games on this page you can see the description of various columns in this data set we have rank name platform year and so on so heres our data source its a csv file called vgsalescsv as you can see there are over 16 000 rows and 11 columns in this data set right below that you can see the first few records of this data set so heres our first record the ranking for this game is one its the wii sports game for we as the platform and it was released in year 2006 now what i want you to do is to go ahead and download this data set and as i told you before you need to sign in before you can download this so this will give you a zip file as you can see here heres our csv file now i want you to put this right next to your jupyter notebook on my machine that is on my desktop so im going to drag and drop this onto the desktop folder now if you look at the desktop you can see here is my jupyter hello world notebook and right next to that we have vgsalescsv with that we go back to our jupyter notebook lets remove the first line and instead import pandas as pd with this were importing pandas module and renaming it to pd so we dont have to type pandas dot several times in this code now lets type pd dot read underline csv and pass the name of our csv file that is vg salescsv now because this csv file is in the current folder right next to our jupyter notebook we can easily load it otherwise well have to supply the full path to this file so this returns a data frame object which is like an excel spreadsheet let me show you so we store it here and then we can simply type df to inspect it so one more time lets run this program heres our data frame with these rows and columns so we have rank name platform and so on now this data frame object has lots of attributes and methods that were not going to cover in this tutorial thats really beyond the scope of what were going to do so ill leave it up to you to read pandas documentation or follow other tutorials to learn about pandas data frames but in this lecture im going to show you some of the most useful methods and attributes the first one is shape so shape lets run this one more time so heres the shape of this data set we have over 16 000 records and 11 columns technically this is a two dimensional array of sixteen thousand and eleven okay now you can see here we have another segment for writing code so we dont have to write all the code in the first segment so here in the second segment we can call one of the methods of the data frame that is df dot describe now when we run this program we can see the output for each segment right next to it so heres our first segment here we have these three lines and this is the output of the last line below that we have our second segment here were calling the describe method and right below that we have the output of this segment so this is the beauty of jupiter we can easily visualize our data doing this with vs code and terminal windows is really tedious and clunky so what is this describe method returning basically its returning some basic information about each column in this data set so as you saw earlier we have columns like rank year and so on these are the columns with numerical values now for each column we have the count which is the number of records in that column you can see our rank column has 16 598 records whereas the year column has 16 327 records so this shows that some of our records dont have the value for the year column we have no values so in a real data science or machine learning project well have to use some techniques to clean up our data set one option is to remove the records that dont have a value for the year column or we can assign them a default value that really depends on the project now another attribute for each column is mean so this is the average of all the values now in the case of the rank column this value doesnt really matter but look at the year so the average year for all these video games in our data set is 2006 and this might be important in the problem were trying to solve we also have standard deviation which is a measure to quantify the amount of variation in our set of values below that we have min as an example the minimum value for the year column is 1980 so quite often when we work with a new data set we call the describe method to get some basic statistics about our data let me show you another useful attribute so in the next segment lets type dfvalues lets run this as you can see this returns a twodimensional array this square bracket indicates the outer array and the second one represents the inner array so the first element in our outer array is an array itself these are the values in this array which basically represent the first row in our data set so the video game with ranking 1 which is called wii sports so this was a basic overview of pandos data frames in the next lecture im going to show you some of the useful shortcuts of jupyter in this lecture im going to show you some of the most useful shortcuts in jupyter now the first thing i want you to pay attention to is this green bar on the left this indicates that this cell is currently in the edit mode so we can write code here now if we press the escape key green turns to blue and that means this cell is currently in the command mode so basically the activated cell can be either in the edit mode or the command mode depending on the mode we have different shortcuts so here were currently in the command mode if we press h we can see the list of all the keyboard shortcuts right above this list you can see mac os modifier keys these are the extra keys that we have on a mac keyboard if youre a windows user youre not going to see this so as an example here is the shape of the command key this is control this is option and so on with this guideline you can easily understand the shortcut associated with each command let me show you so here we have all the commands when a cell is in the command mode for example we have this command open the command palette this is exactly like the command palette that we have in vs code heres a shortcut to execute this command that is command shift and f okay so here we have lots of shortcuts of course youre not going to use all of them all the time but its good to have a quick look here to see what is available for you with this shortcuts you can write code much faster so let me show you some of the most useful ones im going to close this now with our first cell in the command mode im going to press b and this inserts a new cell below this cell we can also go back to our first cell press escape now the cell is in the command mode we can insert an empty cell above this cell by pressing a so either a or b a for above and b for below okay now if you dont want this cell you can press d twice to delete it like this now in the cell im going to print a hello world message so print hello world now to run the code in this cell we can click on the run button here so heres our print function and right below that you can see the output of this function but note that when you run a cell this will only execute the code in that cell in other words the code in other cells will not be executed let me show you what i mean so in the cell below this cell im going to delete the call to describe method instead im going to print ocean now im going to put the cursor back in this cell where we print the hello world message and run this cell so you can see hello world is displayed here but the cell below is still displaying the described table so we dont see the changes here now to solve this problem we can go to the cell menu on the top and run all cells together this can work for small projects but sometimes youre working with a large data set so if you want to run all these cells together its going to take a lot of time that is the reason jupiter saves the output of itself so we dont have to rerun that code if it hasnt changed so this notebook file that we have here includes our source code organized in cells as well as the output for each cell that is why its different from a regular pi file where we only have the source code here we also have autocompletion and intellisense so in the cell lets call df dataframe dot now if you press tab we can see all the attributes and methods in this object so lets call describe now with the cursor on the name of the method we can press shift and tab to see this tooltip that describes what this method does and what parameter it takes so here in front of signature you can see the describe method these are the parameters and their default value and right below that you can see the description of what this method does in this case it generates descriptive statistics that summarize the central tendency and so on similar to vs code we can also convert a line to comment by pressing command and slash on mac or control slash on windows like this now this line is a comment we can press the same shortcut one more time to remove the comment so these were some of the most useful shortcuts in jupyter now over the next few lectures were going to work on a real machine learning project but before we get there lets delete all the cells here so we start with only a single empty cell so here in this cell first im going to press the escape button now the cell is blue so we are in the command mode and we can delete the cell by pressing d twice there you go now the next cell is activated and its in the command mode so lets delete this as well we have two more cells to delete there you go and the last one like this so now we have an empty notebook with a single cell hey guys i just wanted to let you know that i have an online coding school at cordwindmarchcom where you can find plenty of courses on web and mobile development in fact i have a comprehensive python course that teaches you everything about python from the basics to more advanced concepts so after you watch this tutorial if you want to learn more you may want to look at my python course it comes with a 30 day money back guarantee and a certificate of completion you can add to your resume in case youre interested the link is below this video over the next few lectures were going to work on a real machine learning project imagine we have an online music store when our users sign up we ask their age and gender and based on their profile we recommend various music albums theyre likely to buy so in this project we want to use machine learning to increase sales so we want to build a model we feed this model with some sample data based on the existing users our model will learn the patterns in our data so we can ask it to make predictions when a user signs up we tell our model hey we have a new user with this profile what is the kind of music that this user is interested in our model will say jazz or hip hop or whatever and based on that we can make suggestions to the user so this is the problem were going to solve now back to the list of steps in a machine learning project first we need to import our data then we should prepare or clean it next we select a machine learning algorithm to build a model we train our model and ask it to make predictions and finally we evaluate our algorithm to see its accuracy if its not accurate we either fine tune our model or select a different algorithm so lets focus on the first step download the csv file below this video this is a very basic csv that ive created for this project its just some random made up data its not real so we have a table with three columns age gender and genre gender can either be one which represents a male or zero which represents a female here im making a few assumptions im assuming that men between 20 and 25 like hiphop men between 26 and 30 like jazz and after the age of 30 they like classical music for women im assuming that if theyre between 20 and 25 they like dance music if theyre between 26 and 30 they like acoustic music and just like men after the age of 30 they like classical music once again this is a madeup pattern its not the representation of the reality so lets go ahead and download this csv click on this dot dot icon here and download this file in my downloads folder here we have this musiccsv im going to drag and drop this onto desktop because thats where ive stored this hello world notebook so i want you to put the csv file right next to your jupyter notebook now back to our notebook we need to read the csv file so just like before first we need to import the pandas module so import pandas as pd and then well call pd that read analyze csv and the name of our file is musiccsv as you saw earlier this returns a data frame which is a twodimensional array similar to an excel spreadsheet so lets call that music underline data now lets inspect this music underline data to make sure we loaded everything properly so run so heres our data frame beautiful next minute to prepare or clean the data and thats the topic for the next lecture the second step in a machine learning project is cleaning or preparing the data and that involves tasks such as removing duplicates null values and so on now in this particular data set we dont have to do any kind of cleaning because we dont have any duplicates and as you can see all rows have values for all columns so we dont have null values but there is one thing we need to do we should split this data set into two separate data sets one with the first two columns which we refer to as the input set and the other with the last column which we refer to as the output set so when we train a model we give it two separate data sets the input set and the output set the output set which is in this case the genre column contains the predictions so were telling our model that if we have a user whos 20 years old and is a male they like hip hop once we train our model then we give it a new input set for example we say hey we have a new user who is 21 years old and is a male what is the genre of the music that this user probably likes as you can see in our input set we dont have a sample for a 21 year old male so were going to ask our model to predict that that is the reason we need to split this data set into two separate sets input and output so back to our code this data frame object has a method called drop now if you put the cursor under method name and press shift and tab you can see this tooltip so this is the signature of this drop method these are the parameters that we can pass here the parameter were going to use in this lecture is columns which is set to none by default with this parameter we can specify the columns we want to drop so in this case we set columns to an array with one string genre now this method doesnt actually modify the original data set in fact it will create a new data set but without this column so by convention we use a capital x to represent that data set so capital x equals this expression now lets inspect x so as you can see our input set or x includes these two columns age and gender it doesnt have the output or predictions next we need to create our output set so once again we start with our data frame music data using square brackets we can get all the values in a given column in this case genre once again this returns a new data set by convention we use a lowercase y to represent that so that is our output data set lets inspect that as well so in this data set we only have the predictions or the answers so we have prepared our data next we need to create a model using an algorithm the next step is to build a model using a machine learning algorithm there are so many algorithms out there and each algorithm has its pros and cons in terms of the performance and accuracy in this lecture were going to use a very simple algorithm called decision tree now the good news is that we dont have to explicitly program these algorithms theyre already implemented for us in a library called scikitlearn so here on the top from sklearn3 lets import the decision tree classifier so sklearn is the package that comes with scikitlearn library this is the most popular machine learning library in python in this package we have a module called tree and in this module we have a class called decision tree classifier this class implements the decision tree algorithm okay so now we need to create a new instance of this class so at the end lets create an object called model and set it to a new instance of decision tree classifier like this so now we have a model next we need to train it so it learns patterns in the data and that is pretty easy we call model that fit this method takes two data sets the input set and the output set so they are capital x and y now finally we need to ask our model to make a prediction so we can ask it what is the kind of music that a 21 year old male likes now before we do that lets temporarily inspect our initial data set that is music data so look what we got here as i told you earlier ive assumed that men between 20 and 25 like hiphop music but here we only have three samples for men aged 20 23 and 25 we dont have a sample for a 21 year old male so if you ask our model to predict the kind of music that a 21 year old male likes we expect it to say hip hop similarly ive assumed that women between 20 and 25 like dance music but we dont have a sample for a 22 year old female so once again if you ask our model to predict the kind of music that a 22 year old woman likes we expect it to say dance so with these assumptions lets go ahead and ask our model to make predictions so lets remove the last line and instead were going to call model dot predict this method takes a two dimensional array so heres the outer array in this array each element is an array so im going to pass another array here and in this array im going to pass a new input set a 21 year old male so 21 comma one that is like a new record in this table okay so this is one input set lets pass another input set for a 22year female so heres another array here we add 22 comma zero so were asking our model to make two predictions at the same time we get the result and store it in a variable called predictions and finally lets inspect that in our notebook run look what we got our model is saying that a 21 year old male likes hip hop and a 22 year old female likes dance music so our model could successfully make predictions here beautiful but wait a second building a model that makes predictions accurately is not always that easy as i told you earlier after we build a model we need to measure its accuracy and if its not accurate enough we should either fine tune it or build a model using a different algorithm so in the next lecture im going to show you how to measure the accuracy of a model in this lecture im going to show you how to measure the accuracy of your models now in order to do so first we need to split our data set into two sets one for training and the other for testing because right now were passing the entire data set for training the model and were using two samples for making predictions that is not enough to calculate the accuracy of a model a general rule of thumb is to allocate 70 to 80 percent of our data for training and the other twenty to thirty percent for testing then instead of passing only two samples for making predictions we can pass the data set we have for testing well get the predictions and then we can compare these predictions with the actual values in the test set based on that we can calculate the accuracy thats really easy all we have to do is to import a couple of functions and call them in this code let me show you so first on the top from sklearn the model underline selection module we import a function called train test split with this function we can easily split our data set into two sets for training and testing now right here after we define x and y sets we call this function so train test split we give it three arguments x y and a keyboard argument that specifies the size of our test data set so test underline size we set it to 02 so we are allocating 20 of our data for testing now this function returns a tuple so we can unpack it into four variables right here x underline train x underline test y underline train and y underline test so the first two variables are the input sets for training and testing and the other are the output sets for training and testing now when training our model instead of passing the entire data set we want to pass only the training data set so x underline train and y underline train also when making predictions instead of passing these two samples we pass x underline test so that is the data set that contains input values for testing now we get the predictions to calculate the accuracy we simply have to compare these predictions with the actual values we have in our output set for testing that is very easy first on the top we need to import a function so from sklearnmetrics metrics import accuracy underlying score now at the very end we call this function so accuracy score and give it two arguments y underline test which contains the expected values and predictions which contains the actual values now this function returns an accuracy score between zero to one so we can store it here and simply display it on the console so lets go ahead and run this program so the accuracy score is one or 100 percent but if we run this one more time were going to see a different result because every time we split our data set into training and test sets well have different data sets because this function randomly picks data for training and testing let me show you so put the cursor in the cell now you can see this cell is activated note that if you click this button here it will run this cell and also inserts a new cell below this cell let me show you so if i go to the second cell press escape button now we are in the command mode press d twice okay now its deleted if we click the run button you can see this code was executed and now we have a new cell so if you want to run our first cell multiple times every time we have to click this and then run it and then click again and run it its a little bit tedious so ill show you a shortcut activate the first cell and press ctrl and enter this runs the current cell without adding a new cell below it so back here lets run it multiple times okay now look the accuracy dropped to 075 its still good so the accuracy score here is somewhere between 75 to 100 but let me show you something if i change the test size from 02 to 08 so essentially were using only 20 of our data for training this model and were using the other 80 for testing now lets see what happens when we run this cell multiple times so control and enter look the accuracy immediately dropped to 04 one more time now 46 percent 40 26 its really really bad the reason this is happening is because we are using very little data for training this model this is one of the key concepts in machine learning the more data we give to our model and the cleaner the data is we get the better result so if we have duplicates irrelevant data or incomplete values our model will learn bad patterns in our data that is why its really important to clean our data before training our model now lets change this back to 02 run this one more time okay now the accuracy is one 75 percent now we drop to 50 again the reason this is happening is because we dont have enough data some machine learning problems require thousands or even millions of samples to train a model the more complex the problem is the more data we need for example here were only dealing with a table of three columns but if you want to build a model to tell if a picture is a cat or a dog or a horse or a lion well need millions of pictures the more animals we want to support the more pictures we need in the next lecture were going to talk about model persistence so this is a very basic implementation of building and training a model to make predictions now to simplify things i have removed all the code that we wrote in the last lecture for calculating the accuracy because in this lecture were going to focus on a different topic so basically we import our data set create a model train it and then ask it to make predictions now this piece of code that you see here is not what we want to run every time we have a new user or every time we want to make recommendations to an existing user because training a model can sometimes be really time consuming in this example were dealing with a very small data set that has only 20 records but in real applications we might have a data set with thousands or millions of samples training a model for that might take seconds minutes or even hours so that is why model persistence is important once in a while we build and train our model and then well save it to a file now next time we want to make predictions we simply load the model from the file and ask it to make predictions that model is already trained we dont need to retrain it its like an intelligent person so let me show you how to do this its very very easy on the top from sklearnexternals module we import lib this job live object has methods for saving and loading models so after we train our model we simply call joblib dot dump and give it two arguments our model and the name of the file in which we want to store this model lets call that music dash recommender dot job lib thats all we have to do now temporarily im going to comment out this line we dont want to make any predictions we just want to store our trained model in a file so lets run this cell with control and slash okay look in the output we have an array that contains the name of our model file so this is the return value of the dump method now back to our desktop right next to my notebook you can see our job live file this is where our model is stored its simply a binary file now back to our jupyter notebook as i told you before in a real application we dont want to train a model every time so lets comment out these few lines so ive selected these few lines on mac we can press command and slash on windows control slash okay these lines are commented out now this time instead of dumping our model were going to load it so we call the load method we dont have the model we simply pass the name of our model file this returns our trained model now with these two lines we can simply make predictions so earlier we assumed that men between 20 and 25 like hiphop music lets print predictions and see if our model is behaving correctly or not so control and enter there you go so this is how we persist and load models earlier in this section i told you that decision trees are the easiest to understand and thats why we started machine learning with decision trees in this lecture were going to export our model in a visual format so you will see how this model makes predictions that is really really cool let me show you so once again ive simplified this code so we simply import our data set create input and output sets create a model and train it thats all we are doing now i want you to follow along with me type everything exactly as i show you in this lecture dont worry about what everything means were going to come back to it shortly so on the top from sklearn import tree this object has a method for exporting our decision tree in a graphical format so after we train our model lets call tree dot export underline graph vis now here are a few arguments we need to pass the first argument is our model the second is the name of the output file so here were going to use keyword arguments because this method takes so many parameters and we want to selectively pass keyword arguments without worrying about their order so the parameter were going to set is out underline file lets set this to music dash recommender dot d o t this is the dot format which is a graph description language youll see that shortly the other parameter we want to set is feature underline names we set this to an array of two strings age and gender these are the features or the columns of our data set so they are the properties or features of our data okay the other parameter is class names so class underline names we should set this to the list of classes or labels we have in our output data set like hip hop jazz classical and so on so this y data set includes all the genres or all the classes of our data but theyre repeated a few times in this data set so here we call y dot unique this returns the unique list of classes now we should sort this alphabetically so we call the sorted function and pass the result a y dot unique the next parameter is label we set this to a string all once again dont worry about the details of these parameters were going to come back to this shortly so set label to all then round it to true and finally filled to true so this is the end result now lets run this cell using control and enter okay here we have a new file music recommender dot dot thats a little bit funny so we want to open this file with vs code so drag and drop this into a vs code window okay heres a dot format its a textual language for describing graphs now to visualize this graph we need to install an extension in vs code so on the left side click the extensions panel and search for dot dot look at the second extension here graphviz or dot language by staphon vs go ahead and install this extension and then reload vs code once you do that you can visualize this dot file so let me close this tab all right look at this dot dot here on the right side click this you should have a new menu open preview to the site so click that all right heres the visualization of our decision tree lets close the dot file there you go this is exactly how our model makes predictions so we have this binary tree which means every node can have a maximum of two children on top of each node we have a condition if this condition is true we go to the child node on the left side otherwise we go to the child node on the right side so lets see whats happening here the first condition is age less than or equal to 305 if this condition is false that means that user is 30 years or older so the genre of the music that theyre interested in is classical so here were classifying people based on their profile that is the reason we have the word class here so a user who is 30 years or older belongs to the class of classical or people who like classical music now what if this condition is true that means that user is younger than 30 so now we check the gender if its less than 05 which basically means if it equals to 0 then were dealing with a female so we go to the child node here now once again we have another condition so were dealing with a female who is younger than 30 once again we need to check their age so is the age less than 255 if thats the case then that user likes dance music otherwise they like acoustic music so this is the decision tree that our model uses to make predictions now if youre wondering why we have these floating point numbers like 255 these are basically the rules that our model generates based on the patterns that it finds in our data set as we give our model more data these rules will change so theyre not always the same also the more columns or more features we have our decision tree is going to get more complex currently we have only two features age and gender now back to our code let me quickly explain the meaning of all these parameters we set fill to true so each box or each node is filled with a color we set rounded to true so they have rounded corners we set label to all so every node has labels that we can read we set class names to the unique list of genres and thats for displaying the class for each node right here and we set feature names to age and gender so we can see the rules in our notes hey thank you for watching my tutorial i hope you learned a lot and youre excited to learn more if you enjoyed this tutorial please like and share it with others and be sure to subscribe to my channel as i upload new videos every week once again thank you and i wish you all the music best 