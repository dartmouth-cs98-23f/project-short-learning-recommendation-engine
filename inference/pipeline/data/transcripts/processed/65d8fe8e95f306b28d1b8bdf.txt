in this video i will try to give a broad overview of how a computer works from the ground up subtitles are available it will get a little bit technical but i will try to keep things as simple as possible there will be a summary at the end of every section and links to further explanations in the description hopefully this overview will teach you something new or give you a new perspective on things probably nobody in the world knows every single nuance of how a computer is built and operates this is why when you hear this sound beethovens 5th symphony that is a warning that i am making massive oversimplifications which im sure youll point out to me in the comments beethovens 5th symphony that was the warning for the entire video music modern computers at their core are electrical circuits a very simple circuit might consist of a battery connected to a switch then a light bulb then back to the negative terminal of the battery modern computer components typically supply a voltage of 33 or 5 volts between the positive terminal and the ground or negative terminal if you like to think of it that way computers treat information as binary on or off true or false one or zero based on if the voltage is high or low the important component in our circuit here is the push switch which comes in two flavors push to make thats when a person presses down and the circuit is completed between the two terminals and the bulb lights up  the push to break switch is exactly the opposite this is the symbol for a transistor more specifically its a metal oxide semiconductor field effect transistor or mosfet its source and drain are like the two terminals of a switch but it has a third terminal called a gate just like switches there are two types the nchannel type makes a circuit when a high voltage is applied to the gate like a push to make the pchannel breaks the circuit when a high voltage is applied like a push to break so transistors act like switches except instead of a person pressing it down a voltage is applied in modern computers these types of transistors are used in pairs referred to as cmos or complementary metal oxide semiconductor the gate terminals of a given pair are always connected together so they receive the same input here is a simple example if we apply a high voltage or 1 to the input the nchannel mosfet opens a route between high voltage and the output the pchannel closes the root to ground if we apply a low voltage or 0 at the input the pchannel opens a path to ground ok so this circuit seems pointless we got the same thing at the output as we did at the input but lets swap around the two mosfets now when we apply a high voltage or 1 to the input the ntype opens a route to low voltage or 0 when we apply a 0 to the input we get a 1 at the output whatever we put in at the input we get the opposite at the output later we will come back to how this forms the basis of all modern processors understand that it is vast networks of cmos pairs like these which allow computers to think beethovens 5th symphony for now lets see how transistor networks are made in basic terms silicon is a semiconductor with four valence electrons which is doped or mixed with other elements gallium for example has three valence electrons  one less than silicon hence more positive or ptype meanwhile an element like arsenic has five valence electrons  one more than silicon therefore adding a negative charge hence ntype trace amounts of these elements typically one for every million silicon atoms or so are implanted by chemical diffusion or by firing them out of a particle accelerator transistors are made by sandwiching a region of one of the dopants between two of the other lets look more closely at the nchannel configuration this by itself does not conduct electricity but when an electric field is applied to it a conducting channel forms hence the name field effect transistor this can be thought of in simple terms as the electric field attracting electrons from the ndoped region which has a surplus to the pdoped region which has a deficit near the semiconductor stack we have a conducting electrical terminal when its at high voltage an electric field forms and the transistor conducts but to stop a short circuit we need to add an insulating layer between them the contact is metal the insulator is silicon oxide and finally we have the doped semiconductor hence the term mosfet for a computer we need millions of interconnected cmos pairs and they must be small and close together so that electrical signals can travel between them quickly making a processor typically begins with a solid block of pdoped silicon called a die transistors are then created on top of the die by a process called lithography writing on stone there are two main techniques used in lithography the first is deposition chemically building up a layer of controlled predetermined thickness across the entire die this means that for example ndoped silicon can be coated all over the top of the pdoped die unwanted surface material is then removed by a second technique called etching this is done by applying chemicals or hot plasma to the top of the die several steps are taken to ensure that the etching is targeted at specific areas and therefore material is removed selectively a chemical termed a photoresist is deposited onto the die light is shined through a mask exposing predetermined areas of the photoresist the exposed areas must be the same size or larger than the wavelength of light used hence very short wavelength ultraviolet light is used for the lithography a special etching method is used to remove only regions of photoresist which were exposed and nothing else this opens up gaps in the photoresist and then another etching method is used which targets everything except the unexposed photoresist finally the remaining photoresist is etched away as a result material has been removed wherever there are any gaps in the mask the two techniques of deposition and etching used in conjunction mean that the ntype dopants for all the transistors on the die can be added simultaneously next the silicon oxide is deposited and etched and finally metal is deposited and etched away to leave metal channels on top of the die these metal features form not just the conducting terminals of the transistors but also the tracks equivalent to wires in a circuit which connect the transistors as required every time photoresist is deposited exposed through a mask gaps are made and a die is etched finally the billions of transistors are assembled and connected together by this method there may be three cnos pairs with three different inputs then going out to four different cmos pairs somewhere else and so on and so on beethovens 5th symphony to summarize computers handle information as ones and zeros when voltage in an electrical circuit is either high or low transistors act as electronic switches changing between these two states the transistors always come in complementary pairs so when one half of the pair opens the other closes lithography is the process by which huge numbers of interconnected transistors are built up on a block of silicon music to understand why transistor networks are useful we need to talk about a branch of mathematical logic called boolean algebra rather than go into the full gory mathematical details i will just illustrate the basic concepts with some not too serious examples lets say some friends are choosing a restaurant alice is happy when the restaurant serves burgers bob is happy when the restaurant does not serve burgers we can think of evaluating restaurants in this case as something called a gate an object which takes a binary input true or false 1 or 0 and returns a binary output in this case the input is whether the restaurant has burgers and the output is if someone is happy with the restaurant for alice the gate is simple the output is the same as the input in electronic terms the circuit is just a connection for bob the gate is whats unimaginably called a not gate this is a symbol typically used to denote it in the previous section we have seen how this cmos pair acts as a not gate lets consider a more interesting example when the logic gates can have multiple inputs such gates have pretty straightforward names as well see now the friends are choosing restaurants which might serve pizza noodles both or neither alice is happy when the restaurant serves at least one of the two options or both this idea is represented by what is called an or gate this is the symbol bob wants choice so he wants both pizza and noodles on the menu hence the and gate charlie likes it if the restaurant serves pizza or noodles but not both lets say she thinks that they wouldnt do a good job if they werent specialized enough the corresponding gate is called exclusive or xor for short each of these gates also has a complementary gate basically the same gate with a not gate after it for example the nand gate gives a 0 when all its inputs are 1 and gives a 1 otherwise these complementary gates are denoted by the usual symbol with a circle at the output for a computer these and all other possible gates must be implemented through cmos pairs connecting two pairs as follows creates a nand gate the nchannel and pchannel transistors still work in pairs only when a high voltage or 1 is applied to both pairs of inputs do the paths to high voltage close and the path to ground opens so a 0 is output this is exactly the behavior of a nand gate the nand gate is important because its whats called universal this means that any other gate can be created out of nand gates as long as there are enough of them now there are more efficient ways to make certain gates but in essence this means that the problem of implementing logic gates through cmos pairs is solved there are also gates with three four or as many inputs as necessary for example take two and gates connected as shown here and they simply become a three input and gate and so on and so forth beethovens 5th symphony to summarize logic gates are conceptual mathematical objects which allow us to make deductions based on binary true or false statements for example if its true that today is saturday or today is sunday then its also true that today is the weekend we have now seen how the cmos pairs from the last section can be used to practically implement these gates in terms of electronic binary logic music now we shall see how computers handle numbers and use logic gate networks to do arithmetic we are all used to base 10 numbers meaning that there are 10 digits from 0 to 9 the digits represent multiples of powers of 10 which are 1 10 100 1000 and so on modern computers use base 2 numbers with just 2 digits 0 and 1 binary digits are multiples of powers of 2 which are 1 2 4 8 and so on for example in base 10 the number 953 is 9 times 100 plus 5 times 10 plus 3 times 1 in binary the number 1 0 1  is 1 times 4 plus 0 times 2 plus 1 times 1 which is 5 in base 10 any number in base 10 can be represented by a number in base 2 and vice versa to represent the number 1 0 1 3 electrical tracks in order would have their voltage on off on each of these tracks carries a binary digit or bit with three electrical tracks this is called a 3bit number there are similarly 4bit numbers 8bit numbers and so on of course the 4bit number 0 1 0 1 is equivalent to the 3bit number 1 0 1 lets consider adding together a pair of 1bit numbers a and b to get c 0  0  0 0  1  1 what happens when we try to add 1  1 in binary the same thing as happens when we add 5  5 in regular base 10 there is no digit big enough so we put a 0 in that column and carry the 1 to the next column so to guarantee being able to store the result for any possible values of a and b the result c must be a 2bit number the bit on the right is 1 when a or b is 1 but not both this is the behavior of the xor gate if you recall charlie from the last section the bit on the left is 1 only if a and b are 1 ergo the and gate therefore c is obtained by connecting a and b to gates like this when adding numbers a and b larger than 1bit things get more complicated with three input gates because there is now a bit from a a bit from b and a carried bit as i said in the previous section nand gates are universal meaning any required gate network can be implemented using enough of them beethovens 5th symphony in base 10 multiplying by 10 is easy just add a 0 onto the end of your number in base 2 the same is true for multiplying by 10 in binary or 2 in base 10 so multiplying by the numbers 10 100 1000 in binary just involves shifting each bit to the left and putting a 0 on the end which is unimaginably called a bit shift what about multiplying by an arbitrary number say for example 11 in binary this is the same as multiplying by 10 multiplying by 1 and adding the two together so binary multiplication of a by an arbitrary number b works as follows begin with zero if the rightmost bit of b is 1 add a bit shift a once and if the next bit of b is 1 add this to the total continue for every bit of b computers also rely on making comparisons of numbers such as is a equal to b is a greater than b and so on the computer might have the current time in seconds stored as a binary number a updated every second and the time to set up an alarm stored as b the alarm would be made to go off when a is equal to b to do this the computer must check that every bit of the number a is the same as the corresponding bit of b so the xor gate returns 1 when an input is 1 and the other input is 0 in other words when its inputs are different the xnor gate which is the complement of the xor meaning it returns the opposite to the xor therefore returns a 1 when its inputs are the same a bunch of xnor gates applied to each pair of bits of a and b return whether those bits are equal or not the and gate returns a 1 when all its inputs are 1 so applying it to the xnor gates returns a single bit which is 1 if and only if a is equal to b there are also ways to implement subtraction division and other comparisons all using gate networks for example bit shifting the other way divides a number by two these are all implemented using transistors etched on a chip just a note when i say the word number in this video i am referring to an integer or whole number there is also a way to store fractions in a binary version of scientific notation called floating point numbers or floats i wont go into how they work but the general principle outlined here still applies to summarize a sequence of binary on off electrical signals is used by computers to represent a number in base 2 as opposed to base 10 which is used by people day to day networks of logic gates can be used to add subtract and compare binary numbers and with a few extra steps multiply and divide them too music we have seen how circuits composed of transistors can be used to implement addition and other algebra for any number with arbitrary binary digits or bits if you want to build a computer we would have to choose exactly how many electrical tracks and gates to have available for representing a number this is like when youre filling in a form and it has a set number of boxes physically printed on it for putting in your age for commercial computers this is always a multiple of 8 8 bits are called a byte the computer will have adder circuits and so on with the types i described in the last section which take 1 byte or 8bit numbers 2 byte or 16bit numbers 4 byte or 32bit numbers as inputs no matter of how many bytes a number is comprised one of its bits can be set aside to denote a plus or minus sign when a number is signed in this way if the leading bit is 0 then the number is positive if the leading bit is 1 then the number is negative as anyone who has ever taken a mathematics exam knows its important to store your workings whichever operation a computer undertakes the inputs and outputs must be somehow stored to do this a type of circuit called a latch is used once it has latched it will stay that way for a long time and can therefore be used to store a bit of data 8 latches store a byte and so on this is an example of whats called a dlatch comprised of nand gates you may notice that this looks rather strange before weve seen gates in a strictly sequential manner where the output of one gate goes directly to another now there is an output from one going to the input of another but then the output comes right back it is this kind of interconnection that allows this network of gates to hold and retain its output value 0 or 1 nothing will change unless the e or enable input is 1 when enable is 1 whatever bit is applied to d will propagate to the output the computer will carry out an operation addition for example enable a bunch of latch circuits to store the output and then switch the enable back off the result will then be held there as long as is required 8 of these latches can form register which will store a byte of data as long as its required an add circuit of the type we looked at in the previous section would have such registers to store the inputs before the addition takes place and a register to capture the result of the addition it takes some small but significant amount of time for electrical signals to propagate  for transistors to finish switching and so on to guarantee that the operation is fully carried out before attempting to read out the answer all computers have a clock in basic terms an oscillating crystal switches the voltage on and off on and off at a very specific rate at the time when this video was made computer processors have typical clock speeds of 2 gigahertz meaning that the clock switches at 2 billion times a second the regular switching allows events to be synchronized to fully carry out an addition operation it will take at least 3 clock cycles on the first clock cycle numbers would be loaded into the input registers then the addition circuit can work over the next clock cycle finally on the third clock cycle the output register gets an enable signal and stores the result actually most operations take much longer than one or even three clock cycles to carry out we have seen in the previous section that multiplication takes several adding steps to accomplish nonetheless whether it takes one or a hundred cycles the clock is still used to synchronize when an operation begins until the output is ready all the socalled arithmetic logic that is all the arrays of logic gates which do addition and subtraction is physically located together with the registers on a chip called the processor or  central processing unit there are also circuits in there called the cache which nowadays can store tens of kilobytes of data as the intermediate stages of calculations for example there is a need for a larger and longer term way to store many more bytes of data than the registers and the cache computers have separate physical chips of random access memory or ram which makes use of capacitors to store this data if a capacitor is charged it has a high voltage and therefore a value of 1 if its discharged it has 0 volts relative to ground and so is 0 the charge leaks or is lost over time but is topped up by the memory circuits as long as the computer is powered a typical laptop computer has tens of gigabytes or billions of bytes of ram every byte stored in ram has its own address like a post box in an apartment block the address is itself a binary number the ram has many transistors forming gate networks which ensure that when it receives the address in binary format from the processor it then returns the byte stored at that address until recently computers wouldnt usually have more than 4 gigabytes of ram each of those bytes requires a unique address so memory addresses were 32bit numbers such 32bit numbers go up to just over 4 billion so that used to be fine when ram got bigger there effectively werent enough addresses so now 64bit numbers are used for memory addresses this is the difference between 32 and 64bit programs so lets say youre playing a video game where you have a number of coins in your wallet the video game will keep track of the address where the wallet total is stored if you found eight more coins the game will fetch the number currently in your wallet from that address load it into the register load a biary number corresponding to 8 in base 10 into the other register add them together and put the results back into the address with the wallet total we will look at this in more detail in the next section computers also store huge volumes of data on hard disk for decades at a time even without power a hard disk is covered in tiny magnetic domains which can point up or down corresponding to 1 or 0 as the disk spins a sensor head can either passively read off the orientation of the magnets as bits or actively flip the orientation of the magnetic domains to write data onto the disk each of the bytes also has its own separate address a laptop or personal computer can store hundreds of gigabytes on a hard disk there are other technologies like flash memory dvds and so on that i wont go into here the fundamental limit on how fast a computer can do operations is the speed of light which can go about 15 centimeters or half a foot during a typical computer clock cycle so it would take multiple cycles for a computer larger than that to fetch any data realistically transistors switch much slower than that while a hard disk takes time to spin up and scan to read the data in terms of types of computer memory the cache is small but quick to access the ram stores many more bytes of data but takes longer to read the hard disk takes the longest to read but stores a lot of data almost permanently so there is a tradeoff between how quickly the data can be retrieved and how much can be stored from now on in this video i will explain things as if the computer just has a single pool of memory which it can instantly read in reality things are more complicated as ive just described beethovens 5th symphony to summarize computers have a clock which synchronizes the operations being performed and ensures that there is enough time to finish performing one operation before starting another computers process binary numbers in groups of 8 bits called a byte registers are used to store numbers during computations and at other times numbers are stored in the cache in random access memory and on a hard disk each byte in memory has its own unique address which is itself a binary number music we have a way of implementing binary operations and storing the results but the computer needs a way to determine which operation to use and when this is called an instruction there are instructions such as add two numbers and copy this number computers use whats known as the von neumann architecture which means that the instructions are stored in memory as binary numbers amongst other data for example the instruction number 16 and base 10 or this byte in binary might mean add together two 8bit numbers and store the result instruction number 17 might mean the same thing but for 16bit numbers and so on when the computer encounters an instruction it will use a comparison circuit which we looked at in a previous section to switch on the logic circuit for the necessary operation if the byte is equal to 16 switch on the add circuit how does the computer know when a byte is an instruction or not 16 might be the instruction to add or it might be the number of coins in a video game well everything has to do with a precise order in which the bytes appear in memory first comes the instruction byte if the instruction is to add the computer will need the two memory addresses of the things being added and the memory address where the result is to be stored remember that memory is like post boxes for a big apartment building with a unique address on each byte in the case of modern 64bit systems addresses are 8 bytes long therefore the entire add instruction has one instruction byte and 24 bytes of addresses 25 in total on the other hand if the instruction is to copy a number it just needs to be followed by the origin and destination addresses meaning the whole thing takes 17 bytes in total the trick is that each type of instruction always takes up a set number of bytes and  crucially  the next instruction immediately follows on after the previous one so when the computer encounters the add instruction not only does it carry it out but it knows that the next instruction is precisely 25 bytes along to start with the computer interprets byte number 0  the one at the very start of memory  as an instruction and thereafter goes from instruction to instruction conversely if there has been an error and the next instruction is not where its supposed to be  tough luck the computer will probably crash how does the computer actually carry out an add instruction the number from the first address is loaded into one input register and the second address into another input register the add circuit is enabled and it does the addition then after a sufficient number of clock cycles the result can be written from the output register to the required address in memory what happens if the instruction is to add two 16bit numbers together the computer simply goes to the address of number a and instead of getting just one byte it gets that byte and then one immediately after the same for number b and the result c beethovens 5th symphony a computer program is a collection of instructions and addresses to be done in order the computer goes from instruction to instruction to make the program run lets look at a specific example part of the game which is just a program after all where the player has a wallet with coins in this is what the contents of memory might look like byte number 0 is the instruction to add then come two addresses the address of the wallet total and the number of coins the player has just found the third address is the wallet again after the addition the wallet total will be overwritten no matter what the computer will now interpret byte number 25 in memory as an instruction it is another add instruction the addresses of the wallet and the amount of coins the player has made from selling items are the inputs the wallet address is the output again the next instruction is 25 bytes further along at byte 49 the program keeps going on with millions of other instructions required to make the game function in this case the wallet total is being used a lot so it will probably be held long term in the processors cache as well as the ram when the player saves the game it will be written to a save file on the computers hard disk to summarize the computer interprets certain bytes in memory as instructions for which operation to carry out computer programs are stored in memory they are just large sequences of instructions memory addresses and numbers the computer goes from instruction to instruction like clockwork always knowing based on the type of the current instruction how far along the next one is music so far weve looked at instructions which work in a linear manner copy a number add two together and so on the program would always produce the same result and eventually it would just get to the end of memory and stop we need a few more instructions to make a computer whats known as turing complete being turing complete means that it can eventually carry out any possible computation load a web page render video game and so on the only difference between two turing complete computers is how fast they are at doing those computations the first type of instruction a computer needs is whats called a jump or sometimes called a go to following the instruction byte is a memory address as the name suggests instead of going directly to the next instruction in memory the program jumps to the specified memory address and carries out the instruction there this means that the program can now do a loop in our video game example we have seen how instructions are used to add numbers of coins to a total kept in a wallet these instructions and all the others required to update the game world render the graphics and so on are followed by a jump instruction back to the start this way the game can keep running indefinitely the other crucial type of instruction that a computer needs is a branching or conditional instruction if a given condition is met for example if two numbers are equal then jump to a particular address we have already seen how a comparison can be implemented with logic gates adding such logic makes a jump conditional allowing different sets of instructions to be executed based on calculations performed so far or inputs to the computer such as a keyboard or mouse with conditional jumps the computer is turing complete given enough time it can do any calculation at this point its worth mentioning how a real program might actually be written if you thought that things were quite confusing so far youre not wrong remembering which instruction does what which memory addresses have what data stored in them where jumps go and so on this is all hard to keep track of programmers typically work with what are referred to as high level programming languages this means that all the nuts and bolts of instructions and memory addresses are hidden away and instead life is made easier for the programmer for example this is a bit of code in the c or c language this code is readable by humans if a is greater than b set q to be a otherwise when b is greater or equal to a set q to be b in other words the number q will end up with whichever number is larger out of a or b this is easy to understand for the programmer and anyone who tries to read it a program called a compiler will take this code and arrange it into the correct set of instructions sort out where the variables are stored in memory where to jump do we need to use 16bit or 32bit numbers and so on this is whats referred to as compiling the code there are many aspects of programming languages which simplify the job of the programmer but one of the most important is the idea of a function or method in mathematics the square root is a function which takes a number and returns another certainly there are implementations of the square root function in computer code but there are also more arbitrary functions and methods such as for fetching emails and so on say that a program needs to evaluate the square root of different numbers repeatedly the instructions which comprise the square root function need only be stored in memory once whenever the function needs to be used or called the computer will jump to the functions location in memory carry out the instructions and jump back with the result to the place in the program where it left off functions and methods can be compiled into libraries so that programmers across time and space can share useful code that theyve written if youve ever seen a dll file on windows thats what that is once a function or method has been written efficiently other programmers can use it without needing to spend much time on it beethovens 5th symphony to summarize computers have an instruction to jump to a memory address and carry out whatever instruction is there this allows loops within programs some jumps only happen when a condition is met any computer that is capable of such jumps can carry out any computation as long as it has enough memory and time to do so music chances are youre watching this video on some sort of display there are many technologies past and present which have been used for computer monitors so i will speak in generalities light bulbs like at the start of the video are too large but light emitting diodes or leds are smaller and more efficient the higher the voltage across an led the brighter it is a display is capable of electronically changing the voltage across each of its leds and therefore their brightness according to data from the computer since computers handle numbers in bytes in other words groups of 8 bits it makes sense to have the brightness go up on a scale from 0 to 255  the largest value a byte can take the human eye has cells sensitive to red green and blue light by using a set of three leds red green and blue varying the relative brightness of each one the human eye can be tricked into perceiving the full spectrum of light a mix of red and green gives yellows and browns red and blue gives pinks all three colors at full brightness give white and at partial brightness give grey and so on a little spot composed of three colors like this no matter what technology is used is called a pixel a display has pixels arranged in rows and columns to form a 2dimensional grid for example this video at maximum resolution is 1920 pixels in width by 1080 pixels in height the number of bytes it takes to fill a display in memory is 3 times the width times the height in simplest terms the computer must update this many bytes in memory 30 or 60 times per second and send the result to the display so for example if you full screen this video in its maximum resolution each frame would take up this many bytes in memory while displaying graphics and images may seem like a purely artistic undertaking and in some sense it is in actual fact for a computer it is nothing more than gate logic and instructions we have seen so far each pixel has a horizontal or x coordinate and a vertical or y coordinate which corresponds to its position in memory for example lets say your display is exactly a thousand pixels wide and you start with the top left pixel if you move forward three thousand bytes in memory or the equivalent of a thousand pixels youll go off the end of the top row and onto the left pixel of the second row there are many algorithms or long lists of instructions to draw windows buttons text and computer graphics all by using this kind of arithmetic and manipulating bytes in memory to display a simple desktop environment a loop fills every pixel with the background color by repeatedly copying the sequence of three bytes that uniquely defines the color the taskbar is drawn by looping over only rows of pixels with specific y coordinates a start button is created by filling a rectangle with a given range of x and y coordinates with another color text is added on top by copying predetermined patterns of pixels for each letter or through some other algorithm to display a window its necessary to know its specific width and height and the current position of its top left pixel adding the x value of the left pixel and the width by simple arithmetic gives the rightmost edge pixel a title bar can then be drawn along with a border text and so on if the user moves or resizes the window all of this arithmetic has to be redone and the window redrawn the simplest computer graphic involves drawing a line between two points both with their own set of coordinates xy the bresenham algorithm involves a loop which draws just such a line by following a straight xy curve familiar from school mathematics draw three lines and you have a triangle which can be filled with textures illuminated by simulated light sources and combined with thousands of others to make a 3d shape no matter how complicated it all comes down to addition multiplication and jump instructions compiled into functions sound is the other major form of output from a computer sounds are waves of high and low pressure moving through the air speakers and headphones produce sounds by moving a membrane back and forth there is a permanent magnet attached to the membrane inside a fixed conducting coil an oscillating current through the coil pulls the magnet in and out making the membrane oscillate and creating a sound the computer breaks up time into short steps and specifies the current at every step in time by sending a binary number to a sound card electronics turn the digital binary values into the appropriate current a microphone works in exactly the opposite way there are many input devices out there but the way a computer deals with inputs is usually the same the inputs leave socalled messages in memory which are groups of bytes of preset length identifying the device and what exactly the input consists of for example a message queue may have it three messages of eight bytes each when decoded the first one states that the a key has been pressed down the second states that the mouse has moved 30 pixels to the right and the third that the shift key has been released on a keyboard the keys are arranged into a grid  when a key is pressed it makes an electrical contact between a horizontal and vertical row allowing the precise key to be identified between the keyboard and the computers motherboard the message announcing when a key is pressed down or released is relayed to computer memory allowing the computer to act on it in our video game example imagine that the b button is used to buy things and the s button is used to sell in windows these key presses have corresponding decimal numbers 66 and 83 respectively in terms of instructions the game would have conditional jumps based on the value of the last keystroke if the keystroke value is 66 then a computer would jump to a set of instructions corresponding to buy if 83 it would jump to instructions corresponding to sell a computer mouse tracks how far left or right and up or down it has moved along a flat surface and also which buttons have been pressed a program typically the computers operating system keeps track of the x and y pixel coordinates of the mouse by adding or subtracting any changes in position received from the mouse say that a window with a button is currently active when a user presses down the left mouse button the program will check the x coordinate of the mouse cursor against the dimensions of the button if x is greater or equal to the left side of the button and less than or equal to the right side of the button then the click is horizontally inside the button the programs then check the ycoordinate is vertically inside the button too if both are true the button is considered pressed if at any moment you have 10 buttons on screen the program will check every button in turn if its been pressed down or not beethovens 5th symphony to summarize a computer display is a grid of pixels each one a group of a red a green and a blue light the brightness of each light is set by a corresponding byte in computer memory a pixel therefore has an arbitrary color and a group of them together makes an image sound is recorded by measuring the motion of sound waves and saving them as binary numbers in memory the reverse process is used to play back the sounds external devices send messages to the computer which are placed into memory allowing the computer to identify inputs such as when a key has been pressed or the mouse has been moved and then act upon them finally i want to take stock of the entire video i think its amazing how doping silicon with impurity elements and performing relatively simple logical operations allow us to watch and create videos process information and even inhabit virtual worlds computing is all about building up simpler concepts to achieve more complicated ones if youve got cmos pairs you can make a nand gate if youve got nand gates you can make any logic gate if you have logic gates you can make instructions if you have instructions you can make algorithms into functions from functions you can build up programs as complicated as you like this also means that computers are very dumb they have no intuition and must rigidly follow programs which have every possible eventuality spelled out in great detail 