 in this video we are going to discuss  introduction to dynamic programming  dynamic programming we use to solve optimization problems  optimization problem means where i have to find optimal answer  optimal means either i have to find  maximum answer or minimum answer  maximum means lets say if we are finding  profit then i will find maximum profit  lets say if i am finding cost then i will find minimum cost  so this is actually optimization problem  now optimization problem must be coming in your mind that we have solved this with greedy method  dynamic programming is also doing the same work  but there is a lot of difference in both the approaches  if we talk about greedy method what we  did there is lets say this is my source  source is connected to destination and  this is intermediate nodes in between  i have directed graph lets say this is my directed  graph and this is my source and destination  now these are intermediate nodes lets say i  have to reach destination from source  now here obviously what i will use i want to find minimum cost  what is the optimal answer you reach  destination from source with minimum cost  what does greedy method do lets  say this is distance this is 10 22  now what will greedy method do by default  it will choose this arrow or this edge only  reason for that is at the stage you  are standing at that stage the minimum one  means if we talk from cost point of view  who is giving the best answer s to a  so what will it do it will close both these paths  means it will not even look at this which one greedy method  because what we are doing is which one is the best out of these three this one so we are going above this now is it necessary  that it will always give right answer no  lets say the cost of the next path a to b is 100  and this cost is lets say 10 20  take anything 5 3 obviously here my cost is 2 i chose this first  now next cost a to b is 100 so obviously  what will be my wrong answer here  reason for that is at the stage you are standing  you have found the minimum solution here  this is the approach of greedy approach  but what does dynamic programming do  dynamic programming does not take  such decisions it will follow all the path  it will follow all the sequence of decisions  first it will traverse all those sequence of decisions  then it will reach a final solution so here  you can say that dynamic programming  always give the optimal answer yes greedy always give the optimal answer may or may not be true  as i told you in the example here what is  the method of greedy here it is failing  but dynamic programming will not fail  here because it will check all the paths  then it will give the final answer here  so the first point is here greedy  and dynamic programming actually divides  the problem into series of overlapping subproblems  means we are dividing a big problem into small subproblems  then we are combining the solutions of my subproblems  like we do in divide and conquer what we did in divide and conquer  like there is an example of merge sort so what we do in merge sort  we divide the array which we have into two parts then we divide it into two parts  in this way we convert it into subproblems then we combine these two  means we combine all the problems and convert it into a final answer again  but if we talk about dynamic programming here  then the first approach is also the same  means what is the first feature of these two features optimal substructure  what does optimal substructure mean that your problem is divisible  means your problem is divisible in parts in this way all the problems are being made  you solve all those problems and combine them and convert them into final answer  but the main difference is this from divide  and conquer dynamics that is overlapping subproblems  what does it mean by subproblems what  does it mean by overlapping subproblems  that all the problems here are repeated but  in divide and conquer nonoverlapping will come here  because it will not be repeated there  lets say if i take 5 3 2 1 10 20  if i take it like this lets say here  5 3 2 came here 1 10 20 came  here i have 5 and 3 came now when i combine  5 and 3 i obviously sorted these two  what do we do in merge sort  we sorted these two 3 and 5  now see 3 and 5 are not being repeated  anywhere else in the whole program  means all these problems are not being repeated  anywhere you solved it use it thats it  but in dynamic programming what are the  problems all the problems are repeated  what do you do with those repetitions you store them  so that you do not solve all the problems again and again  once you have solved it store it next time  if the same subproblem comes again  you pick up data from the direct table means pick up  data from the table where you have stored the result  how lets say if we take the example of fibonacci series  now how does the program work in fibonacci series lets say we have f of n  what do we do with f of n f of n1 plus f of n2 we convert it  means if my series is 0 1 2 3 4 5 so what is fibonacci series  fibonacci series is 0 on 0 1 on 1 next  1 plus 0 1 1 plus 1 2 2 plus 1 3 3 plus 2 5  5 plus 3 8 8 plus 5 13 it moves forward in this way  means here my actual recurrence relation  comes that f of n is equal to f of n1 plus n2  when will my f of n come when n value is 1  if my n value is 0 then my f of n will come 0  otherwise my recurrence relation becomes this now if i solve f of 4 here  if we solve f of 4 then what will happen f of 3 f of 2 see this is what we did  first of all optimal substructure means we  are dividing a problem so are we able to divide  yes we are able to divide what will we do next  f of 2 f of 1 what will we do with this  f of 1 f of 0 so see the problem is dividing  in your substructure in all the problems  but the second point here is overlapping subproblem  what does overlapping subproblem mean  when we solve this see leave level here i can write f of 1 f of 0  this f of 1 is already a small subproblem  this is also small now see here when i solve f of 1  how much answer did f of 1 give 1 when n value is 1 then the answer will be 1  when n value is 0 then the answer will be 0 what will  be 1 plus 0 1 so see what you do with f of 2 store it  now next time f of 2 is coming somewhere see f of 2 is being repeated here  f of 1 is being repeated f of 0 is being repeated so  you dont need to solve all these problems again and again  what you do is store the data in a table  means we have stored f of 2 f of 1 f of 0  f of 3 so that when the same subproblem will  be repeated again i have only written f of 4  if you try to write f of 10 or f of 11 then you will  see that a lot of subproblems are being repeated  that is called the overlapping subproblems  so what does dynamic programming do here  we will store these subproblems we will store their results so that we dont solve them again and again  because if we solve them again and again then  its time complexity order of 2 raised to power n  means exponential time complexity will  be created here but if you store it  lets say you have stored f of 2 f of 3 f of 4  that is how many functions will be opened  f of 4 f of 3 f of 2 1 and 0 you dont need to  solve this repetition again and again  so this is actually the foundation of dynamic  programming we will use this in multiple problems  like matrix chain multiplication multistage graph  we have a traveling salesman problem  longest common subsequence sum of subset  problem we use all these problems in them  even all pair shortest path 01 knapsack  what do we use in all these dynamic programming thank you 