moneys currently professor at the weights money institute he received his phd in 1989 from the university of california at berkeley and the interesting fact is that it was done under the supervision of mono and bloom he works in various fields of computer science mainly the foundation of cryptography and especially notable for creating nonmalay above cryptography visual cryptography with adi shamir and suggesting various methods for verifying that users for computer systems are human he was named an iac are a fellow in 2008 for fundamental contributions to the scientific foundation of cryptography and for sustained educational leadership in cryptology so this is what i found in wikipedia thank you so thank you for the invitation and for the opportunity to speak in such a a company so ill talk as you heard ill talk about cryptography data structures and match made in heaven so cryptography is a very old subject but it really started as an academic subject only in the mid seventies of course we keep papers of difficult and the rsa a insane and i also started around that time is like the earlier is computational complexity theory and there is a very tight relationship between the two the key idea of the cryptography you can say to use the intricate ability of some problems to the adventure your advantage the bad news of one area of the good news of the other he really in order to construct securities in based of that and this theme theres been a great great results the areas of complexity and the cryptography is really stimulated each other and there just to mention the whole pcp a sprung from started from a very from a question of what happens when you want to get zero knowledge without any conclusion you wont have perfect zero knowledge without any computational assumptions and key results in one area and were applied in the other in that played against traffic old message in your paper which is already pretty old by now paper did an address which he gave to fox in fox 97 to had the racer in the subtitle of cryptography and complexity match made in heaven so in homage to this title well talk about a data structure but before that news shafie goldwasser and silver macaulay are they turing award winners of this year it was just announced anyway and anyway the fishes of this talk is that actually cryptography data structures the area of data structures are quite familiar they really have enjoyed a very fertile a connection now but im unlike the computation completing the connection with complexity which was usually celebrated here are some how people hear it and did not celebrate the fact that you know im using this end and vice versa and there are actually many examples and then what ill do in this talk is give you some examples which of course are very biased sample of a of such developments so lets start with the first example its not the first example that exists but the first example i want to talk about thats hellmanns timespace tradeoffs so a helmet a when other another important development in the mid70s in terms of cryptography in addition to the invention of public key cryptography was the fact the introduction of the ds the data encryption standard because there was something that the standard of encryption of shared key encryption that was considered good and suddenly you know this problem well not clear whether it was all but at least was it something to talk about however what was the problem to have very short key 56 bits today its definitely very short but even back then it sounded like borderline in helmand but distilled to 256 if you want to do exhaustive search who is a pretty high number so what hellman pointed out is that actually you can do much better then spend two to the 56 all over again for each each time you want to break a ds and he asked the question suppose i have a function and i want to invert it how costly so if you aware your allow preprocessing so your pre processing and then you youre looking at how the cost of the vision of any additional breaking so if for instance if you build a table a large inversion table then of course its a roughly order 12 to invert it depending how costly it is to access the table but that requires a huge amount of storage so we probably want to have less storage and are willing to work a little anymore and so we we have some sort of limited space so then we are asking what is the best we can do in terms of time with you stay so what hellman showed a 19 a key is if you want to invert a permutation then you need storage s and time t 3 times s which is the n and if you want to invert functions it three times a squared n squared so well think of ts being lets say n to the twothirds and your capillaries their size is two to the little and that is the capital n is the size of their of the universe the number of a total number of keys that you can have so how did he work how did that work so lets say we have a permutation so then we have a permutation pile only hint how you do it for a permutation so we have a permutation pie you can lets for simplicity also think of it as one cyclic permutation doesnt really matter and so you can definitely go forward thats the advantage that you have you can go forward so in order to invert the permutation you can go all the way around you can apply to itself many many cups so if for instance instead of being a cyclic permutation it had only small cycles to do it would be very easy to invert the problem tation so the hardest case seems to be when there is a cyclic permutation so what did he suggest he suggested adding shortcuts ok so you add every t steps you add a shortcut ok so the shortcut tells you if you get him to go back a n minus the x in order to instead of going all this way this will think this would be a shortcut so this means that when you are going forward you only have to get to these special points so that you can make a shortcut and then the time to invert would be by going forward in using the shortcuts the time to invert would only be t so what you get is this sort of expression and this is true for permutations for functions things are a bit more complex and we we have the worst times im actually its a very interesting open problem to just to try to improve these things there are some lower bound in some models in is these lower bounds today there is a slightly different method the rainbow rainbow table method which is very popular but these are still very this is that these things are the most probably the most important thing a time memory tradeoffs style if you want to have online realtime style is a attacks and crypto system then probably youll be using something of that nature okay so this is hellmanns the timespace tradeoffs what is what is the connection to data structures okay so lets talk about the problem suppose that you have a bunch of books that you more many books and you want to arrange them on your on your shelf so that youll be able to search under both under title and under offer so you dont have any this is sort of an implicit date its an implicit data structure you dont have any other storage except their items themselves and you can already access them using a comparisons you cannot pay were not talking about ashley at this point later on well talk a lot about as you so we can only compare to you can compare the author and you see whether its larger or smaller you can compare the title so definitely the best you can hope for is order log in here and the issue is can you arrange so of course if you want to just offer it would be very easy if you want to just titled it would be very easy but the question is can you do both and one of my first papers while i was minerals bradley student with fear and superg much meat email encino we we came up with an order log in solution and im not going to show it and actually its true from many of the results just try to show the idea the relationship between the crypto and their data structure anyway so we came up with an idf so first you you split the records into katies if you have k not just two but you have k types of a split the records in 2k keys in 2k sets and what you want is that each set would be a nearly perfect sample for that key so you split according to let say title is some of the books are considered title books some of the books are considered off the books and its a very good sample so if you know where where you the book is if you say book if your book is not the book youre looking for is not according to it was not chosen as part of the title bouquet according to the title step youll know what where it should have been to within one or two locations and you can do such a you can do such a partitioning using whole sphere anyway so now the problem is of course you do you know roughly where it should be but its not sitting in the right place so what you have among the other books you have some sort of permutation of the original layer order so you want to search in this permutation hey now you dont have you know you dont know things exactly but thats okay you can actually add a few bits and then show how to store them so im not going to talk about all these things at all ill just mention that you still have you have you have the problem that you have a permutation where where the books say went with if your book was not in the thing you are looking for is not in there if youre looking for a book by title in the book that youre looking for is actually the author section so its its a order in some since um according to some permutation of what it should be and you can actually compute the permutation you can commute the forward presentation and youre trying to invert it and what did we use we use this sort of whatever hellman had exactly the helmet drake except that t here should be constant and we we were able to store a like some small constant some small constant times and pointers and then then store them in then show how to so we have exactly we could use exactly the idea of fair helmet and come up with a solution which took only where each computer will reach forward computation with its backward computation where it could be done in actually long time so we could search for the book all together in a long time so here we see an example an idea that came up in the crypt of literature shona in the a data structure one okay so lets move on and ask so if we look back at hellmanns work kiss his analysis the way he wrote it assumed a lot of randomness on the function the function that you are trying to invert he assumed was very random and even if you take various projections of it it it still remains random and its better to to work in a worstcase style i have a function f maybe i am assuming some computer tutorial properties that its say either permutation or it doesnt have too many a doesnt have too high integrate things like that but we dont want to assume that were trying to invert a random function because its not its a function related to das its not a random function so and what the question was whether you can come up with them with an analysis of hell hellmanns work without assuming anything about it and would work with amis fear we have a way of composing of the function if with a que ways independent a function g and and of course now if you have to if you want to invert f composed with g its right youll get from it something very similar to inverting if i mean in terms of if you can invert f composed with g youll also be able to invert if and the problem is that k now each time to evaluate the function you also have to value gee okay what should kb k should be roughly i mean i didnt show you the actual helmand construction but kate but k is going to be pretty large its going to be something like a capital n to the one third so its going to be very large value and we want to for each time we have to spend if well have if you look at the sort of traditional construction of k words independence using polynomials or whatever then thats very expensive then each time you want to evaluate the function you have to invest time into the one third so we were faced with this problem and im not going to tell you how we solve it back then but actually today there is a i will hint of how you can solve it today today there with relationship to data structures there are actually solutions of k ways independent functions that can be evaluated very quickly in order one okay so so lets switch to the dynamic dictionary to hashem problems so we we have there and we want to come up with a data structure for representing a set of words s from universe you and i guess the red you dont seem either or something anyway so the size of the set s will denote with red line and the size of the universe is little you and we want to be able to do look up in insert and delete and the performance we we look will consider look up time update time and the space the amount of space and so we want to actually constant time operation and minimal space consumption this is of course a very problem thats been investigated for guess the first analysis interesting analysis is clear fluids of linear probing breaking news but still the tradeoffs are not faithfully this is closed from that time to the time aerobic which i think in homes they had a you mentioned the canoe from 66 but you had a picture of him from much later and is closer in spirit anyway and so in work with my students you are between and gil segev we came up with a solution with for any polynomial number of sequence and look up insert and delete all operations take a constant time and the probability is over the initial randomness and it this segment is true that it all operations take constant time so fix concern with some probability 1 minus 1 over palm so again im not going to show you the whole thing im going to show you a few ideas which are related to crypto so you so first you may ask why are we so interested in worst case and not amortized or whatever so first if you are have some sort of youre using it in heart the hard way hardware type environment it may be very important because youre building it you dont want to waste too much a you dont want to waste the amount of hardware you need to invest is connected to the worst case so you dont want that another reason is comes actually from cryptography suppose you you somebody is trying to to perform a timing attack on you so you have clocked adversaries they look how long it takes you to respond and act accordingly so they can learn your internal randomness ok so you they can actually learn your return randomness and reconstruct the hash function from we saying which operations take a long time in which operations take little chi and there and therefore they can find bad inputs so if youre in any sort of adversarial environment its bad to use such such hash functions in general even if youre less more benign environment if it somehow inside an operating according to the time it takes to perform the operations lee the next operation is affected something like that youre losing the fact that the assumption that the adversary is oblivious to your randomness so we want to have the worst case type things all operations take exactly the same okay so in terms of space we may want now really the minimal amount of space so you want if youre storing every element out of the universe of size you you dont see some universe which i guess we cant see so there is a universal size you youll have a set of size and infirm a few are actually storing each element explicitly it takes you and log you a bits but you need we need less than that we need just a log you choose n bits to represent the set sign another out of you so you are wasting roughly n log n bits in when you is small when you is small polynomial event then this will be significant and for instance if youre doing bloom filters so bloom filter not the blunt filters youre doing a blood trail can show you want to solve the proximate set menu problem and so you have a subset again same type of subset we dont see the universe due to coloring problems and so you want to say yes on elements in the set you want to say no and i edelman sudden the set but youre willing to suffer some my error of gamma if its not in the same and here you can show if gamma is a sub constant amount of space you need is m blog 1 over gamma we dont know exactly for the dynamic case we dont know exactly when the set can change dynamically you dont know exactly how it behaves when gamma is a constant but certainly when when gamma sub constant and this becomes very significant and blog a 1 over gamma so this is the famous say they bloom data structure from 1970 solves this problem to a certain extent and but we can actually use dictionaries to solve it and get a slightly better solution at least again when the case for a gala which is constant simply by hashing hashing too small said hashing to a set of size n over gamma okay so you started from university you actually set of size n over gamma and you to insert x you need to store g of x and instead of a storing extra story reggie of x  m in order to check whether its in you check whether g of x is in the dictionary so now the problem that you have is during your universe is of size n over gamma and you dont have enough bits to to represent each element separately that would be very way from youll be getting something which is you wanna get getting such an expression the other hand if you have an optimal solution into optimal in terms of memory to the dictionary problem then you would have an expression like in may log 1 over gamma so just for comparison with a original bloom filter that will be kind another constant times they lost a loved one of the blog eat a so so whats the source of waste why how can you waste space in the hash table what is if its not full and apparel is not full so there are empty entries are really wasted were not going out going to describe how we solve that problem the other is youre using too much in order to represent an element its really if i youre using to represent an element log u bits but really there there is already if im searching for an element in location i there is a lot of information on the fact that i mean location lie it means that somehow the element led me to location i so dont really need to store all these things ok and were going to use this idea were going to use the idea that you we can get rid of some of these days so hey i think for some some of you will if you start the analogy if im if im up if if im standing and the fridges open it means that im hungry so i dont need to remember that im hungry right i can throw away this baby come hungry so this is the same thing if im looking at location if i i will music will be using our hash functions will be a permutation and well be using and a pi of x is the new identity of things and the prefix of the the new name is going to be the identity of the cell of where were going to search for me okay so when the cell is being probed we know the prefix there isnt any point in remembering you so essentially and so if were storing elements and benzene lets say then were searching inside the bills it is the second level level theyre really there isnt any point in storing all of this information inside the bin instead we can get rid of that part that tells us that this is a lettuce to want to go into point so too so we can store less information m so let me talk about cuckoo hashing because that will be important both for this and for for the next day application soco caching is a wonderful a scheme if you dont know it you should definitely you definitely should i think its one of the great inventions in computer science of the century it was suggested by your pine radler in 2001 and its extremely simple what theyre suggesting is your you have two tables he wanted me to each of size but if roughly larger than in and you have to hash functions h1 and h2 in order to do look up you have to look up in t1 and you have to look up in key to so you compute h1 to search for x what you do is you compute h 1 of x and woke up in a t1 you compute h 2 of x and you look up t to to see where its you these are the only two possible locations were a or egg neck skin be okay so look up is extremely simple to hash computations in two air lockers and and the nice trick is the insertion is also pretty simple and hence the name a coco it comes from their hookah bird it kicks away the eggs of other bird i suppose a north americans need this explanation because it only happens in europe in this area not in the north america the cuckoo birds dont behave like that so thats perhaps why im ridley from denmark anyway still are anyway so in order to put a look you put an x a location i h 1 of x if its if its empty great it wasnt empty you need to find a place for the guy that was there why and your insert it into the other table and again you kick out whoever was there etc so just do a simple example youre trying to insert a you you go to h1 of a is equal to h1 okay so you kick out a a goes through h2o its h2 of a why was there we need to find a place for ny h 1y was empty so you put it there and that the fing finishes so this is very simple though of course the question is why does it work and it doesnt always work but it works with reasonably high probability and it works if you look at the cook of graph then you have a set s defining such as you have here you have the you have a bipartite graph each location here corresponds to locations in the memory their worlds corresponds to 2 locations of the memory the edges correspond to elements and you have an edge connecting a edge connecting for each element x you have an edge h 1 of x iconic hdx and now the nice thing is the ss successfully stored if and only if every connected component in the cocoa graph has at most one cycle okay and the insertion algorithm achieves this so so this is pretty good except that youre wasting it well right you need a little more than twice as many elements so it roughly half for this thing to work roughly half the locations will need to be empty so there are various ways a very getting it to be denser and denser and in particular in our work we showed how you can actually work in bins and get improvable results but the point is that thats not enough in order to get a 1 plus a little o of one of the information theoretic now we need to get to to to use these permutations with image so in particular right you as i said you use the permutation and your partition you jump into part look at the pyxis partitioning compiles the first part tells you a what build it should go okay the left part tells you to what ben it should go and the second part is sort of the new identity will incur the new identity of the elements if its going to be in a certain bit there isnt any point in story so if we know that we know that its going to be in this billion been corresponding that we can throw away this part and install just fairness okay so we just scored this valued and can get so how do we get permutations so here we use again crypto we look at the construction of a feistel permutation that was in the construction of des used chrysler permutation theyre more the construction of mubarak of the pseudo random permutations using feist implementation and essentially what we have here is we petition to left parking right point we apply a function here which should be pretty random we know how to construct remember our problem is we have good constructions of pseudo elf ok wheres independent functions but not we dont have great constructions of the gateways independent permutations so what we do lets say is a step or or this we can do this isnt for its a little bit more involved but lets think of it as just pay one step you to apply a carriage independent function x or it with a left park and this tells us the pin number and our can remain unchanged this theres a new id this is and what we have here is some sort of a highly independent cash for the blood to i so that we can still represent it in sub linear space and so how so how do we get something that is close to okay wise independent permutation so we do this like so let me do it here we can get pi 1 and i 2 can be and just pairwise independent communications but here inside leave these two to these two permutations are constructed exactly as i showed before okay in each one of these functions f1 and f2 are going to be highly independent but there are functions or irritation the whole thing the whole result is a permutation and we get a we this we can get a collection of delta dependent permutation where theyll carry something like k squared over square root with you and you can compose a few of them and reduce the error so here weve used herein a basic idea of crypto of constructing pseudo random permutations in order to come up with the analog of the k was independent permutation that we we still dont know how to construct a so we still need so this is both in the work that i told you on making the helmets result rigorous and here we still need the ability to perform to come up with k wise independent a functions which can be evaluating the order one and have reasonably synced a representation so eh eh so lets go to our final application and also the construction later they still are you and thats hashing for domain extension so suppose that we have a pseudorandom function that operates on a fixed domain site so lets say it operates on n bits from n bits to embed some its like a super education so we want to construct a certain oral function on any domain size from m bits to a so we have one and fixed it maps n bits to n bits and we want to map am bits to anything so what can we do and we measure such construction by the domain now how large a new domain is the security is a simple random functions in general a win okay in general and we measure security of a server amel function by the number of queries you it can answer the time the time they tackle can attack it absolutely the distinguishing probability so we have a construction with katie and epsilon and we want to come up with a construction with k prime keep riding epsilon prime which are as good as possible ok so we measure the construction by how the deterioration of the security how worse ours are play prime v prime minister on prime or ours are compared to kten epsilon and the number of calls made to the underlying pseudorandom function so even if you look at the original gold right world vessel macaulay paper pseudorandom where functions construction of several functions you can apply and get it in such a reduction but it wouldnt be so good in terms of the number of a calls to the function wouldnt be a constant number of calls to the underlying pseudorandom function so what can we do luckily a levin had the idea and i think its already in the original paper paper in the original gg or maybe all paper but actually its explicitly described it in one of weddings paper much more so than many other ideas that are only hinted anyway so what you do is you in order to do to extend the domain you hash you use pairwise independent hashing go on the older nude large domain and you have to do the original domain whats the problem the problem is birthday so if you have few queries after something like use you cannot use it for more than q squared over 2 to the n applications because after a kiss after this many the probability of a collision is kims point of entry to the end so deterioration in terms of distinguish ability is q squared over 2 to the n the question is whether so thats its a very good constructions in terms of the number of applications right we applying just one hash function one hash function would you pay away so that could be very efficient and then then we are applying the original pseudorandom function so thats great in these terms but in terms of the security deterioration it doesnt work and you cannot do apply to to you cannot to do more than square root of 2 to the n name any queries so okay so what a we saw there have been various constructions trying to achieve it and in recent work with a tiger bearman the heightened and the inner villain lair komarovsky we came up with a construction that needed to call the original function the underlying function two times hey and this is of course reversed right security number of courses like this is the number of calls and this is the security in any way ah this also gives you suddenly strange anyway and i cant even blame the fact that its not my computer in this case i guess its my own doing anyway so they what happens in terms of security we can get we can get the security this should be here we can make the security they distinguish anon security to be as small as we which you can have two calls and other work to call so the underlying pseudorandom function plus other work and the security can be open from q 0  2 to them but it can be even smaller if you are willing to spend more work but not cryptographic work so how did we get it we did it by using other peoples work the best type of result you let other people do the work and then you just a snatch it in applied so the people who did the work were fine pop against blam blam another only one zoo could work together and they came up with a construction of highly independent functions that can be easily evaluated in the spirit of very cuckoo hashing so a then you need a happy well you need that their point was this is their construction so you have functions f1 and f2 which are going to be essentially a f1 and f2 are going to be think of f1 and f2 is truly random functions but where can you have to run a random function if you have a table if its just a table lookup so their domain is limited so so we will be applying h1 h1 is going to be something like login or blog or in our notation here ny is independent h2 is also going to be something like anyways independent remember anything the original number of bids were going to apply a h1 is going to map to a relatively small ff one man maps to 22 it is whatever independence we want so were going to bite so in order to evaluate the our hash function you have to apply they have to compute h 1 of x f to compute h 2 of x then apply f 10 to them if the pi f 22 them x or the result then the whole thing would be exhorted with another something like anyways independent function so n n is the number of bits when they say ni need the number of bits or in the rigid in whatever application whether in your and sorry it makes sense to talk about end when were talking about the crypto application and if were talking about they the data structure application will talk about login so rogan is still pretty little high but we can deal with that as well and not virgin until know in half and so so this is this is another way this is a pictorial way of viewing it again you have a large domain you apply the hash function you get a small domain you apply if you apply it from here you get your ex or the two results plus youre using another g for sort of those that didnt make it in what we showed with bypass road was a make sure this type of result if h the h a g these a functions these families if these families are a que wise independent an f is truly independent then the resulting family that we get is k over 2 to the k indistinguishable from random by any cake query nonadaptive distinguish ok so nonadaptive you seem so its not quite what we want we want if were trying to use it for whatever application both in the hashing both in the destruction occasion and in the domain extension application i think the adversary can be adaptive i mean certainly if you think of of adversaries in the context of silver and the functions they are adaptable think of them as a nap p so luckily the way the proof is written can you can easily get from it a stronger result and you can actually show that it holds for adaptive distinguishes as well again you can use their work in and get a this quite general statement that tells us that if you prove it in a certain combinatorial way you will be able to translate it and obtain a result that is good against a adaptive adversaries as well so the the way the domain extension would look like is something like what we saw before we will get will use an f would be the original children under like pseudo random function will have g and h which go which are k ways independent and the result would be we lose what dont lose anything in qu we lose a little in the time because we still need to evaluate lee the hash function and in terms of the deterioration in the epsilon when we get an expression of the form k over 2 2day a omega aq over to today a to the k so once once k is larger than log kill we started to getting a reasonable results and we can this is what i told you before we can make it as small as we wish okay so and this is it these are roughly the examples i wanted to show and i would end up with just one question is there a general theory that explains these tight relationship how come were getting so many were able to you to go back and forth between crypto and a data structure so easily is there its just a general explanation for the way this phenomenal thank you g takes care that the probability isnt smaller the probability of failure is something like 1 over the table size g takes care of failures makes the probability much much smaller oh then okay this film inger talking about a okay digital finger got rid of like oh glory still the original its finger fulfill your talking about that okay you are talking about a very old papers okay now that theyre not a space optimal but no but some of the work you did for bigger and volvo have a mean that they extended the pine  result to get rid of tony you can get rid of the the fact that you have law login independence that you can actually get it to order one independence you never have to work more than one order one so thats actually because it follows from work of this with this will be involved 