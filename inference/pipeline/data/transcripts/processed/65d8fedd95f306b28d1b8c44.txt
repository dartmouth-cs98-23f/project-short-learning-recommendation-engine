that computes anything in a flash or do problems exist that would stump even the most powerful computers imaginable how complex is too complex for computation these questions are central to a fascinating conundrum called the p versus np problem p versus np is one of the great unsolved problems in all of math and computer science or you know really in all of human knowledge if were being honest anyone who finds a solution could win a handsome 1 million prize offered by the clay institute and this solution could lead to breakthroughs in everything from medicine to artificial intelligence and even the perfect game of mario brothers but it would come at a cost a definitive answer to the p versus np problem could break your bank account and even lead to the end of the internet as we know it to find out why lets start with a simple logic puzzle a robot arrives in a foreign land where everyone either always tells the truth or always lies the robot reaches a fork in the road with two choices one path leads to safety in the land of truth tellers while the other leads to doom in the land of liars a sentry appears but its unclear which group they belong to what question can the robot ask to determine the safe route heres some options and heres the answer with this one question both types of sentries would point to the correct safe path allowing the robot to solve the problem quickly now what if the robot encounters multiple sentries and dozens of pathways leading who knows where what can it do to find safe passage compared to the first problem is a correct solution here proportionately more difficult to find or is it exponentially harder maybe theres a shortcut that could speed things up or maybe finding a solution to this complex situation is nearly impossible the question of how hard a problem is to solve lies at the very heart of an important field of computer science called computational complexity computational complexity is the study of the inherent resources such as time and space that are needed to solve computational problems such as factoring numbers for example and especially its the study of how those resources scale as the problems get bigger and bigger computational complexity theorists want to know which problems are solvable using clever algorithms and which problems are truly difficult maybe even practically impossible for computers to crack so how do computers solve problems in the first place a computers core function is to compute these machines perform basic mathematical operations like addition and multiplication faster than any human in 1936 a 23yearold british university student alan turing developed a fundamental theory of computation while attempting to solve a problem about the foundations of math turing claimed in a paper its possible to invent a machine which can compute any computable sequence given enough time and memory this simple theoretical turing machine which includes a place to store information and a device to read and write new information based on a set of instructions is the basic framework for all digital computers to come one of the key insights of computer science is that turing machines are mathematically equivalent to just about any other programming formalism that anyone has invented at least for conventional computers inside a digital computer data are represented as binary bits sequences of ones and zeros and these bits can be manipulated through logical operations using a branch of math that preceded the invention of computers called boolean algebra the basic rules of boolean algebra were formulated in 1847 by english mathematician george boole boolean algebra formulates decision problems yes or no problems that can be asked in sequence to answer complicated questions the output of a boolean function for any given input can be represented in whats called a truth table and it is either one or zero true or false expressions in boolean logic consist of multiple variables linked together by three logic gates and or not these logic gates work like this for an and gate when the inputs for both variables x and y are true the expression evaluates to true otherwise its false with the or gate the expression evaluates to true when either x or y is true a not gate simply inverts the value of a variable switching a true to false or vice versa by using only these three simple logical operations and building them up into various configurations boolean formulas can operate like a turing machine and theoretically solve any computable problem in 1937 an electrical engineering graduate student claude shannon demonstrated in his masters thesis that the boolean operations and or and not can be calculated using electronic switching circuits a decade later bell labs introduced the first solid state semiconducting transistor transistors are simple electronically controlled switches with three wires a control wire and two electrodes to input and output data they can be in one of two states on or off representing either a one or zero true or false transistors can be combined and arranged in different configurations to mimic the boolean logic gates of and or and not by combining enough of these transistors together on computer chips in complex arrangements called circuits its theoretically possible to compute almost anything anything that is computable that is more about that later in the 1950s hungarian american mathematician and computer scientist john von neumann brought the modern computer one step closer to reality he developed the architecture of the universal electronic computer the same architecture at work inside most electronic computing devices today from smartphones to supercomputers since the mid 1950s when the first transistor based electronic computers were built the technology has swiftly advanced by scaling down and cramming more and more transistors onto tiny chips computing power and speed has nearly doubled every two years today computers can perform trillions of calculations per second but even thats not always good enough theres a class of problems that computers can never solve a quandary alan turing foresaw in the same paper where he conjured up his calculating machine turing had the insight and in fact proved that not everything is computable the limiting factor is not the hardware but instead the software or program computers solve problems by followinglists of instructions called algorithms an algorithm just means a stepbystep procedure for solving a problem running an algorithm is analogous to following the steps of a recipe or an ikea assembly manual heres an example of an algorithm that sorts a list of numbers from lowest to highest it works like this take a random list of numbers start with a first number from the left which here is six now look through the remaining numbers and identify the smallest one which in this case is three next swap the places of six and three and youll have the smallest number in the group on the left take a second pass this time starting with the second number from the left swap with the smallest and so on after enough passes all the numbers are sorted lowest to highest using this simple algorithm any problem that can be solved by an algorithm is computable but by the 1970s computer scientists realize that not all computable problems are created equal some turned out to be easy while others seemed hard for problems like multiplication computer scientists found really fast algorithms but for others like optimizing the operations in a factory they couldnt find any easy solutions and it turned out that some problems were so hard the only known way to solve them could end up taking more solution steps than there are subatomic particles in the universe thus the p versus np problem was born so what exactly does p and np mean p problems or problems that can be solved in polynomial time are the types of problems that are relatively easy for computers to solve the vast majority of what we use our computers for on a daytoday basis you know you could think of as solving various problems in p from finding the shortest path between two points on a map to sorting a list of names alphabetically or searching for an item on a list these are all examples of polynomial p problems a polynomial is a mathematical function that can contain variables raised to a fixed power or exponent like n to the power of two or n cubed the time it takes a computer to solve p problems grows polynomially as the input increases in size given enough computing power all problems in p can be solved by a computer in a practical amount of time now np problems are a class of problems that share a unique feature if given the solution it turns out to be quick and easy to verify if its correct easily solved p problems are contained within the class of all np problems because they can also be verified relatively quickly in polynomial time however theres a class of np problems that are easy to check yet seem difficult to solve in the first place its really helpful to think about something like a jigsaw puzzle or a sudoku puzzle right we all have experience that you know these could require an enormous  amount of trial and error to solve but nevertheless you know if someone says that they solved it its much easier to check whether they did if someone gives you a completed hard puzzle like a large sudoku or crossword the answers can be verified much fasterthan it can be solved in the first place its the same for a computer the reason these types of np problems can be more difficult for a computer to solve is because as far as we know their complexity increases exponentially as their input increases an exponential function has the variable in the exponent like two to the power of n heres an example of exponential versus polynomial growth for the same input with these hard exponential np problems the increased complexity of large inputs can quickly exceed the limits of what a computer can compute in a reasonable amount of time and solving them using brute force techniques alone is practically impossible you could be doing that you know from from now until the whole universe has degenerated into black holes and you wouldnt have even made a dent in it over the years mathematicians discovered clever polynomial algorithms for some seemingly difficult np problems proving that these problems were actually in the simpler class p and making them solvable by a computer this opened the door to the question are all np problems really p problems could every problem that is seemingly intractable for a computer to solve today turn out to be easy in the future p equaling np would have far ranging consequences solutions to nearly any problem would be well within our reach ai would become smarter overnight businesses could solve complicated optimization and logistics problems boosting the global economy and scientists could make once unthinkable breakthroughs maybe we could even find a cure for the common cold however if p equals np that would also mean that all current methods for strong encryption security measures that protect everything from your online privacy to your crypto wallet would instantly become obsolete it would be hacker heaven in the 1970s mathematicians stephen cook and leonid levin working independently on opposite sides of the iron curtain made important discoveries that have come to define the p versus np problem they discovered the idea of np completeness almost all of the notoriously difficult problems in np are actually equivalent so if you could prove one of those is equal to p youve solved all of p versus np this is kind of like a veterinarian realizing that even though toy poodles and st bernards look very different theyre in fact the same species and a treatment that works on one would very well work on the other there are hundreds of known np complete problems and finding a single solution would lead to breakthroughs on multiple fronts including physics economics and biology not to mention computer science itself np complete problems include a host of famous problems you may have heard of including the knapsack problem which involves the most efficient way to pack items like in a suitcase or the traveling salesman problem which involves route planning and navigation complicated np complete problems even underlie everyday tasks like figuring out how to deliver millions of amazon packages on time or efficient in lifesaving matching of organ donors with recipients and even mastering games like tetris or candy crush all known np complete problems can be transformed into one another the most famous of these is whats called the boolean satisfiability problem or sat sat is one of the most famous problems in computer science besides its theoretical interest  its a very fundamental workhorse problem in applied computer science especially in software verification sat is a decision problem that asks for a given boolean formula or expression made up of n variables and the logical operators and or and not is there a combination of truefalse variable assignments for which the entire formula evaluates to true if so then it is said to be satisfiable if someone can devise a clever fast algorithm for the sat problem making it easy to compute then voila proof that p equals np however most computer science researchers believe that p doesnt equal np and proving p doesnt equal np has turned out to be one of the hardest problems in math and computer science in the 1980s one promising avenue of research emerged called circuit complexity the field studies the complexity of boolean functions when represented as circuits the behavior of any given boolean function can be described by its truth table however the same truth table can be produced by circuits of differing complexity as seen in these two examples a boolean functions circuit complexity is defined as the total number of logic gates in the smallest circuit which can compute that function researchers study circuit complexity to understand the limits of computation and to optimize the design of algorithms and hardware for some boolean functions the minimum number of logic gates grows polynomially as the number of input variables increases these are said to have low circuit complexity and are analogous to pclass computational problems functions where the number of necessary logic gates grows exponentially with increasing input variables are said to have high circuit complexity one potential approach for proving p doesnt equal np required researchers to identify a single function known to be in the class of np thats also definitely has high circuit complexity in 1949 claude shannon proved that most boolean functions have high circuit complexity so how hard could it be to find one instance harder than it sounds alas researchers encountered a mathematical roadblock called the natural proofs barrier this barrier implies that any proof that p doesnt equal np using known circuit complexity techniques would have to have a bizarre and selfdefeating character clearly a different way forward was needed while most researchers started looking for other approaches some began to investigate the natural proofs barrier itself leading them to new questions how hard is it to determine the hardness of various computational problems and why is it hard to determine how hard it is its a very meta area of computer science called metacomplexity it has turned out that a lot of the progress that one can make on problems like the p versus np problem today you know involves sort of selfreferential  arguments involves sort of turning inward given the limits of known techniques metacomplexity researchers are searching for new approaches to solve some of the most important unanswered questions in computer science and crucially metacomplexity is intimately connected to the question of whether provably secure cryptography schemes even exist one important current focus of research is whats called the minimum circuit size problem or mcsp mcsp is interested in determining the smallest possible circuit that can accurately compute a given boolean function is there a simple solution the minimum circuit size problem is a problem about circuit complexity but how complex is the problem itself researchers suspect that mcsp is np complete but unlike many other similar problems they havent been able to prove it a proof of mcsps npcompleteness would be a big step towards showing that secure cryptography does exist and recently theres been tantalizing progress towards that goal like the robot searching for safe passage in a foreign land the pursuit of metacomplexity is blazing a trail for theoretical computer science a path that may lead to an answer to whether p equals np or not if civilization lasts long enough you know i would tend to think that probably problems like p versus np will someday be solved and my main uncertainty is is it humans who solve them or is it ai  is it gpt 10 that  solves the p versus np problem for us and then will we be able to understand the solution if it does 