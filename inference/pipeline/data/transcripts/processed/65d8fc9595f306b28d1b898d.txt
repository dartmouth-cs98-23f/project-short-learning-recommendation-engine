marketplace for your website selling firearms is prohibited by your websites terms of service agreement not to mention the laws of your country to this end you want to create a system that can automatically detect if a listing on the marketplace is selling a gun how would you go about doing this yeah its a interesting question im curious about a few things here first i guess one thing im wondering about is like how if i was given this task like how is this working in kind of production you know the task is to automatically identify the listings what happens with those identifications do they go to a human who checks it or is it like immediately changes the website yeah so lets say that the current setup is that its all crowd source so lets say we have a flag and then a user can flag the listing if they see its a gun or maybe someone who works in terms of like moderating the marketplace can also flag it and then itll go to another internal lets say someone who works in customer support that can then remove the listing if they determine it as a gun and thats the only thing that kind of happens right now okay and then how would this fit in is the end of the line always going to be customer service or how would this fit in that pipeline you think so i guess reframe the question back to you but lets say that this is the current system right and i guess given the kind of context would you think that the goal is to first disable it when theyre posting do you think we should be like detecting it afterwards after a few days and then sending it to customer support what part do you think yeah so i guess yeah the reason i was asking that question i guess i could have said that too because if if customer service is is going to look at it afterwards which i think would probably be the better way to go to start but if theyre doing it that way then that means that i really need to do a very good job of detecting all the possible firearm listings its bad if i miss something that is a firearm but i miss it because at the end the customer service is going to look at it and so im assuming itll be okay it might cost some money but its probably going to be okay if i give it false positives like listings that arent guns and then let the customer service deal with it but it seems like this pipeline would be very costly in that in the sense that youre maybe breaking laws of your country or your terms of service if you totally miss the listing and you have this uh false negative right yes so thats thats yeah so thats how i would think about it so i guess given the costs do you think we would then err on the side of reducing the number of false negatives or false positives in this case so my initial point was about false negatives because we want the customer service to get everything thats pertinent and they can decide because they wont see anything thats not been flagged or not been identified so but if costs are a concern then yeah we would be concerned with the false positives because that would mean that the customer service gets extra ones that are not really relevant at all theyre adding to their workload okay so lets like maybe think about an assumption of what is okay in terms of how the process might go and maybe this could be an example so you know in my mind i think like if we lets say someone posts a gun it gets put onto marketplace it gets removed within one hour thats probably good probably not a lot of time for someone to go out reach out message try to get that gun from the seller in that scenario maybe a bad case scenario is that we get overloaded with a bunch of other items that are trying to be sold that are not guns and then you know they get the typical your posting was flagged until its reviewed by customer service therefore you know reducing kind of liquidity in this marketplace as well all of a sudden you know sellers are like oh like this marketplace sucks like i cant even list you know my plants on here or else they get flagged right and then therefore kind of reducing that when were thinking about the different scenarios here what is it kind of like the optimal one you kind of have an idea of what you think is kind of best case scenario here for both parties bringing it back if youre facebook what would you think facebook would want to do in this scenario it does depend on what happens with the the model at the end so there are different scenarios weve laid out so if one of the scenarios is the one i was talking about which is that you dont want to miss anything that case false negatives are important in other cases like youre mentioning which is if if it ends up being a sticker thats posted because my the model identifies it but its not there and then it can lead to a lot of issues so thats the the false positive case what well want to be concerned with then in our model so i guess if were concerned with both those scenarios then we want to minimize both false positives and false negatives and so we can use metrics like f1 score to to sort of minimize that i guess another thing thats related to this of why we might choose something like an f1 score which is basically a combination of precision and recall and precision is where youre really concerned with you make a bunch of predictions and how many of them are right the recall is the case where you make a bunch of predictions how many of the real case scenarios do you get so how much stuff do you miss i guess recall is like what do you miss another reason to use these two measures and i think that seems pertinent here is because the number of guns are probably gonna be small right the im assuming the actual number of gun posts is probably very small maybe even less than one percent in like a facebook marketplace that sells all sorts of stuff its an imbalance sample too those measures that i just mentioned are good for that because they they sort of ignore the fact of the true negative which is that the post isnt about guns and you get that right but theres so many of those so you want to ignore those so measures like precision and recall will ignore the thing thats very obvious and predominant which is the listing not having guns and focuses on just getting the positive case of getting the listing with guns the imbalance case will also maybe come into consideration for the models we choose so that seems good for the imbalance sample and i guess false positives and false negatives i think the other things i was thinking is that what sort of the scale and scope and the kind of data we might have because thatll pertain to how we can answer this question so im guessing maybe speed at least for training the model isnt a big issue and the importance is accuracy like were very concerned with an accurate model yeah definitely and im guessing online you had mentioned like maybe its okay i mean the model doesnt need to be that fast i guess right in terms of when it gets deployed and its making predictions for each post yeah and then i guess in terms of the prior data so i guess we would have access in this case to other postings and where customer service has flag stuff so we have like a large data set where we know that there was a posting and we know whether it was of guns or not yes yeah i think we can identify if there were guns theres probably something where the actual value itself is flagged and then probably also a categorization of why it was flagged for and for this scenario we could say that confidently probably customer service is labeling them as guns or firearms in that category okay yeah so were we can select those flags that are for guns and farms okay it seems kind of straightforward then so the idea is that you know we really want to identify these gun postings part of it might be related to the law part of it also might be related to you know people dont want to see these gun postings and and they also dont want to be necessarily wrongly flagged for the guns postings so its very important to have a very accurate model at identifying these very small cases of gun postings and we dont seem to have as many concerns about model training time or anything like that were really concerned with accuracy with that in mind with the fact that we already have this data im guessing our data set is fairly large maybe theres some things we might want to do with augmenting the data which i think so if i think about data collection and then i can think about features and then think about the model so if now i think about the features that i have i have flags that might have been given by users so i have that as a feature i might have the particular user who posted it their demographic information location information so maybe you know parts of the country have more guns being sold or not there might be other contextual information i dont know why this might be but maybe early in the morning people like to post their gun sales and then i think whats critical for me here is the text as a feature the body of the text itself i guess another feature could be the maybe they post some images but im thinking maybe for now just to focus the model a little bit i can i might ignore the images part just for now but i think when i talk about the text a lot of what ill say can apply to the images and i think the the big part here to me it seems like the text in that data and being able to leverage that information to get you know keywords or to get patterns of words yeah so so you might have that you might have other data to like the length of the text or something like that so we have those features user data flags context information the text so now i want to focus a little bit on on the text itself and what we can do with it to use for our model i think just to start i mean i often feel this way when dealing with text data you want to start with a simpler model i suppose and so the simpler model might be something like a bag of words one also reason to start with that is that you can get a nice baseline and i guess a related question here i i meant to ask this earlier was that you know we do we have other baselines like i guess we have previous performance of how the user flags worked or so we have some other data in the past yeah yeah lets assume that yeah we have all this data that facebook itself has yeah so we have some baseline data of how their current process is working and then im suggesting we can have this other baseline where we just we use the simplest approach for text analysis even though i did mention we did talk about this that there is a lot of time so technically we could use more complicated models like attentionbased transformers that take contextual information into account but for now ill just focus on the simpler model and and talk through with that maybe we can talk at the end of the value of these more uh sophisticated approaches so i guess if we have the text data then you know we want to we can extract the bag of words which just means that we get for each body of text we get the unique words in the text and the counts of those words we have like i dont know how many millions of posts so we have this for each post we have these bag of words the other thing we can do is an approach called the tfidf where we scale the value of each word based on its frequency in different postings and the reason this can be valuable is that you might expect that postings about guns for instance tend to use specific words not found in other postings you know before even running the model i might be helping my model by selecting words that are unique to particular listings and so this will up weight those words that tend to be very specific to specific listings because the bag of words can be like millions and millions of words so its a huge sparse matrix so sometimes you might want to do additional reductions so you might do something like a pca to reduce that to something like 500 dimensions the point of all this process is is that youre taking the text and youre putting it into some embedding space and the value of the embedding space is its almost like what youre doing is youre putting each listing youre plotting it in space and the idea is that you want to plot points in space that mean similar things this processing technique should before we even build our model should place each listing next to each other that mean the same thing thats the sort of idea of this process and since we know that idea we can always substitute it with other methods that are more sophisticated if we want that sort of like how we get the features so now i guess we want to think a bit about the model that we want to build because we have the imbalance sample i would think maybe the model to start with at least we can again iterate as we go but for our first prototype maybe we could start with a tree based model particularly something like a gradient boosted tree because whats nice about these models is that you have each tree that makes a prediction so in this case its taking all our features and predicting whether its a gun posting or not a gun posting and then it takes the points the data points that have the most error and it scales them so it up weights those data points that were in error for the next tree what this effectively will do is itll upweight the sort of minority sample points those listings that are for guns are very few and so theyll if they keep causing an error in the model their weight will keep going up and theyll be more and more important in making the prediction thats maybe why a gradient booster tree would be good to start with yeah the only one issue could be if you want online training and so maybe if theres an issue of online training the gradient boosted trees may not be optimal for it and so we could try other models if we wanted and the difference between online and offline training is that online training happens while the model is deployed and does continual improvement is that right yeah yeah exactly but im guessing in this case what we probably would want to do is maybe every so often we update the model in which case the usually the gradient boosted trees are pretty quick to train and theyre fast at also delivering the predictions at inference time so we could just retrain the whole model but say for whatever reason every time customer service answers that you want to update the model then this tree based approach depending on what package you use it its not going to be very optimal so you might want to use other approaches like a neural network that could allow for this online training we talked a bit about like so were building this model with the gradient boosted tree we talked earlier about we cant really use accuracy like just plain and simple accuracy because its such a small sample that we have theres very few gun posts the one thing i could have mentioned earlier is one way to deal with that too is to balance the sample so if we have a lot of data we also could have evened out the the two samples so we could have taken how many gun postings we have and just gotten a matched sample of the equivalent other sample but say were not doing that say there theyre not enough gun postings to really have that match then accuracy wont be that great and what well want is like what we talked about is precision and recall are there other things to consider evaluating the model and maybe when we roll it out yeah like i said we can use precision and recall and we can combine them in this f1 score that just range between zero and one and that can tell us how well the model is performing at predicting those gun sales when were building the model we we probably would be training i guess on our historic data wed be taking some sample of data in time thats our training sample and then the test set is something later in time we should probably mimic how its occurring in production where our model is trained with a given set of data in time and its predicting new data in the future one thing we might want to consider is how long this prediction is good for how often we want to keep rebuilding this model because i guess as everything on the internet or the spam calls i get they get more and more creative at doing these things so yeah you know we might want to update the model uh to deal with these creativities that people have yeah and thats actually a good question because i think as people realize that their posts are being flagged were dealing with very malicious actors that are active in their campaign to sell guns on the internet maybe one of the aspects is that they start creatively disguising their posts right and so that right the traditional nlp test of detecting bullets or guns for sale turns into like code names or something in which then we still have to then reuse that use of identifying manual tagging sorts so i guess one additional question i have is how do we know the performance edition of doing like more advanced approaches right and so lets say that we want to dive into computer vision i know you have a computer vision back under our and so like i guess like how would you assess the necessity of maybe using like images into your analysis versus just only using text and you know you know that image is probably harder to train theres probably a lot more difficulty with having expertise and images versus just text which has like great packages on python to use and so yeah how would you kind of like approach that situation how would you know that its worth doing the image analysis into the features versus just going with a basic model yeah so i guess the question is like whats the added value of the images and is it worth bringing all that what whatever time it takes then exactly yes i think i mean a very simple approach that you could use that i like using is you just like sort of build the model you have all the features in there and then you get its prediction what the full models prediction accuracy is so say for instance the full model is at 90 seems really good and then you drop the images from the model and then you see you know when you remove the images what the value is and the accuracy and say its 85 and then say you you do it again but you remove the text data and the text data when you remove it its like 7 60 accuracy or something so so so yeah there you can know oh wow the text is very valuable but the images does drop it so youre like okay well you told me now when you drop the images the accuracy does drop but is that a meaningful drop so one thing i think you could do is just simulate like randomly sampling the data especially because we have enough data like i said here i guess in this facebook huge amount of data set so what you could do is randomly sample from the data and retrain the model each time and get this drop in accuracy when you remove the images and so say i guess i could say if 95 of the time the drop in accuracy is more than zero its like its like theres a negative drop so then i might say yeah images are important because almost all the time that ive tried it out in simulating across multiple samples there is that drop in accuracy gotcha okay cool yeah i mean that makes a lot of sense any additional kind of thoughts on this question oh i was going to say something about like if we could augment the data too for text data but some of those things are cool where you can use machine translation to change the specific text words but keep the meaning but i guess other things this model would be sort of a first step were taking in all these features the user data the flags and the text were making some predictions so i think the final thing would just be to check where the errors are happening and maybe use that to help with the model so one thing you might find is that say we flag toy guns all the time are being flagged yeah so one simple thing you could do with just the simple model where i use a bag of words is i could use like uh ngram model so i could take every two words and and use the pairs of words and then in that case i would get toy gun and that way i could identify oh these things that are actually toy guns that are being wrongly flagged and i could solve that problem by just changing the model to include this local history um with pairs of words cool yeah that makes sense final question and this is kind of just more in relation to the question itself like what do you think about this question like how well do you think it assesses the candidates performance just overall how do you feel your answer would kind of like fit in into like a broader facebook interview i mean im not sure about the broader facebook interview but i guess this i mean this question is pretty it seems very standard like its very machine learning right you test your knowledge of minority like when you have very few things youre predicting you have to sort of build the model but you go from end to end and i think its also to me seems like a fairly common problem you might face not this specific one but something like this where you know you need to identify something from a particular listing a particular post or or some you know in my case i deal with videos a lot and so its its like in line with i think what what you also might have to work on yeah what were your thoughts you have any yeah i mean i liked it a lot and i liked your answer and how you structured everything and i feel like thats a great approach for most machine learning type questions as well because i feel like most of them have a very defined beginning middle and end in terms of wheres the data how do you build the model and then how would you deploy and evaluate it and i think focusing on those approaches is really key and so i think you did a great job there yeah good awesome 