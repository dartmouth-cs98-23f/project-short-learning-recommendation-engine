data structures today and explain them as simply as possible these are extremely important to learn whether its for coding interviews computer science class or building projects we’ll be going through the list from easiest to hardest so beginners have a better idea of where to begin we’ll go over a simplified explanation for what each data structure is and talk about common uses for that data structure i’ll also be putting the time complexity for common operations on screen but if you don’t know what that is don’t worry i’m just including it on the screen for people who want to see let’s not waste any time and get right into it arrays arrays are ordered collections of data typically the data is all of a similar type like integers or strings but some languages also allow for differing data types an example of a reallife use for an array would be if you had temperatures for the next 5 days and wanted to store them so your program could access them arrays are used all the time and for pretty much everything so they’re definitely the most important data structure to learn first one of the amazing benefits of using an array is that it’s very easy to find any element as each element in an array is assigned a number called an index that you can use to find it this form of numbering is often called “zerobased indexing” which just means the first element in the array is at an index of 0 this can often confuse new programmers because if you want to retrieve the second element you have to use its index which is 1 not 2 while the advantage of arrays is that it makes it easy to read elements o1 the disadvantage is that they have a slightly harder time inserting or deleting elements on now just a quick note we won’t talk about memory much in this video but for the first two data structures in this video the memory component is very simple and important so you can tell the difference between them we’ll use our temperature array from earlier as an example arrays are stored in contiguous memory which means each of the elements in the array are next to one another in memory if a new element is added in the middle of the array the entire array must shift down but what would’ve happened if there was already something in the next memory address to fit this new element in now the array’s memory will have to be reallocated to an entirely new space where all of the elements fit while computers are incredibly quick this is not very efficient arrays are very good for reading elements but can a bit less efficient when it comes to insertion or deletion now we’ll take a look at a data structure that’s the opposite linked lists while arrays were fast at reading elements and a bit slower at inserting or deleting linked lists are a bit slower at reading elements but fast at inserting or deleting linked lists are similar to arrays in that they also store ordered lists of data elements however a huge difference is in the way they are stored in memory each element of a linked list has what we call a pointer which is basically the address of the next element of the list as a result elements in a linked list do not have to be stored beside each other you can store the next element in any location and the previous element will point to it if you want to find it the advantage of this is that it solves our problem with array insertions and deletions to add a new element you find a free spot in memory for it and have the previous element point to it to remove an element you just delete the element and have the previous point to the one ahead of the deleted element the disadvantage of this is that linked lists do not have indexes as the elements are not stored right beside each other this means that to find an element we have to go through the list starting from the beginning if we want the third element we have to first look at the first element see where it points go to the second see where it points and then we find the third if you think of a huge linked list you can start to understand why it’s not the fastest at reading so to recap arrays are faster when it comes to reading linked lists are faster when it comes to inserting and deleting hashmap remember how arrays had values stored and for each value there was an index that numbered them well hash maps are essentially the same thing except that you can choose what the “index” is which hash maps call a key the key and it’s value are commonly known as keyvalue pairs the other major difference between arrays and hash maps is that hash maps are unordered hash maps are fast o1 for both inserting and removing elements but the real benefit to using hash maps is their ability to search quickly o1 let’s say you wanted to store a list of capital cities if we stored these in an array we would have to know the index for each one to read it but for a hash map if we make the keys countries we can just look up the country to find the capital city hash maps go by a few different names they are sometimes called hash tables or if you know python they’re called dictionaries for the purposes of this video you can assume they’re all the same thing so if you know how to use dictionaries in python congratulations you’ve actually been using hash maps the way hash maps work underneath the hood is really interesting but a bit out of the scope of this video i’ll be making specific videos for all of the data structures so we’ll cover hash maps more indepth there for now just understand that they’re unordered and their custom keys allow for very quick searching stacks  queues the most simple way to describe stacks is to think of a stack of plates or pancakes the first plate goes on the bottom the last plate goes the top stacks are lifo structures which stands for last in first out because the last element in is like the last plate that goes on top the stack when you go to grab a plate this last plate on top will be the first you take off stacks have three common operations which are push pop and peek pushing is when you add a new element to the top of the stack popping is when you remove the topmost element from the stack and peeking is when you’re just taking a look at what the element at the top of the stack is all of these are very fast which is why stacks are optimal for certain problems if you’re wondering when stacks might be used think of the pancake and plate examples for any scenario that has a similar structure where the last element in is the first element out stacks are likely a good data structure to use queues are the opposites of stacks the simplest way to think of a queue is like a lineup at a grocery store the first person in the line will get serviced first and every additional person who joins the line goes at the end queues are fifo structures which stands for first in first out because the first element in is the first element to come out queues have very similar operations to stacks which are enqueue dequeue and front enqueue is like push for a stack and is when a new element is added to the back of the queue dequeue is like pop for a stack and is when the element on the front of the queue is removed front is like peek for a stack and is when you take a look at the frontmost element in the queue queues are more frequently used than stacks especially in realworld programming think of youtube playlists when you start watching a playlist you’ll start with the video that was added first and the last video you watch will be the final one that was added trees trees are a category of data structure that as you might have guessed by the name resemble trees trees have nodes which are connected to each other by edges the first node in a tree is called the root node nodes have a parentchild direction where one is a parent node that leads to another node which is a child node sometimes the parent nodes are sometimes just called nodes and the child nodes are called leaves there are tons of treebased data structures but in this video we’ll be talking about binary trees and in particular binary search trees a binary tree is a tree where each parent node has up to two children nodes a binary search tree is a type of binary tree where all left children nodes are less than the parent node and all right children nodes are greater than the parent node these binary search trees make it very easy to search through large amounts of ordered values the classic example is to think of a number guessing game where one person thinks of a number between 1 and 100 and the other person has to guess with each guess they get told whether the correct number is higher or lower than their guess the strategy is to always guess the middle number because then you’re eliminating the most amount possible each time this is what a binary search tree does we can eliminate a parent node and everything below it or above it and continue that process until we get to our correct number this is not only useful for this game though a more practical example is to think of a digital dictionary dictionaries have over 100000 words if you give a computer a word and want it to give you the definition it would be incredibly slow for it to start at the beginning and look through each word until it finds the correct one on instead because the dictionary is sorted alphabetically the computer is able to go right to the word in the middle of the dictionary and check if the target word comes before or after it continues sorting like this until it reaches the word ologn there are tons of other treestructures like heaps and tries but we’ll leave those for another video graphs lastly we have graphs graphs are basically models for a set of connections like trees graphs are made up of nodes and edges in fact trees and even linked lists to an extent are technically types of graphs but graphs can get a lot more complicated in a graph there are less restrictions than with trees nodes can be connected to any amount of neighbours graphs can be directed where nodes point to other nodes but they can also be undirected some graphs have cycles where two nodes both point to each other the edges between nodes can also be weighted where the path has a value associated with it as you can see graphs are very complicated which is why many people consider them to be one of the hardest data structures to learn i’m going to make an entirely separate video dedicated to graphs so we’ll tackle the complexities in a little bit for now let’s see an example where graphs are useful data structures imagine you’re running errands and you have five different stores to visit we can represent this as a graph where each store is a node and each edge has a distance using this data structure we can develop an algorithm that allows us to calculate what the shortest route between all five places is for a reallife example think of uber every uber driver and user could be seen as nodes and the application is constantly trying to optimize so that the waiting time for each rider is as short as possible there are endless applications for graphs which is why they’re such an important data structure to understand conclusion  thank you thanks so much for watching if you enjoyed this content on data structures and want to see more data structure videos comment down below and leave a like on the video i want to take a quick moment and express my gratitude to everyone for being so incredibly supportive so far and to celebrate hitting 1000 subscribers i started this channel just over a month ago and i’ve been super fortunate to have found 1000 amazing people who have been willing to take a chance on my small youtube channel i never thought i’d be able to hit 100 subscribers in this time let alone 1000 so i’m just so thankful that all of you have been so supportive i promise i’ll do my absolute best to continue increasing the quality and quantity of content as much as i can thank you and 10000 here we come 