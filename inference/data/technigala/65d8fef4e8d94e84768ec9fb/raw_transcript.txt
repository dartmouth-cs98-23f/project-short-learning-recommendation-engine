second,duration,transcript
7.68,7.04,"What do DynamoDB, Apache Cassandra, Discord, and 
Akamai CDN have in common? They all use consistent  "
14.72,6.08,"hashing. Now, what is consistent hashing? Why do all 
the cool kids use it? In this video, we'll learn  "
20.8,6.96,"all about it. Let's dive right in. In a large scale 
distributed system, data does not fit on a single  "
27.76,7.04,"server. They are distributed across many machines. 
This is called horizontal scaling. To build such  "
34.8,5.2,"a system with predictable performance. it is 
important to distribute the data evenly across  "
40.0,6.72,"those servers. A common method to distribute 
data as evenly as possible among servers is  "
46.72,7.76,"simple hashing. This is how it works. First, for each 
object, we hash its key with a hashing function  "
54.48,6.96,"like MD5 or MurmurHash. This maps the object 
key to a known range of numerical values.  "
62.0,4.96,"A good hashing function distributes the 
hashes evenly across the entire range.  "
67.92,6.32,"Second, we perform the modulo operation on the 
hash against the number of servers. This determines  "
74.24,5.52,"which servers the object belongs to. As long 
as the number of servers stays the same,  "
79.76,7.36,"an object key will always map to the same server. 
Here's a concrete example. We have four servers  "
87.12,5.6,"with eight string keys with simple hashing 
this is how we distribute the eight string  "
92.72,6.8,"keys among the four servers. Now, this approach 
works well when the size of the cluster is fixed,  "
99.52,6.24,"and the data distribution is even. But what happens 
when new servers get added to meet new demand  "
105.76,6.08,"or when existing servers get removed? 
Back to our example. If server 1 goes down,  "
111.84,5.92,"the size of the cluster is now three. Even though 
the hashes for the object keys stay the same,  "
118.48,6.64,"we are now applying the modulo operation to a 
different set of n. In this case, it is now three.  "
125.92,6.96,"The impact is pretty drastic. Most of the keys get 
redistributed. This affects almost all objects, it's  "
132.88,7.04,"not just the objects originally stored in the 
server that is now offline. This triggers a storm  "
139.92,6.0,"of misses and lots of objects to be moved. For 
situations where servers constantly come and go,  "
145.92,6.32,"this design is untenable. Consistent hashing is 
an effective technique to mitigate this issue.  "
153.12,5.68,"The goal of consistent hashing is this. We want 
almost all objects to stay assigned to the same  "
158.8,6.8,"server even as the number of servers changes. 
Here is the core insight of consistent hashing.  "
166.24,6.48,"In addition to hashing the object keys like before, 
we also hash the server names. The objects and  "
172.72,6.8,"servers are hashed with the same hashing function 
to the same range of values. In our example we have  "
179.52,8.64,"a range of x0 to xn. This range is called a hash 
space. Next, we connect both ends of the hash space  "
188.16,8.24,"to form a ring. This is a hash ring. Using a hashing 
function we hash each server by its name or ip  "
196.4,8.96,"address, and place the server onto the ring. Here, we 
place our four servers onto the ring. Next, we hash  "
205.36,5.76,"each object by its key with the same hashing 
function. Unlike simple hashing where we perform  "
211.12,7.04,"a modulo operation on the hash, here we use the 
hash directly to map the object key onto the ring.  "
218.8,5.68,"Here is what it would look like for our four 
objects. To locate the server for a particular  "
224.48,6.56,"object, we go clockwise from the location of the 
object key on the ring until a server is found.  "
231.6,7.84,"Continue with our example, key 0 is on server 0, 
and key 1 is on server 1. Now, let's take a look at  "
239.44,8.08,"what happens when we add a server. Here we insert 
a new server s4 to the left of s0 on the ring.  "
247.52,8.24,"Note that only k0 needs to be moved from s0 to 
s4. This is because s4 is the first server k0  "
255.76,9.04,"encounters by going clockwise from k0's position 
on the ring. Keys k1, k2 ,and k3 are not affected.  "
266.08,6.24,"With simple hashing, when a new server is added 
almost all the keys need to be remapped. With  "
272.32,5.84,"consistent hashing, adding a new server only 
requires redistribution of a fraction of the keys.  "
279.12,6.72,"Let's walk through a quick example of removing 
a server. When s1 is removed, only k1 needs to be  "
285.84,8.32,"remapped to s2. The rest of the keys are unaffected. 
Let's recap. What have we learned so far. One,  "
294.16,6.0,"we map both servers and objects onto the hash 
ring using a uniformly distributed hash function.  "
301.12,6.64,"Two, to locate a server for an object, we go 
clockwise on the ring from the object's position  "
307.76,5.04,"until a server is found. Now, let's consider 
a potential issue with this design.  "
313.52,4.88,"The distribution of the objects in the 
servers on the ring is likely to be uneven.  "
319.28,6.64,"Conceptually, we pick n random points on the ring, 
we are very unlikely to get a perfect partition of  "
325.92,6.8,"the ring into equally sized segments. For example ,
if servers are mapped on the ring like this,  "
333.36,8.4,"most of the objects are stored in s2, with s1 
and s3 storing no data. This problem gets worse  "
341.76,7.04,"if servers come and go frequently. In our example, 
even if the servers were originally evenly spaced,  "
348.8,6.48,"if s1 is removed, the segment for s2 is now 
twice as large as the ones for s0 and s3.  "
356.8,6.4,"Virtual nodes are used to fix this problem. The 
idea is to have each server appear at multiple  "
363.2,7.44,"locations on the ring. Each location is a virtual 
node representing a server. In this hash ring, we  "
370.64,7.12,"have two servers, with each having three virtual 
nodes. Instead of having s0 and s1, we now have  "
379.12,9.6,"s0_0, s0_1, and s0_2 to represent server 0, and s1_0 
s1_1, and s1_2 to represent server 1 on the ring.  "
389.68,7.12,"With virtual nodes, each server handles multiple 
segments on the ring. In our example, the segments  "
396.8,6.24,"labeled s0 are managed by server 0, and 
those labeled s1 are handled by server 1.  "
404.0,4.48,"In real world systems, the number of 
virtual nodes is much larger than  "
408.48,6.32,"three. As the number of virtual nodes increases, 
the distribution of objects becomes more balanced.  "
415.68,5.6,"Having more virtual nodes means taking more space 
to store the metadata about the virtual nodes.  "
421.28,5.04,"This is a trade-off, and we can tune the number 
of virtual nodes to fit our system requirements. "
427.6,5.76,"Let's see how consistent hashing is used in 
the real world. Some popular NoSQL databases  "
433.36,6.8,"like Amazon DynamoDB and Apache Cassandra use 
consistent hashing, where it is used for data  "
440.16,7.52,"partitioning. It helps these databases minimize 
data movement during rebalancing. Content delivery  "
447.68,6.48,"networks like Akamai use consistent hashing to 
help distribute web contents evenly among the  "
454.16,6.64,"edge servers. Load balancers like Google Load 
Balancer use consistent hashing to distribute  "
460.8,5.68,"persistent connections evenly across backend 
servers. This limits the number of connections  "
466.48,6.4,"that need to be re-established when a backend 
server goes down. That's it for consistent hashing.  "
472.88,5.12,"If you would like to learn more about system 
design, check out our books and weekly newsletters.  "
478.0,5.36,"Please subscribe if you learned something new. 
Thank you so much, and we'll see you next time."
