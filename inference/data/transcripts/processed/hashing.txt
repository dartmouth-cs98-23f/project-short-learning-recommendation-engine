in a previous episode of the vacuum engineering show i talked about hash tables and how uh powerful and very commonly used they are given a key we can find its corresponding value in no time in zero seek time were not searching were not scanning were not doing anything its a single axis in memory retrieving that value the power behind hash tables is the use of the arrays which is a very common data structure obviously very very common data structure right knowing the array position the the index you can get the value of the array immediately because you know how how does memory work if you know the address of the ram where your cell exists where your values exist you can get the value immediately right the cpu can fetch the value immediately for you right so once you find the index you find the address you can value so what the hash table guys did it says okay were gonna take your name your string your color your car your va anything that has been this key were going to hash it using a oneway function and then convert that into an index using a modulo function based on the array size so we eventually from the name we convert and continue an index and that will give us the address and the memory and we can get the value so thats the trick the hash table guys use you know so the only cost you add is like what the hashing function which is not really that bad but thats the power of the hash table but the problem is the moment the size of the array changes the hash table size changes this all forms apart because what what the if blue the key blue used to fit in index number 11 if you increased or decreased the array size and i you know where im going with this then the blue will fit into index 99 now and as a result right you either wont find the value or youre gonna start writing the values duplicate and everything will basically be bad so you now have to really move things around your resize and its a really big problem so why im mentioning that the problem that we are seeing today with distributive system is as follows if my database are increasing in size and it no longer can fit in a single instance i i bumped up the vertical scaling to its maximum its now 48 core cpu three gigahertz whatever you know its 512 gigabyte or even one terabyte ram but still i have billions of rows i cannot i added all the indexes i try to partition it horizontally in the same instance by range so but still the even the partitions are so large so i that machine cannot handle the queries um throwing at my beautiful database so what do we do we distribute it we shard the database thats i really dont like to go there unless i kind of exhaust all my options and believe me people dont even look at the options anymore people are very quick to follow modern things you know without actually going to the basics and trying to tune your database and getting a better performance but regardless lets assume youre a youtube scale lets give you a google scale and you run out ideas that single instance cant handle anymore you need to distribute the billions of rows table or key dictionary or collection into multiple servers right so instead of having billions lets have i know a few millions on this server and few millions on this server a few millions on the server female in the server immediately a problem occur the problem is like how do i know right if i have a key i want to look it up we introduced an intermediately an intermediary problem right that didnt exist before well first if i have a key i go to my database server and i ask it and i immediately give it to me i only go to one hop now if youre distributed and you only have the key you have to answer the first question which server should i connect to to retrieve the key which server hosts my key and that is the problem here that is the original and only problem that we have in distributed system which server should i connect to to fetch that key so the trick was always lets figure out the server from the key and that is the concept of hashing hashing tables appear here so in this episode of the vacancy show id like to talk about that a little bit distributed hashing and then what problems did we have and how consistent hashing solves this problem and obviously nothing is perfect in this world so id also like like to talk about the problems consisting hashing actually have today welcome to the backend engineering show with your host hussein nelson and the concept of distributed system is a must when you get to a certain scale yeah i always try as much as possible to you know push people against being distributed if they can do things to have their single instance you know be more performant when it comes to query because you see a lot of a lot of people our engineers are hurry up to scale right and spend more money to start to work with the distributor without actually while their query is actually using 500 of their cpu and then doing like a million logical reads you know where they can tweak it a little bit and tweak it and tune the database a little bit understand their queries so they can have or even you know lower that cost you know as a result but we dont think this way anymore we always take the shortcut unfortunately but regardless so usually advanced and adept dpas try to optimize a single coin as a result if you if you can get a query to consume less cpu even if its a small query scaling that query right will eventually give you better scaling on your instance but thats not our topic thats another day but lets say you reached the state where you exhausted all your options you know when it comes to a single instance right then you moved he says hey i have to move to and uh distribute the system its just too large you gotta move so people what they did says okay i have a key and now i dont know which i have 10 servers right i dont know where this key lives in distant server environment so ill say all right so were going to do lets say i have four server a cluster with four servers and i want to distribute my values across these four servers so server s0 s1 s2 and s3 right what were gonna do is like giving the key i need to know the server name the server ip and thats something that we are introducing as a problem like we introduced a friction that didnt exist before first previously so i just one server we know the server right but now we have to figure out from the key we have to figure out the iprs of the server to connect to in order where our key actually exists that answer can be answered using a very simple hashing function so were going to hash the value lets say im have value number four uh gonna hash it get some value and then that value were gonna do modulo number four and that gives you server zero so store server zero right here right in this case right so four modulo four is zero and then okay how about key number five right or even whatever that key used to be maybe lets say its a its a blue or red right red youre gonna hash it get that value number five which is a number and then five modulo four will give you s1 and s1 will go right here right so five right lives in s1 and same thing 6 will live in s2 and 7 will live in s3 youre just gonna do module four because four is your server pool size right and then lets say going back lets say eight then eight module four oh so back to zero and then use get the point which is which works perfectly from the key i was able to figure out the server so cost is zero is nothing heres we solve distributed system right there heres one problem though as long as you have four servers your love is beautiful you dont have to worry about anything but now even those four servers reach their limit again whatever reason limit that means youre youre at the globe scale you know you have so many users right so to me that i need four machine more than four machines database instance that means im at the global scale and i have users left and right millions of heads you know so thats the scale were talking about right so i say okay okay all right lets just add another server server 4 s4 so we have s0 s1 s2 s3 and s4 sounds good comes back to the problem with hashing tables the moment you change the size the whatever value where original so the values their original key values are now all shuffled right previously value number four used you do for modulo 4 the key four used to live on server s0 because 4 modulo 4 is zero but now for modulo 5 which is now the new server we have five servers is actually gives you value four so its now as an s4 so now what you need to do is like move the key with a value four from the server zero to server four and now you have to move everything else and this is this is basically the same thing five modulo five right the server five the the key four will move to server four the key eight will move to server three the key 5 will move to server 0 the key 6 will move to server 1 and the key 7 will move to the key 7 will move to s1 right so everything will be shuffled and the operation of adding a new server will cost us a huge amount of effort to kind of shuffle things around so look think about networking think about database usage just to add another server to not only bothering one server youre bothering the entire cluster with your operation because you have to shuffle things around right because your key no longer maps so what what people think what the smart people say okay lets invent something that might solve this problem which is called consistent hashing so how does it really work so they go they went back to the idea of having so they went back to idea the core idea we use the index as the server names here right lets flip this lets change this a little bit lets not be very discreet like oh server 0 1 2 3 4 lets build a ring lets actually build a ring of these servers all right so instead they think of this idea as an actual rank as an actual circle so values go back right and remember a lot of people thought a lot about this to solve this problem and the key here is instead of the output of the key hash going to a server were going to approximate it you know by by using this concept of the rank so lets take an example so clarify the first thing were going to do is the servers themselves we need to fit them on the ring which this is something we didnt do before so the ring is think of this rank as a circle so the degrees based on the degrees this is a 360 degrees right so server lets say server one youre going to do a modulo 360 lets say were gonna get a zero right so were gonna put servers server one and as were gonna call it s0 based on the degree here right and then lets say server two ip address ten zero zero three modulo 360 we got 90 right and again im picking im picking values that are so rounded up this is just for example youre never going to get youre hardly going to get s 90 right exactly right youre going to probably get x is 27 right but yeah x90 same thing server 3 or server 4 youre going to get s 180 if after you do that and then server 3 gonna get s2270 we have s0 s90 s180 and s270 you know thats that completes an actual range and for people listening in the podcast think of this as an actual ring with the values for servers and each corner effectively so why are we doing this the beauty here is we have values and this is the key here lets have a key value of a thousand same thing youre gonna do right the thousand the key value thousand right however this key exists maybe it was blue and then you did a hash and then got you got the number thousand you take that thousand right and you do a modular 360 will you get an actual server immediately the server index no youre not going to get that so now lets lets actually put it in an actual example right here right so now im about to insert the value im going to insert a new key value 1 500 thats thats my key right there so what youre going to do is youre going to do modulo 360 which is the circle again dont dont be very uh specific on the the value 360 you can double this and double this and double this to get more values but im again this is just an example so 360 here so if i take 1500 right and modulo 360 im going to get a value of 60 if you think about it s60 doesnt exist there is no server marked 60 but heres a trick we do have a server mark as zero and we have an s90 so s60 really fits between the 0 and the 90 and what you do is you pick the next one so 60 if its between 0 and 90 immediately so that key will go to the next value which is s90 and thats thats how you do it basically now visually this is easy to understand right computationally this is not as simple because what does that mean between 0 and 90 i have i have four servers thats thats easy to find where where your value how 60 fits between 0 and 90 is actually computational and thats another binary search to actually find that value thats a little bit outscale outside the scope of this video but now once we have that value we have the 60 now okay oh 60 is like whats right after 60 is 90 now okay so the value of 1500 fits on server s90 thats how we solve it so by doing this scan what is the next one we really removed that discrete value lookup you know we instead changed it with a scan and the beauty of this scan is going to save us a lot of things in the future lets continue these examples all right 1500 lets take another example as a 2000 2000 modular 360 is 200 200 fits between server s180 and server s270 again 180 and 270 think of the as degrees right so right there in this case okay whats exactly right after 200 its 270 so 2000 less than 270 okay so think of it like youre looking at clockwise so whatever is the next value youre going to get that and then you put another value say 3000 modular 360 thats 120 120 if its between server 90 and server 180 select moves directly to the 180 and then you store the value 3000 there how about a thousand thousand modular 360 is actually gives you 280 wait a minute 280 is the there are no server after the last server the largest value is actually s270 there is no larger after that right there is no larger than two server 217 this is values 280 so what do you do if theres no larger values you go back to the circle right and this is very nicely when you actually draw the circle you see that s 280 is between s270 and s0 so you immediately go and put the value 1000 in server 0 and thats how you build the ring lets take another example for completeness here uh four thousand four thousand modulo 360 it gives you 40 40 is between 0 and 90 right oh thats very nice so for so now we have two keys slips in server s90 in this case yeah thats very interesting lets spice things up now what if i added a new server here look at the beauty of this here now if i add a new server here lets say its ipa this is at 10 0 0 13 right i do it modulo 3 360 and i got 50 so now my server is actually s50 fits right between s0 and s90 keep that in mind now things change because we still need to move data around but not as much lets figure that out how much data i need to move around well the algorithm goes like this right remember if you have values if you add value says 50 in this case anything between the 0 and the 50 really needs to be fit in server 50 right because thats the algorithm thats the range here that were looking at right here and so if you the the algorithms look like this like okay so what is the server right after me well the server right after me is right here is 90 right so lets query that server find out all the hash values and out all the hash values where the actual hash value is less than 40 right because s90 would have stored everything between 0 and 90 right so find out everything that is less than 50 because i i should store these now right so we found one entry which is 40 oh 40 doesnt belong 90 anymore so go ahead and talk to server 90 establish a communication could be tcp could be anything and then start moving data around right hey its 90 and do you have anything with a hash value that is less than 40 is this less than 50 which is me oh yeah i have this value move it to me and as a result we just established the data here so now think of it as as i add another server the only change is my neighbor really im only gonna bother my neighbor and its only the neighbor right after me right thats thats what im gonna do in this case right and so instead of actually bothering all the servers in my cluster im only bothering one server so thats much much much better than actual hashing but still there is a cost to it right there is complexity you need to build all that out what if the operation failed how do you roll back what if do you add the server anyway what if one of the keys didnt transmit so were adding so much complexity so distributed systems are not easy you guys right even if you think about it lets take another example where were removing a server if we go back to our original case where we have s0 s90 s180 and s27 and lets say im going to remove s90 altogether so now what happens here if you remove s90 then anything that s90 had must go to s180 if you think about it right because any value so now what what happens is the operation should go okay remove server s90 that operation that we need to do right im gonna remove that physically remove it not talking about a crash thats a completely different story right crash you dont even have time to move anything right so if you thats why you have to have redundancy thats another complication right there but if you have a physical operation that say okay i want to remove this for maintenance remove s90 well its 90 holes and all values between 0 and 90 so all of those should go directly to the server right after me clockwise which is 180 so remove all those puppies and stick them to where to server 180 thats a very expensive operation as well so if you think about it consistent hashing are powerful is powerful the algorithm of consistency are very powerful but the limitation here becomes you still need to move data around and the more data you have you know in these instances then the transmit of these will take more time so adding or removing server is actually not a trivial operation you know and then you really think need to think about another thing that is called replication you need to duplicate this data as much as possible because a server might crash so you need to have a backup so just using this algorithm blindly is not enough you have to cater for crashes you know and as a result you have to have a backup oh if this server is not available lets lets have a mapping server that actually directly copies that data immediately right so thats what you do you have to do that well what if two servers map to the same hash you cant have it if you have a lot of more than 360 servers youre gonna youre bound to have the value that fits in the same server and im not sure what you can do here you can what you can do is like i suppose in this case you can treat it as a as a replication so you have like a a backup scenario where we have this server you can either put it in both right that was an episode of the consistent hashing hope you enjoyed this video im gonna see on the next one guys thousand goodbye 