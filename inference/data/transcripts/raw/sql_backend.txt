second,duration,transcript
0.0,6.98,select star from
2.6,9.039,table is a universal SQL
6.98,7.0,syntax that will basically return all
11.639,3.601,columns in the table that you're
13.98,5.0,selecting
15.24,7.86,it's been said that select star is slow
18.98,6.879,and to avoid it like don't return on
23.1,4.2,column because it is slow
25.859,3.801,but
27.3,7.38,I want to actually
29.66,8.02,dive deep into the reasons of why select
34.68,5.1,star is is slow
37.68,3.36,some of these reasons you might already
39.78,5.099,know
41.04,6.48,hey we're turning 50 columns
44.879,4.02,is of course lower than returning one
47.52,3.96,but
48.899,4.801,I think some of these reasons
51.48,5.46,you might not have think about because
53.7,4.679,it really involves understanding the
56.94,2.759,entire stack
58.379,3.02,and
59.699,4.261,the backend
61.399,6.101,engineering fundamentals and
63.96,5.4,specifically the network aspects of
67.5,4.34,things as well
69.36,6.84,you know and of course
71.84,7.56,programming logic memory management how
76.2,7.86,the OS works all of this really affects
79.4,6.46,the performance of your queries and
84.06,3.599,selecting all the fields while
85.86,4.74,convenient because you don't have to
87.659,5.761,enumerate the fields you want
90.6,5.159,it's really it can impact the
93.42,5.4,performance in general so
95.759,5.941,I wrote up an article on medium that I'm
98.82,6.36,gonna review in this video I'm going to
101.7,5.94,add my comments and going through the
105.18,5.04,reasons of all of these things how about
107.64,4.56,we jump into it alright so
110.22,4.98,all right so let's get started how slow
112.2,5.879,is Select star let's read this little
115.2,5.58,bit of a paragraph and then start
118.079,5.881,discussing this though in a row store
120.78,6.299,database engine rows are stored in units
123.96,5.279,called Pages boy don't get me started
127.079,3.9,now we're already in the first sentence
129.239,4.161,and I already
130.979,5.161,like thinking about this stuff right
133.4,5.8,after I ride this and then coming back
136.14,7.14,and says wow there is just so much to
139.2,7.86,these things like a page is and a block
143.28,6.12,is the most overloaded term in in in
147.06,6.92,software engineering that is right you
149.4,8.22,have no idea how the word page shows up
153.98,6.82,in the entire stack you know from the
157.62,8.82,database to the file system to the
160.8,9.48,operating system to the uh SSD itself
166.44,6.72,right or to the drive itself the page oh
170.28,4.52,pages are all different in sizes and
173.16,4.859,specifically here we're talking about
174.8,6.939,database pages right and then database
178.019,6.36,pages are are really fixed size like all
181.739,5.821,the databases that I know of use fixed
184.379,7.621,size Pages or just just think of it
187.56,7.38,structure I suppose with headers and the
192.0,7.92,content of the page is essentially
194.94,7.68,mostly rows or if you have like a column
199.92,5.459,store it's going to be the columns right
202.62,4.38,for that first row and then the columns
205.379,3.121,for the second rows it depends on the
207.0,3.12,implementations and if you have
208.5,3.3,documents it's going to be the document
210.12,3.24,so it's going to have graphs it's going
211.8,4.019,to be the graphs
213.36,4.44,and so on right and of course this
215.819,4.861,little bit changes if this is an index
217.8,4.56,page versus a heap page but essentially
220.68,3.96,that's the gist of it right so
222.36,5.04,everything is at the page effectively
224.64,5.099,right and this is an example I put where
227.4,4.619,this is how the postgres page looks like
229.739,7.881,there's a bunch of headers and these are
232.019,9.421,called the the Tuple pointers and they
237.62,8.92,specifically specify where does this
241.44,7.019,Tuple start in byte 134 and it has a
246.54,5.52,length of 20 bytes right and the second
248.459,7.46,table starts at 155 and it has 10 and
252.06,8.04,this is basically lives in page zero
255.919,6.301,those are Pages there but so technically
260.1,4.98,speaking if you really think about it
262.22,6.64,the row
265.08,6.839,is stored in the page with all its
268.86,5.64,columns so the first question is since I
271.919,5.521,am when I read a page
274.5,5.58,I get all the rows
277.44,4.979,and in that page and I get all the cons
280.08,5.64,so technically select star should be
282.419,6.0,cheap right because I already have all
285.72,6.539,the columns in line
288.419,5.401,quote unquote online in that page right
292.259,3.301,because that's how raw store stores
293.82,4.5,things basically we're dealing with
295.56,6.44,transactional you know workload in this
298.32,6.84,case so we'll always assume raw store
302.0,5.259,but but then why is why do people tell
305.16,3.72,us that select start is slow and that's
307.259,6.361,basically what we need to understand
308.88,7.68,here right you see every time you fetch
313.62,6.24,let's say let's explain first of all how
316.56,5.639,do we read something right I want to
319.86,6.059,read a row
322.199,3.72,right select
325.94,8.039,star from table where ID equal one let's
330.78,6.12,say this is a student ID right so
333.979,5.141,assuming there is no index
336.9,4.26,what the database will do is okay we're
339.12,4.32,going to do a full table scan so there
341.16,5.879,is your table and the table is literally
343.44,5.46,one file and it is organized as an array
347.039,4.261,of these pages that we talked about this
348.9,4.56,fixed size pages so what what the
351.3,4.5,database will do is again I need to do a
353.46,4.86,full table scan
355.8,4.739,and what that means is I need to scan
358.32,6.659,the pages one by one in the file so I'm
360.539,6.841,gonna read page 0 from the file how do I
364.979,4.321,get page zero remember when you read
367.38,3.92,from disk you have very
369.3,4.619,a certain
371.3,5.26,operations when you want to read right
373.919,5.521,you you read you specify the file
376.56,5.759,descriptor where do you want to read
379.44,6.36,from where the starting position is and
382.319,5.88,how much bytes you want to read that's
385.8,5.339,it and the how much thing is I think up
388.199,4.5,to two gig that's the limiting and Linux
391.139,4.021,at least okay
392.699,4.321,that that's all you already got so how
395.16,4.259,does that convert to pages when it comes
397.02,5.519,to databases well once you understand
399.419,6.06,the fundamentals is this is all simple
402.539,5.761,stuff right the database to read page
405.479,4.981,zero page 0 starts at the zeroth
408.3,5.22,position in the file so the opposite is
410.46,6.0,zero and Page the page size is also
413.52,7.14,fixed right in postgres is 8k in annual
416.46,8.04,DB MySQL is 16 right and
420.66,5.52,so the length is 8k it's all effects so
424.5,4.259,you might say how do I read page seven
426.18,4.92,then well seven is literally page seven
428.759,4.741,is seven times the length of all the
431.1,5.099,pages that went before it right so seven
433.5,5.52,times eight plus one so you actually
436.199,6.78,start the next page right the next buy
439.02,5.399,and then you read 8K right and so on
442.979,4.081,that's that's basically how you read
444.419,6.241,pages once you the database reads the
447.06,6.96,these raw bytes and and these in Reading
450.66,6.24,verses there's little more to it than
454.02,4.86,then just I say read right I don't like
456.9,3.96,to say these things anymore I like to
458.88,4.02,understand how things work there's
460.86,4.8,there's layers and layers and layers of
462.9,5.82,things underneath that read operation
465.66,5.819,that is the file systems involved the
468.72,5.58,the bytes are converted into file system
471.479,6.541,blocks and these blocks are mapped to
474.3,5.28,the SSD blocks or the sectors or in the
478.02,4.2,in the drive
479.58,6.179,and those blocks are physically
482.22,6.539,retrieved you know because the API to
485.759,7.041,read offset length is not consistent
488.759,8.22,across the the the the the the the
492.8,7.72,storage driver right we don't read bytes
496.979,6.241,we read blocks assuming this is a block
500.52,4.44,storage right we we deal mostly with
503.22,4.68,block storage so everything is a block
504.96,5.34,so if you want to read a single byte you
507.9,5.1,read whatever the number of minimum
510.3,6.239,number of block the file system allows
513.0,5.94,you to and that's 4K in most cases
516.539,4.321,all right so I'm gonna I'm gonna talk
518.94,4.979,about this maybe in another video so so
520.86,6.72,just so I don't I don't go off track
523.919,4.441,here but once you read that
527.58,4.92,um
528.36,6.539,once that page is read from the SSD
532.5,5.22,transfer to the file system into many
534.899,5.821,blocks and now we have the raw bytes the
537.72,7.619,operating system have the raw bytes in
540.72,8.4,memory hot right the database now takes
545.339,6.06,those Place those memory location and
549.12,5.7,space them into something called the
551.399,7.261,shared buffers right it's the databases
554.82,7.019,on Cache where those pages will be lived
558.66,4.679,so that hopefully someone will want to
561.839,4.44,query something
563.339,5.641,that is in the same page so I just pull
566.279,4.5,to this shared memory effectively it is
568.98,3.18,the reason is shared memory because the
570.779,4.261,databases will spin up multiple
572.16,4.739,processes of course most databases deal
575.04,3.84,with multi-processes and these
576.899,3.721,multi-processes all of these executing
578.88,2.76,multiple transaction that you need to
580.62,4.68,see
581.64,5.639,a unified view of of all the pages and
585.3,4.44,this is where the shared buffers are
587.279,6.06,located right so that's what we do so
589.74,6.719,when I do a select ID right one oh
593.339,5.341,that's uh page zero oh well we don't
596.459,5.581,really know it's page zero we just scan
598.68,7.86,we read page zero now look let's read
602.04,6.6,row by one is is the id1 is id1 is the
606.54,4.739,id1 and then we find it if we didn't
608.64,5.4,find it we
611.279,5.341,read the next page page one and then it
614.04,5.28,verified it is page page two and so on
616.62,4.56,right until we find that ID and once we
619.32,4.32,find it
621.18,7.86,we really have everything because the
623.64,7.62,page have all the columns in line
629.04,3.479,I'm gonna put an asterisk on that so
631.26,3.84,that's
632.519,4.921,that's how things work now
635.1,5.1,now let's go to the reasons because now
637.44,5.579,everything is there why is Select star
640.2,3.78,slow right let's first go to the first
643.019,4.741,reason
643.98,7.38,case index only index only scans goodbye
647.76,5.46,first of all you're right right if
651.36,5.159,you're actually reading the Heap which
653.22,5.04,is the table data you're right you have
656.519,3.541,that select store
658.26,4.56,you can have everything
660.06,5.459,but here's what you miss on
662.82,4.68,let's assume you have an index
665.519,4.44,like a student let's go back to the
667.5,3.54,example of students right if I am a
669.959,3.661,student
671.04,4.739,and I have a table student there is a
673.62,3.899,the table uh there's an ID field there
675.779,3.901,is a grade there is a name there's a
677.519,4.201,bunch of other stuff right so now I have
679.68,4.08,the student who has an ID that is a name
681.72,4.859,there's a gray there's a bunch of other
683.76,6.54,columns as well right
686.579,5.221,so now as you might have a grade
690.3,4.5,index
691.8,4.92,an index on the great field
694.8,4.32,so if I do
696.72,4.2,a query says okay give me all the
699.12,2.82,student IDs I'm just interested in the
700.92,5.7,IDS
701.94,5.94,that scored more than 90.
706.62,4.62,right
707.88,4.8,Mark a mark of 90 or higher
711.24,3.9,well
712.68,7.68,if you're great
715.14,8.939,index and assume let's assume this is
720.36,5.64,my sequel right or
724.079,3.661,SQL Server
726.0,3.959,and I always I picked those two letters
727.74,3.659,because they they store secondary
729.959,3.06,indexes a little bit different than
731.399,3.661,postgresway and we're going to come to
733.019,4.081,the boss guys it's just it's very
735.06,5.16,similar there here
737.1,4.859,so now because I'm doing a grid grid is
740.22,4.5,greater than 90. definitely I'm going to
741.959,5.101,use the index that is there right so as
744.72,3.96,I'm scanning the index and again the
747.06,4.32,scanning the index is going through the
748.68,3.96,B trees and the b3s have layers and
751.38,4.68,these layers
752.64,5.22,store these keys and the keys are stored
756.06,4.38,in pages and the pages are stored on
757.86,4.8,disk very similar thing it's just that
760.44,3.78,data structure is different now but but
762.66,4.1,the content is still Pages you're
764.22,2.54,reading pages
766.94,5.92,now we have read this we read through
770.7,6.24,this beautiful
772.86,7.8,index and we found as we're scanning
776.94,5.82,right because the index is ordered the
780.66,4.14,grades because we are having an index on
782.76,5.34,the grade it's order so the ones I find
784.8,6.779,the 90 I find 90 and 90 and 90 and
788.1,5.88,another 90 and a 91 and 92 everything is
791.579,6.781,ordered and and and
793.98,7.38,because the value of the secondary index
798.36,6.18,in the leave page is the primary key
801.36,5.279,right again this is let's see my sequel
804.54,5.039,right
806.639,6.241,uh or Oracle of the you have an index
809.579,6.541,organized uh table right
812.88,5.579,then you technically have the ID because
816.12,6.12,the CSA the ID is the primary key right
818.459,6.601,you have the ID right there in the leave
822.24,5.52,page in the index so your
825.06,5.519,your work is done
827.76,4.68,technically rock is done I said you
830.579,4.021,found the the grade you have over there
832.44,5.459,of course is right there
834.6,4.859,and you have also the the primary key
837.899,5.341,which is the ID which is what you want
839.459,8.401,so it becomes what we call a covering
843.24,7.8,uh indexes scan or in in postgres speak
847.86,5.46,is called index only scans right so you
851.04,4.26,only really need to scan the index
853.32,4.8,because you don't really need anything
855.3,5.279,else you just ask for the ID but the
858.12,5.339,moment you do select star that
860.579,4.921,optimization is just screwed the
863.459,4.141,database is
865.5,3.72,you really had to ask for the all the
867.6,4.739,fields are you really did have to do
869.22,4.679,that damn it now says okay you need the
872.339,4.5,ID but you also need the name and you
873.899,6.661,need the date of birth and you need uh
876.839,6.3,his documents and whatever right so now
880.56,6.12,what the database needs to do is collect
883.139,7.081,all these IDs which our primary ID is
886.68,6.899,and now it has to do turn around and do
890.22,7.979,another lookup it's called index six
893.579,9.0,right on the primary key hey I have I
898.199,11.161,found ID 7 scored more than 90 and 11
902.579,8.7,and 1007 and 1008 and and and 20
909.36,4.32,0007
911.279,4.68,they have to be random right because you
913.68,4.62,don't you have no idea that the students
915.959,4.921,who score more than 90 are actually in
918.3,4.5,order right you'll be lucky but it's
920.88,4.259,never the case this is called random
922.8,3.779,reads So Random reads are the worst
925.139,3.661,right I wanted you to the database
926.579,5.581,random everything is the worst when it
928.8,5.64,comes to ssds reading from desk reading
932.16,5.16,of databases you want to avoid those but
934.44,5.88,sometimes you can't right so now you
937.32,6.06,have a collection of these puppies you
940.32,5.16,turn around and then do another scan or
943.38,4.019,a seek on the primary index so you say
945.48,4.799,Okay I want to find this a student this
947.399,6.421,student so you'll be you'll be
950.279,7.62,scatter shot all over the index which
953.82,5.759,will cause eventually many i o
957.899,4.861,to desk
959.579,6.2,why because you just chose to do a star
962.76,6.8,instead of asking for what you want so
965.779,7.0,really really slow stuff in postgres
969.56,5.44,right in postgres
972.779,5.661,by default when you just create an index
975.0,6.42,on the grade right
978.44,4.959,always has to do that even if you ask
981.42,5.3,for the ID it has to go back to the
983.399,5.18,table because uh
986.72,5.2,postgres
988.579,5.081,secondary indexes which is everything is
991.92,5.58,secondary there are there are no primary
993.66,5.4,indexes in in postgres the the value is
997.5,3.899,actually called the Tuple ID which is
999.06,4.8,where we explained right here right a
1001.399,6.18,typical ideas is literally is literally
1003.86,8.099,a two pair which is Page index and the
1007.579,5.94,index of the Tuple or the row in that
1011.959,4.68,page right
1013.519,7.56,that's that's what it is so like this in
1016.639,5.961,this particular case page 0 comma one is
1021.079,6.061,the first row
1022.6,5.859,0.2 0 comma two is is the second Tuple
1027.14,3.36,and so on right
1028.459,5.34,so so that that's that's what's
1030.5,5.64,happening to and posca stores these
1033.799,5.04,tuples so it has to go back but in
1036.14,4.679,postgres you also can have a covering
1038.839,4.321,indexes where you can create an index
1040.819,6.061,and you include columns from the Heap
1043.16,7.92,from the table in the index right such
1046.88,6.12,that that index will have the ID or will
1051.08,4.38,have anything else you want
1053.0,5.22,so you can get that beautiful index only
1055.46,5.82,scan so if you have such index and your
1058.22,5.04,front-end application on this case is
1061.28,4.68,actually is the backend server right
1063.26,4.799,that actually executes the query in this
1065.96,3.18,case it is a front-end to the database
1068.059,3.061,right
1069.14,4.56,well
1071.12,4.439,will not utilize this beautiful index on
1073.7,3.839,this Castle so that's that's the first
1075.559,4.141,case index only scans
1077.539,4.64,you basically kiss them goodbye when you
1079.7,4.92,do a select Star right
1082.179,4.601,you might say okay I don't care the
1084.62,4.7,random reads affecting from this is
1086.78,5.94,really bad okay let's talk about
1089.32,6.58,deserialization cost
1092.72,7.94,correct when you select star
1095.9,8.34,The Columns live in the page
1100.66,5.56,but getting them out
1104.24,5.64,and into
1106.22,5.4,the protocol that will be eventually
1109.88,4.02,delivered to the
1111.62,3.72,app
1113.9,4.019,will require something called
1115.34,4.74,deserialization because these are just a
1117.919,5.64,bunch of bytes at this point they are
1120.08,7.14,raw bytes in the page because the page
1123.559,6.421,is just literally a memory once it it's
1127.22,5.64,pulled into the memory right through
1129.98,4.68,right you you may lock it effective
1132.86,4.8,effectively it's just a bunch of bytes
1134.66,5.82,right so so now you have to actually
1137.66,5.16,parse right it says okay there's this
1140.48,3.84,row and the first this is the First
1142.82,3.359,Column this is the second column this is
1144.32,3.96,the third column and once you get the
1146.179,5.221,content of this column you actually have
1148.28,6.72,to coerce you have to deserialize this
1151.4,5.519,from byte down to the data type of
1155.0,4.2,whatever this thing is if this is an
1156.919,5.64,integer you cast it to an integer if
1159.2,4.62,this is a long if this is a double it
1162.559,3.601,has to do a double
1163.82,4.32,if this is a custom
1166.16,3.84,data type you cast it to this custom
1168.14,3.3,data type there's a string request a
1170.0,5.28,string
1171.44,6.26,that also has a cost not much but it can
1175.28,5.46,add up if you have a lot of columns so
1177.7,6.4,deserialization cost you can really add
1180.74,7.14,up because you don't really know
1184.1,6.3,how many fields that exist in advance
1187.88,6.72,right he's doing select store you have
1190.4,6.06,to do all of that stuff right and and
1194.6,3.78,that decentralization of course again
1196.46,4.56,we're talking about the day at the
1198.38,6.06,database level here converting the page
1201.02,6.32,raw byte to data structure that then
1204.44,6.3,that data structure will be
1207.34,6.52,serialized I suppose down to the network
1210.74,6.36,eventually right but but but but dealing
1213.86,8.1,with them into a number or a value
1217.1,8.16,the conversion needs work and and it
1221.96,5.7,needs to be stored in its own form as a
1225.26,4.32,variable as a data structure so you're
1227.66,3.84,actually allocating more memory if you
1229.58,2.76,think about it just to store these
1231.5,2.34,things
1232.34,5.28,right
1233.84,5.04,building those raw objects
1237.62,4.38,all right
1238.88,4.14,so that's uh legislation cost right not
1242.0,2.94,much
1243.02,4.98,but it can add up
1244.94,4.5,okay not all columns are in line first
1248.0,4.799,of all what do we what do you mean by
1249.44,6.0,inline when we say in inline when I say
1252.799,5.76,inline I mean when I say when I have a
1255.44,6.239,raw Store where the rows are literally
1258.559,5.881,one after the other row all columns
1261.679,4.86,first row all columns second row all
1264.44,4.26,columns third row all comes just one
1266.539,5.301,after the other right
1268.7,5.16,The Columns that are appearing inside
1271.84,4.26,the row
1273.86,5.46,I'll call it in line in the same page
1276.1,5.56,right there it's called inline columns
1279.32,5.84,okay and you're going to see this word
1281.66,6.3,being used all the time like inline
1285.16,4.899,functions right and compiler like like
1287.96,3.9,inlining sometimes gives poor
1290.059,4.801,performance things right but the problem
1291.86,5.34,here is remember when we said pages are
1294.86,5.1,fixed size I forgot to mention one thing
1297.2,4.56,which is rows cannot really span
1299.96,4.44,multiple Pages if you have like what do
1301.76,5.039,you have like a really big role with a I
1304.4,5.34,don't know 20 000 columns can't happen
1306.799,5.641,but if you have that then the raw
1309.74,5.819,technically cannot fit you will have one
1312.44,4.8,page with a single row and that row will
1315.559,4.441,not fit that page because it's so big
1317.24,4.559,right so you you will have to spin up
1320.0,3.72,another page to complete that role
1321.799,5.341,database never allowed to do that
1323.72,5.939,because the complexity to find the row
1327.14,4.86,becomes exponentially harder so no
1329.659,5.101,databases as well as far as I'm aware
1332.0,5.22,allow rows to be spanned between
1334.76,5.64,multiple Pages just because of the
1337.22,7.14,complexity if you think about it right
1340.4,6.72,so Rose cannot span badges because of
1344.36,6.12,that then Hussain what do I do if I have
1347.12,7.22,one field of the strength that has the
1350.48,3.86,entire work of Shakespeare in it
1354.679,5.761,that's what databases do like think
1356.659,6.301,about this or or blob or lobs right
1360.44,6.599,things that are actually binary that are
1362.96,6.24,stored in as a column Jason Jason's are
1367.039,3.721,rarely stored in line like Json
1369.2,4.2,documents like in postgres or other
1370.76,5.96,databases you can't because you can't
1373.4,7.62,fit a page so what happens is
1376.72,5.439,those are assigned a pointer and when I
1381.02,3.779,say a pointer
1382.159,4.921,don't think of a C sharp position don't
1384.799,3.24,think of a c pointer here and it's
1387.08,3.42,actual
1388.039,5.76,it's an it's a unique identifier that
1390.5,7.679,points back to that blob right so what
1393.799,6.721,happens is a a marker is created and
1398.179,3.24,that thing is placed on an external
1400.52,4.8,table
1401.419,5.821,right and and MySQL has it poscus has
1405.32,4.56,it's called toast right they have to
1407.24,4.38,have it there's no way out you have to
1409.88,5.22,have some external
1411.62,6.059,place to store your stuff right there
1415.1,4.5,are they cannot fit into the page
1417.679,3.781,and as a result if you think about it
1419.6,4.439,this actually what limits the number of
1421.46,4.56,columns why don't databases allow
1424.039,3.901,unlimited number of columns because of
1426.02,3.86,this reason right because at the end of
1427.94,5.28,the day you can have a non-variable
1429.88,4.779,static type integer like the integer is
1433.22,4.56,not variable right it's a fixed size
1434.659,6.601,it's either four byte or eight okay 64
1437.78,5.879,or 32 right if you have that then how
1441.26,4.08,many actually you cannot really put that
1443.659,4.821,outside it doesn't make sense right
1445.34,7.44,that's an integer right so
1448.48,7.12,so so what happens is you are limited by
1452.78,4.44,the whatever the number of columns based
1455.6,3.059,on certain calculation you can do the
1457.22,4.38,math as well
1458.659,4.861,so what what databases do is they take
1461.6,4.68,that long strength that long document
1463.52,5.519,that long blob that long Json put it in
1466.28,5.22,another table put an ID to it and that
1469.039,6.02,ID is instead is stored in it's very
1471.5,8.4,tiny like one or two bytes or even less
1475.059,8.261,inline so you only that column only have
1479.9,4.98,the pointer that identifier of the
1483.32,4.92,external storage
1484.88,4.919,it's never stored in line
1488.24,3.66,right
1489.799,4.021,and again it depends on the size of the
1491.9,4.68,thing right sometimes if you have like
1493.82,4.62,128 characters supposed to say eh okay
1496.58,4.38,I'll put it in line right there is there
1498.44,4.739,is a threshold to decide that but mostly
1500.96,4.92,large stuff are stored outside and guess
1503.179,5.581,what they're often compressed
1505.88,5.58,so there is a cost if you actually say
1508.76,5.22,give me that Json give me that document
1511.46,4.8,give me that strength you're asking the
1513.98,4.319,database yeah you're saying it's already
1516.26,4.86,in line uh no
1518.299,5.76,I got this but I have to now do another
1521.12,4.52,query to another table called the toast
1524.059,5.701,table and postgres
1525.64,6.1,the oversize something uh text or
1529.76,3.12,something I forgot what it stands for
1531.74,3.12,okay
1532.88,4.38,and that
1534.86,4.86,is an additional IO
1537.26,4.919,because that page where that toast
1539.72,4.579,exists might not be in the shared
1542.179,5.521,buffers and as a result you're just
1544.299,6.461,closed another i o
1547.7,5.28,look at the work you're doing look at
1550.76,6.419,the pain you're causing
1552.98,7.079,you're causing pain an IO call goes to
1557.179,4.98,the disk and the disc suffers every time
1560.059,4.561,you hit it with an i o
1562.159,5.64,right next time you do a select star
1564.62,6.0,think about the suffering you're causing
1567.799,4.38,to all this equipments
1570.62,3.12,okay
1572.179,3.24,I tried to say this with the straight
1573.74,5.52,fair but I couldn't
1575.419,5.581,okay so especially that because these
1579.26,3.539,are things are compressed
1581.0,4.559,right and you can disable compression if
1582.799,3.901,you want but that will just blow to your
1585.559,3.72,storage
1586.7,4.8,if you don't care about storage sure
1589.279,4.681,but then
1591.5,5.76,not only you're pulling it from an i o
1593.96,6.599,external now either a CPU involved
1597.26,6.48,now you're making the CPU work for you
1600.559,5.701,right you're uncompressing stop because
1603.74,4.559,uncompressing has to be done in memory
1606.26,6.299,right now I'm just like ah let me
1608.299,6.721,uncompress Huffman encoding whatever
1612.559,5.401,right gzip
1615.02,4.86,all this stuff is happening now geometry
1617.96,4.44,stuff you deal with geometry I do with
1619.88,4.26,geometry all day that's my basically my
1622.4,3.019,my nine to five
1624.14,3.3,okay
1625.419,5.921,geometry stuff
1627.44,7.38,GIS right so so yeah
1631.34,6.36,this is really expensive right so it's
1634.82,6.239,doing select store now you're silently
1637.7,4.979,and and the sad part is if you ask the
1641.059,3.421,neighbors to do all this stuff to pull
1642.679,4.401,all these blobs to pull these strings
1644.48,5.579,and you just in the client you just say
1647.08,5.14,I really just needed the ID well I don't
1650.059,4.021,really need the rest of this stuff
1652.22,5.16,all right it's like asking someone to
1654.08,6.06,bring you all this stuff right and bring
1657.38,4.26,you a dish of food or something but you
1660.14,5.76,only take one thing
1661.64,7.44,you say oh I I don't want that anymore
1665.9,5.7,how rude how rude really
1669.08,4.079,okay not all comms are online so be
1671.6,4.579,careful
1673.159,5.161,be very careful Network cost
1676.179,3.941,when was the last time you're back and
1678.32,3.719,running the same time in the same place
1680.12,3.9,as the database never
1682.039,4.441,you'd ever put the database in the same
1684.02,5.58,place as the back end right they don't
1686.48,5.46,they never run in the same processes in
1689.6,4.02,the same host right sure you can run in
1691.94,4.92,the same physical Halls on a separate
1693.62,4.919,container right but I don't know why I
1696.86,5.16,would do that but you might have
1698.539,5.341,virtualization set up but still you have
1702.02,4.7,to separate them there is networking
1703.88,6.0,involved right
1706.72,5.86,and and of course you need to keep them
1709.88,5.82,as close as possible so the latency is
1712.58,5.76,low right you don't want to put one in
1715.7,5.459,U.S West and the second one is the
1718.34,6.0,database is you and us East and the back
1721.159,6.421,end application in U.S West and you
1724.34,4.8,expect queries to be fast no you have to
1727.58,4.44,put them in the same network Zone
1729.14,5.82,hopefully right and if if you can't then
1732.02,5.34,create replicas and have the replicas
1734.96,4.38,close by right I think I created a one
1737.36,5.58,video at some point I think I think it
1739.34,6.3,was clever keep your database closed and
1742.94,4.32,your no keep your servers closed and
1745.64,4.139,your database closer
1747.26,5.76,I think I think that was clever
1749.779,5.941,a clever way of saying it did I just
1753.02,6.12,call myself clever because kids kids
1755.72,7.199,these days will call me crunch so uh
1759.14,5.82,right Network cost so now that we talked
1762.919,5.041,about okay you selected all the fields
1764.96,5.099,you took the hit you did you avoided the
1767.96,7.28,beautiful index on the scan you took the
1770.059,8.641,head of database uh data structure C
1775.24,7.179,deserialization from the page down to
1778.7,6.959,their finger and then you took
1782.419,7.62,uh uh uh what was that what else
1785.659,6.061,yes uh you you told me to get all these
1790.039,4.74,text fields and blobfish and Jason
1791.72,5.28,Fields so I had to go to a toastable an
1794.779,5.161,external table decompress them and and
1797.0,6.36,also put them in a data structure so the
1799.94,5.219,double double trouble and then now I'm
1803.36,4.679,ready to send it back across the network
1805.159,4.38,now each database has its own networking
1808.039,5.12,protocol right
1809.539,6.841,right it could be most used like binary
1813.159,6.041,specific proponentation I don't see I
1816.38,4.799,didn't see really a a unified
1819.2,4.38,uh and that's something I I talk about
1821.179,6.72,sometimes in my channel where there is
1823.58,6.78,no unified database protocol
1827.899,5.28,doesn't exist every database just does
1830.36,5.58,its own thing right unlike the web we
1833.179,6.421,have HTTP right it's a unified web
1835.94,7.14,protocol anything web you go HTTP right
1839.6,6.299,and there's like the the use cases uh
1843.08,5.099,went beyond web right
1845.899,5.041,so everywhere else like this is the de
1848.179,4.801,facto standard some people brought HTTP
1850.94,5.339,down to the database I don't know how
1852.98,5.34,how well that performs to be honest
1856.279,3.841,but but every database does its own
1858.32,4.079,thing like a SQL server has its own
1860.12,4.38,postgres has its own redis has its own
1862.399,5.221,everybody database I was like ah I want
1864.5,6.179,to build my own and then now you
1867.62,5.22,you realize that data structures you
1870.679,6.12,have down serialized it down to bytes
1872.84,6.24,down to this protocol uh language that
1876.799,5.461,you have right so the serialization
1879.08,7.079,aspect to to that protocol application
1882.26,6.6,Level protocol right your application at
1886.159,4.981,that the database protocol application
1888.86,5.52,in this case right whatever that
1891.14,5.94,structure is right and then that goes
1894.38,4.86,into the the transport protocol which we
1897.08,4.319,don't have anything else TCP that's all
1899.24,5.059,what we have right so it goes into down
1901.399,5.88,to IP packets and then
1904.299,5.021,segments sorry and then IP packets and
1907.279,3.601,those IP packets are shipped right
1909.32,4.5,so now
1910.88,5.279,if you're sending really really really
1913.82,7.02,really large
1916.159,7.62,columns the response from that protocol
1920.84,6.12,the database response the database SQL
1923.779,5.52,result will be so large such that the
1926.96,3.959,network transmission you will feel it
1929.299,4.201,especially if you have like larger
1930.919,6.181,latency you will feel it
1933.5,7.86,because now I need to write
1937.1,6.299,and the the maximum I can write at a
1941.36,5.4,time is the MTU which is the maximum
1943.399,5.76,transmission unit defined by the IP
1946.76,6.899,layer like layer three and that's
1949.159,7.14,basically is defined based on on path
1953.659,5.161,Discovery MTU right the the the the the
1956.299,4.38,the the protocol that discovers what is
1958.82,4.68,the weakest link
1960.679,5.88,in this network that I'm transferring
1963.5,5.48,this is okay what is the minimum I can
1966.559,4.98,send or maximum in this case I can set
1968.98,5.98,1500 is the default
1971.539,5.721,on the internet you can send lower there
1974.96,5.88,are some routers like a support like 500
1977.26,6.7,like very old routers by 1500
1980.84,4.8,is the standard there are routers with
1983.96,3.839,jumbo
1985.64,3.779,frames that suppose like nine thousand
1987.799,3.781,and stuff like that and they are even
1989.419,5.64,large but that's the kind of standard so
1991.58,5.819,you can only send 15 bytes at a time in
1995.059,4.62,the IP and that even it's even lower the
1997.399,4.02,TCP segment layer right
1999.679,4.261,I know I'm going into very details but
2001.419,4.74,this is the point in all my videos I
2003.94,4.56,always go into details right I don't
2006.159,4.201,make like one minutes videos and deal
2008.5,3.899,with it I I like to explore this thing
2010.36,4.439,because I I am passionate about this
2012.399,5.16,stuff so I apologize if you don't like
2014.799,7.201,this content but I really do like to go
2017.559,6.36,into these details it couldn't brush
2022.0,6.059,everything like I understand everything
2023.919,6.6,remove the black boxes so now if you
2028.059,4.62,have a lot of data even if you do
2030.519,3.721,compress it which is an additional CPU
2032.679,4.86,database overhead
2034.24,7.02,then you still have to transmit it and
2037.539,5.281,the the conjunction algorithm protocols
2041.26,3.539,and slow start
2042.82,6.68,will allow you to send
2044.799,7.141,multiple of these 1500 or 1460 segments
2049.5,4.78,without waiting for an acknowledgment
2051.94,3.6,right and initially you're going to send
2054.28,4.079,one
2055.54,6.059,I suppose 10 recently 10 segments at a
2058.359,5.941,time like Google increased the initial
2061.599,4.921,window size for the congestion window to
2064.3,3.96,10 I suppose because like there is no
2066.52,3.96,point the intern is really fast these
2068.26,5.159,days so let me send 10 at a time so 10
2070.48,5.34,times 15 that's like what that's 15K
2073.419,5.22,this is 15K
2075.82,6.059,right so you can say 15K at a time if
2078.639,5.361,you want right at a stocked right and
2081.879,2.121,then
2084.04,4.02,but but not all Network supports that
2086.139,4.02,right so it always starts slow and then
2088.06,5.279,it creates increase increases slowly
2090.159,5.821,right incremental increases so now as
2093.339,6.681,you go through this you're sending that
2095.98,6.359,but eventually the client have to start
2100.02,4.18,acknowledging this it has to process
2102.339,4.02,this and it only the client only
2104.2,4.74,acknowledged something that actually was
2106.359,4.74,able to receive right so if there is a
2108.94,4.2,data loss guess what the client didn't
2111.099,3.901,receive it the server
2113.14,4.32,timeout will hit and then we'll
2115.0,5.24,retransmit it so all of this you'll feel
2117.46,6.36,it then more Network you have latency
2120.24,5.619,the more you will kind of feel it that's
2123.82,4.32,why it's like I always feel like
2125.859,3.601,applications if you want to really test
2128.14,4.08,applications
2129.46,5.399,like when it comes to Performance like
2132.22,4.8,just just put put the database and the
2134.859,6.0,back end in a very
2137.02,5.46,really you know uh far apart I know it's
2140.859,4.021,a bad idea right to do that in
2142.48,4.8,production but but it will it will force
2144.88,4.38,you to optimize because you're gonna you
2147.28,3.78,you're gonna send as small as possible
2149.26,3.3,and you're gonna receive as small as
2151.06,3.12,possible data you're gonna say okay ah
2152.56,2.4,why am I sending this much let me send
2154.18,3.6,less
2154.96,6.68,right so it's like putting yourself in
2157.78,6.96,slow mode such that you feel the pain
2161.64,4.959,uh off of these kind of things right so
2164.74,5.099,returning all columns require
2166.599,5.941,decentralization right of of these large
2169.839,4.801,columns such as strengths blob the
2172.54,4.26,client will never use that's the sad
2174.64,4.58,part all of this you're encoding all the
2176.8,4.799,high cost of transmission for nothing
2179.22,4.359,nothing at all
2181.599,5.041,and then we finally talk about the
2183.579,4.801,client deserialization where now that I
2186.64,4.4,actually the client received all this
2188.38,5.64,raw TCP
2191.04,5.559,segments from the neck
2194.02,7.44,the neck actually transferred it to the
2196.599,9.121,OS through dma and then that becomes
2201.46,6.96,just robots and the sigma and the OS now
2205.72,4.859,just say okay what's for this listener
2208.42,4.62,where is this going this is IP this IP
2210.579,4.321,this destination all right it is this
2213.04,5.039,socket so it will start transmitting
2214.9,5.52,your data to The Client app which is the
2218.079,6.121,the basically if you have no node.js
2220.42,6.659,that's the node.js app and specifically
2224.2,3.96,the library that you use for the
2227.079,2.221,database
2228.16,3.78,uh
2229.3,4.62,uh client right so if it's a postgres
2231.94,4.38,client that will be that that Library
2233.92,5.22,will be called and you're at the mercy
2236.32,5.4,of how this library is authored how is
2239.14,4.56,it parsing the protocol how is it how is
2241.72,4.98,it understanding this stuff that's why
2243.7,6.54,lazy parsing is also a thing and a
2246.7,6.36,client side where uh let's actually wait
2250.24,5.04,for the client to consume some of the
2253.06,4.559,stuff such that
2255.28,5.16,you can avoid the head of client
2257.619,4.921,deserialization and client building all
2260.44,5.94,these objects fetch has the same thing
2262.54,6.0,by the way right the fish API fetch API
2266.38,4.26,when you call it
2268.54,3.539,it will it will it will give you the
2270.64,3.6,headers only it will give you the
2272.079,4.561,response but it'll give you the just the
2274.24,3.78,byte the raw body right you cannot
2276.64,6.84,actually do anything with the body until
2278.02,7.8,you call Body Dot Json function so go
2283.48,4.44,ahead and actually took take the head to
2285.82,4.88,actually this realizer and the reason
2287.92,5.88,they do fish does it this way is because
2290.7,4.72,uh you might only lead the headers for
2293.8,4.44,some reason or you might only need the
2295.42,5.46,response code right the status code or
2298.24,6.24,content lag so
2300.88,6.3,this is the way such that the app the
2304.48,4.619,client will consume what it needs and
2307.18,4.86,when it actually is the content to the
2309.099,7.26,body it will do Json or dot text to
2312.04,6.36,actually move it from binary down to the
2316.359,3.901,deserialization down to the data
2318.4,5.84,structure in this case it's Json because
2320.26,3.98,compared to Json is expensive right
2324.52,5.76,now I'm assuming it's the response is
2326.92,5.699,Json in this case right and uh so so the
2330.28,5.22,decentralization is costly so if you can
2332.619,5.821,do it lazily that's even better but how
2335.5,5.28,about that if you can avoid sending data
2338.44,5.159,that you never use that's even better
2340.78,6.42,for the back end isn't it right so yeah
2343.599,5.821,guys that's that's all what I have for
2347.2,6.06,you today right
2349.42,6.3,so we talked about Hawaii select star is
2353.26,4.26,really slow really really really slow I
2355.72,4.2,might have missed a reason or not let me
2357.52,4.319,know in the those comments down below
2359.92,3.24,hope you enjoyed this video I'm gonna
2361.839,3.801,see you on the next one you guys stay
2363.16,2.48,awesome goodbye
