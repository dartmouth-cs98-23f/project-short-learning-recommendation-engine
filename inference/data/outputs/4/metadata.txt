Model: mistralai/Mistral-7B-Instruct-v0.1
Time: 1708478861.09081
Videos: [['https://www.youtube.com/watch?v=UiX8K-xBUpE', 'UiX8K-xBUpE', 'mixtral8x7b'], ['https://www.youtube.com/watch?v=Xdhe-meS30A', 'Xdhe-meS30A', 'catan'], ['https://www.youtube.com/watch?v=00AQjBDM46Q', '00AQjBDM46Q', 'mlops_llm_eval'], ['https://www.youtube.com/watch?v=5ChkQKUzDCs', '5ChkQKUzDCs', 'typescript_fireship'], ['https://www.youtube.com/watch?v=J0NuOlA2xDc', 'J0NuOlA2xDc', 'localized_deployment'], ['https://www.youtube.com/watch?v=E5kzAbD8D0w', 'E5kzAbD8D0w', 'dpo'], ['https://www.youtube.com/watch?v=wybjsKtA9hI', 'wybjsKtA9hI', 'sql_backend'], ['https://www.youtube.com/watch?v=CZw57SIwgiE', 'CZw57SIwgiE', 'threads_connections'], ['https://www.youtube.com/watch?v=p6wwj0ozifw', 'p6wwj0ozifw', 'hashing'], ['https://www.youtube.com/watch?v=kxT8-C1 vmd4', 'kxT8-C1vmd4', 'zig'], ['https://www.youtube.com/watch?v=5C_HPTJg5ek', '5C_HPTJg5ek', 'rust'], ['https://www.youtube.com/watch?v=HyWYpM_S-2c', 'HyWYpM_S-2c', 'react'], ['https://www.youtube.com/watch?v=MnpuK0MK4yo', 'MnpuK0MK4yo', 'react_svelte'], ['https://www.youtube.com/watch?v=lauywdXKEXI', 'lauywdXKEXI', 'full-stack']]
Shots: ['mixtral8x7b', 'full-stack']
    Decoding took: 35.204 seconds
    cuda memory allocated: 14.00 GB, cuda memory cached: 14.36 GB
    Decoding took: 37.513 seconds
    cuda memory allocated: 14.00 GB, cuda memory cached: 14.36 GB
    Decoding took: 54.44 seconds
    cuda memory allocated: 14.00 GB, cuda memory cached: 14.36 GB
Processing: catan
Processing: catan
    Tokens: 7774
    Decoding took: 68.018 seconds
    Messages: [{'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hello guys welcome back to my channel today we are going to talk about mistral so as you know mistral is a new language model that came out a few months ago from mistal ai which is a one of the hottest startup right now in europe for language models it also became a unicorn recently and we will exploring both the models they released one is the 7 billion and one is the 8 by7 billion model so lets review the topics of today the first thing i will introduce you is the architectural differences between the vanilla transformer and the architecture of mistal later we will see what is the sliding window attention and how it is related to the concept of receptive field a concept that usually we find in convolutional neural networks i will briefly review the kv cache because i want to introduce the concept of rolling buffer cache and also how it is done with prefilling and chunking uh we will see what is sparse mixture of experts model sharding with a little with a very brief introduction with the pipeline parallelism and last but not least we will also go through the code of mistal because there is a lot of innovations in the code especially when they use the x forers library with the block attention so i want to guide you into understanding the code because it can be really hard for beginners to understand and find thems around there are some topics that are related to mistal but will not be covered in this current video because i already covered them in my previous video about llama and in particular i will not be talking about the rms normalization the rotary positional encoding and the group query attention because i already um teach them in depth in my previous video on llama so if you want to know about them please watch my previous video on llama another the only prerequisite that i hope you have before watching this video because the topics we are going to touch are quite advanced is that you are familiar with the transformer model so if youre not familiar with the transformer model and the attention mechanism in particular and in particular the self attention mechanism please go watch my video on the transformer in which i teach all this concept very thoroughly very in detail these are really a prerequisite for watching this video because the top the topics here are quite advanced okay lets proceed further so lets watch the differences between the vanilla transformer and mistal at the architecture level as you can see from the um image here which i built by myself using the code because they didnt release any architecture picture in the paper u the architecture of mistal first of all lets talk about some terminology when you have a model like this made up of many encoder layers plus linear and the soft max we are talking about a decoder only model because this part this model here looks like the decoder of the vanilla transformer you can see here except for the cross attention because as you can see here there is no cross attention when we have a model without the linear and the softmax we call it an incoder only model for example bir is an encoder only model because birth has some heads at at the end which is one or more linear layers depending on the application but it self birth doesnt need a head because it can be used for multiple downstream tasks so its called an encoder only model because it resembles the encoder side of the transformer because as you can see in the encoder side there is no linear and soft max so mistal is a decoder only model and its very similar if not equal to llama the differences between llama and mistal are highlighted here in red the first difference between llama and mistal is that in the self attention we use the sliding window attention and we still use the group query attention but and also the kv cache for inferencing but this is a rolling buffer kv cache and its actually related to the fact that we are using sliding window attention so later we will see all these concepts and the another difference is that the feed forward layer here instead of using the reu function that we used in um in the vanilla transformer or the zigo function that we us in lama here in mistal we use the ceu function um and the feed forward is one in case of mistal 7b so the first model they released and its it can be eight feed forwards uh networks in parallel with each other which are the experts of this mixture of expert in the case of mral 8x 7b um we will see later how it works so for now you just need to understand that mistal is made up of okay the input which are converted into embeddings then we have this block which is repeated n times and we will see that in the case of mistal is repeated 32 times one after another such that the output of each layer is fed to the next layer as input and the output of the last layer is then sent to this rms norm to the linear and to the softmax to produce the output of the model and um this is exactly the same as what we do with any other transformer model usually we have many of this blocks here now in the code of mistal this part here is known as transformer block but its also known as encoder block or decoder block depending on the in the contents of this um block here i will refer to it as an encoder block because if you look at it it looks like exactly as the block of the encoder side so it has a multi header tension od and norm a feed forward and other norm the only difference is that the normalization here comes before the uh the the bl of the feit forward and the self attention okay lets move forward now lets compare the the two models so one is mistal 7b and one in mistal 8x 7b the parameter dim indicates the dimension of the this the dimensions of the embedding vector so how big is the embedding vector so each token is represented by an embedding vector of size 496 dimensions we have 32 of the encoder layers so this block here is repeated 32 times the head dimension indicates as you remember in the multiad attention we have um each head is watching the entire sentence but only a part of the embedding of each token and this indicates how much how many dimensions each head will attend to in each um for in the multiad attention and the hidden dimension here indicates the hidden dimension of the feed forward layer so if the in the case of the fit forward layer we have two linear layers one that converts the the dimension of the embedding vector into the hidden size then another one that converts the hidden size back into the embedding vector dimensions so in the case of the mistal they are using as a hidden size 14336 usually this is a multiple of the dimension and it looks like its 35 the dimension here the number of heads of attention for the query is 32 two while the number of heads for the k and v so the key and values is eight and they are not equal because of the grouped query attention so if you remember from my previous video on lama in which we talk about the group query attention um in the very sim'}, {'role': 'assistant', 'content': '{\n  "introduction": "This video provides an in-depth analysis and tutorial on Mistral, a new language model developed by Mistral AI, a leading European startup in the language model space. The presenter delves into the architectural nuances of Mistral compared to traditional transformers, explores advanced concepts like sliding window attention, the use of a rolling buffer KV cache, sparse mixture of experts model, and the intricacies of coding with the Xformers library for block attention.",\n  "sections": [\n    {\n      "title": "Section 1: Architectural Overview",\n      "content": [\n        "Comparison between Mistral and vanilla transformer models.",\n        "Introduction to decoder-only models and their relevance to Mistral.",\n        "Key architectural differences highlighted, including attention mechanisms and feedforward layers.",\n        "Exploration of the sliding window attention mechanism."\n      ],\n      "topics": ["Transformer Architecture", "Decoder Models", "Sliding Window Attention"]\n    },\n    {\n      "title": "Section 2: Advanced Attention Mechanisms",\n      "content": [\n        "Deep dive into sliding window attention and its computational benefits.",\n        "Discussion on the concept of receptive fields and their analogy in CNNs.",\n        "Introduction to rolling buffer KV cache for efficient memory usage.",\n        "Explanation of chunking and pre-filling techniques for optimized processing."\n      ],\n      "topics": ["Sliding Window Attention", "Receptive Fields", "KV Cache"]\n    },\n    {\n      "title": "Section 3: Sparse Mixture of Experts",\n      "content": [\n        "Introduction to the concept of sparse mixture of experts and its implementation in Mistral.",\n        "Discussion on model sharding and pipeline parallelism for scaling models.",\n        "The significance of selecting experts based on token processing.",\n        "Efficiency gains from using sparse models in terms of computation and specialization."\n      ],\n      "topics": ["Sparse Mixture of Experts", "Model Sharding", "Pipeline Parallelism"]\n    },\n    {\n      "title": "Section 4: Code Innovations",\n      "content": [\n        "Overview of code-level innovations in Mistral, focusing on the Xformers library.",\n        "Explanation of block attention techniques for handling variable-length prompts.",\n        "Strategies for managing KV caches and attention masks in code.",\n        "Insights into the development challenges and solutions for optimizing language model inference."\n      ],\n      "topics": ["Xformers Library", "Block Attention", "Code Optimization"]\n    },\n    {\n      "title": "Section 5: Practical Applications and Coding Tutorial",\n      "content": [\n        "Step-by-step coding tutorial for implementing Mistral features.",\n        "Examples of practical applications and the benefits of Mistral\'s architecture.",\n        "Discussion on the importance of understanding transformer models as a prerequisite.",\n        "Guidance on navigating and understanding the Mistral codebase for developers."\n      ],\n      "topics": ["Coding Tutorial", "Practical Applications", "Understanding Transformers"]\n    }\n  ],\n  "topics": ["Transformer Architecture", "Sliding Window Attention", "Sparse Mixture of Experts", "Code Optimization", "Practical Applications"],\n  "General Topics": [\n    {"topic": "Artificial Intelligence (AI) and Machine Learning", "complexity": 0.89},\n    {"topic": "Software Engineering and System Design", "complexity": 0.75},\n    {"topic": "Programming Languages and Software Development", "complexity": 0.66}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.whats up guys back today with another longer video which is to build a job board app that could actually be a real startup that people use theres a lot of different places to find entry level or junior developer jobs on the internet for example github jobs stack overflow jobs you have angel list you have indeed but filtering through those especially because you kind of have to spam applications for your first job can take a long time so the good thing about all these job boards is they have public apis for the most part you always want to start with an mvp that is the minimum viable product today that means were going to start with a single data feed that is a single job board api feeding into our app and then finally were gonna have a super minimal simple front end were gonna do this in react and material ui on the front end were gonna use an express server redis for our data storage because were not writing or persisting any data that is not part of the job feed and then finally a node cron job to fetch these jobs and refresh them at a certain interval which are going to be filtered through an algorithm so lets draw this all out to get a better idea of our plan heres our front end what we basically want here is a list of jobs this is going to be pulling data from our api and that will be express and then this will pull from our store which is actually going to be redis and redis will be populated by our cron called a worker which is pulling from music one or more apis its going to be eventually multiple this is going to be job uh board apis so like in lets say indeed we have github we have stack jobs and this is going to be filtered through our algorithm were filtering down the jobs getting rid of the senior jobs getting rid of the manager jobs and eventually when we make it more complicated we could even look through the description for years of experience and create uh search indexes and different things like that but again the minimum is just going to be pulling the jobs in and filtering them down okay so this is our plan lets start with the front end i know a lot of you guys like react and its gonna actually be super simple lets just do a create react app to get started uh i already have a folder our directory here called junior dev so lets uh do a create react app and then call it client you guys know that i love material ui so lets install that as well once we get into our client and lets do yarn add okay thats done and we will start our react at okay lets go through the stuff we can actually delete no tests you always want to write tests in real life but not today logo and also clear this out here now lets open the material ui docs lets get our component api and lets get a title for our page typography h1 lets just copy this and instead of putting it directly in app lets make a new component for jobs and then lets make a new component for a single job all job which well use in jobs and then lets import react exports default functions okay in this we will use typography okay so just to explain what im doing here i am making a separate component because i want our app just to hold our state and then jobs will actually hold our component tree our render styling and app will hold our application state our use state and call our hooks for kubota did mount and for state that was really confusing sorry were using typography here and lets do variant typography variant okay im naming our page entry level software jobs i think its a good name then save import jobs throw that in there like this okay that is some huge text but were gonna leave it for now within jobs we already know were gonna um import job make this a similar export well just copy this whole thing almost sneezed okay turn div and then this will just be a single job row which will put on a class name of a single job and then well just do this in advance because we know were going to eventually have to write some css to style this stuff lets make a job list should probably actually be matching our component name just to change that back jobs and then job okay so lets just say that were passing down some props for all our jobs from our uh app which is holding our state lets just do it like this and lets do some mock json that we might return from our api swe software engineer one and company google um theres gonna be a bunch of fields but lets just leave them like that for now and my mock job so we dont get it mixed up mock just being mock json data and it should work then we can do jobs map job this will return a job job job equals job hopefully thats not too confusing okay now you could just hear the structure job in the box but jobtitle lets see if this works there it is jobtitle and jobcompany and lets actually add some css for job and just make it a display flex next direction oh thats right its always freaking hard switching from jsx to javascript okay there we go boom ill leave it like that for now we can add more stuff to this this list if we want like this facebook apple itll map it out for us lets give that a little bit of margin a little bit of padding lets do a 10 pixel top left right zero and then padding will be the same okay not too bad not too bad so our front end we could call this like kind of done lets call this done for now and lets return to it after doing some full stack stuff so im gonna collapse our client lets see what our actual data feed is gonna look like coming from uh our source which im just gonna use as github jobs because i know that has a really good clean api output that you dont need a key for or anything so api github jobs open it up you can see some examples here okay so it says that the api supports pagination itll return 50 at a time and you could do it by adding a parameter to your queries before jumping ahead we just know we want these json representation of these jobs so we can manipulate it with our node worker so what im actually going to do is call a similar url like this in our node side which is going to give us output like this just by eyeballing this i could see that it is somewhat matching what we already wrote out here in appjs where theres a title somewhere yes like that senior full stack nodejs developer and there is a company somewhere and we can also tell in advance that locations going to be an important field too but basing our analysis on this we could start to model kind of what our worker is going to do as well as how we want our api to act as well so looking back at our plan lets actually just make a folder for uh all our boxes here so this is the client right api is going to be simplexpress server and then the worker is going to have our algorithm and its going to be calling our apis on a cron job which is at a set interval so maybe every hour in the day we want to refresh these apis refresh our redis and make sure that everything is up to date theres no expired jobs that the companies dont want people to see anymore and were basically staying i'}, {'role': 'assistant', 'content': '{\n  "introduction": "The video tutorial demonstrates the process of building a job board app from scratch, intended to serve as a real startup platform for entry-level or junior developer positions. It covers the app\'s development from conceptualization to deployment, utilizing various technologies and programming languages.",\n  "sections": [\n    {\n      "title": "Section 1: Project Initialization and MVP",\n      "content": [\n        "Introduction to the project\'s goal of simplifying the job search for entry-level developer positions.",\n        "Decision to start with a single data feed using a job board API.",\n        "Explanation of the Minimum Viable Product (MVP) concept.",\n        "Initial setup of the project using React for the frontend and Express server."\n      ],\n      "topics": ["MVP Concept", "API Integration", "React"]\n    },\n    {\n      "title": "Section 2: Backend Development",\n      "content": [\n        "Setup of the Express server and Redis for data storage.",\n        "Implementation of a Node cron job to fetch and refresh job listings.",\n        "Discussion on filtering algorithms to refine job search results.",\n        "Detailed walkthrough of backend code, including async functions and API fetching."\n      ],\n      "topics": ["Express Server", "Redis", "Node Cron Job"]\n    },\n    {\n      "title": "Section 3: Frontend Development",\n      "content": [\n        "Initial setup of React components for job listings.",\n        "Introduction to Material UI for styling the frontend.",\n        "Development of a simple, user-friendly interface.",\n        "Incorporation of job filtering and pagination on the frontend."\n      ],\n      "topics": ["React Components", "Material UI", "Pagination"]\n    },\n    {\n      "title": "Section 4: Data Filtering and Algorithm",\n      "content": [\n        "Explanation of the algorithm to filter out non-entry level jobs.",\n        "Use of string methods to identify relevant job listings.",\n        "Adjustments to the algorithm for improved accuracy.",\n        "Testing and refining the filtering process."\n      ],\n      "topics": ["Filtering Algorithm", "String Methods", "Algorithm Testing"]\n    },\n    {\n      "title": "Section 5: Deployment",\n      "content": [\n        "Overview of deployment process on a virtual private server.",\n        "Configuration of Nginx and security with SSL certificates.",\n        "Final adjustments for production readiness.",\n        "Live deployment and testing of the job board app."\n      ],\n      "topics": ["Deployment", "Nginx Configuration", "SSL Certificates"]\n    }\n  ],\n  "topics": ["React", "Express Server", "Redis", "Filtering Algorithm", "Deployment"],\n  "General Topics": [\n    {"topic": "Web Development and Internet Technologies", "complexity": 0.45},\n    {"topic": "Software Engineering and System Design", "complexity": 0.65},\n    {"topic": "Data Science and Analytics", "complexity": 0.55}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.music whats going on danny crew its danny drew here and we are back for another day of kadan in todays lesson video we are going to be talking about the placement traps that kill your game before it even starts i have seen too many new and beginning players play the game of katon make subtle placement decisions that absolutely eviscerate your chances of winning what were going to do is were going to break down these traps were to go through each one with a little bit of nuance and hopefully by the end of this video you will be placing better and winning more games if youre ready lets get into it get excited cuz i certainly am i want to make a quick statement here before we get into the examples which is that not every trap is necessarily a trap its more important to realize that certain situations have certain nuances and its important for you to read the board use the previous lesson videos we talked about placements and placing out and to be able to make a good read if this is going to be a trap or not as an example well walk through some of these key traps placing next to a starting road this is a very common mistake where a lot of players dont see that a player on the way back and start with a road and then drop a road onto their road and they lose the spot theyre going to so the plow we i think weve all been there weve all seen it how about starting with inflexible to resource setups a lot of players love to go for like a double or sheep theres some issues with that which is that it offers potentially some inflexibility again you have to back all these decisions up with good calculation placing with inflexible ports maybe you have a ton of wood and you dont have a way to use it effectively thats a problem how about building on only one potential road subtle well show some examples of that and the last one which you know you have to make a judgment call but placing on setups that might get over blocked op setups you know that 659 or we cheap probably worth taking in most cases but you have to know the dynamic of the board and know if youre going to get outpaced by the rest of the board so lets get into an example here im super excited i hope you are too why dont we sit down for a second pause the board if you need to do some calculations and i would recommend you place this board out as much as you can see if you can pick first second third fourth all the way through to all eight placements and then when youre done with that unpause the video and well talk about how this game actually occurred hopefully you did that so here you go the first placement on this board was 6510 and the whole idea is they want to go 6510 to 810 why is this a placement trap well theres a few reasons if you look at the makeup of this board the first thing is that 6510 is nice on the surface but youre only going to one subtle spot which is the 810 that would be okay but the issue here in first is its not guaranteed youre going to get the 810 if you look at the wheat on this board the eight is the best wheat so you know it has value with all this ore thats on this board but also the 810 is a fantastic spot potentially for like the five9 10 player so i think if black was just being a little bit more critical about their calculations they would see 6510 is probably losing the 810 in most cases and this makes it a very bad pick so first trap be careful make sure you back up your placement decision with good calculation second picks the 5910 now kind of playing off of what we saw in the previous slide the 5910 obviously can take the 810 but youre going to see that there are some clear problems with this one of the issues i have with the 5910 point left is that its too inflexible pointing left to a brick port makes no sense much better in this situation is the point up now it is true that the 5910 left gives you two settles but frankly youre probably not beating the 1083 at the bottom here to the brick port so effectively you have one settle on the five so much better is if you point up here then you get the road subtle onto the 52 but you also get the 31 which plays much better with the setup than simply playing off the brck port so be very careful about taking inflexible setups in second third takes the 643 here at the top you can see that makes a lot of sense now the question for you is what do you do in fourth i want you to pause the video and place it out take as much time as you need but make sure you do the exercise and come back id be very curious in the comments can you tell me what you picked here for fourth id be very very curious type it in now uh that way you dont see the answer give you a second 5 4 3 2 1 all right so this is what fourth decided to pick the 942 and the 8103 now clearly reds intention here was that they wanted to go for ows they want to go 52 get the pork get the or but whats the issue with this well i think a lot of things are going to be clear when you understand the forcing sequence and i believe that this sequence is absolutely forced because if you do your calculations again everything needs to be placed out with calculations and consideration then this is what happen on the way back this player here takes the 853 because they do not want to ever give that spot to the 5109 but then you ask where does the 5109 go well we talked about this earlier theyre going to go in the 810 all of this has been forced given reds placements so then black has to take the space it makes sense they have the wood and the brick they take the 5411 now they should have pointed left because road settling on the 9 through1 is much better than pointing right but i want you to see out of all that entire situation we could have calculated purple settle we could have calculated a white settle and we could have seen whats going to happen now the big issue for red is that hes playing ows when you have two other ows players and hes way too slow he needs to road settle 52 he needs to be buying development cards while trying to build a city and trying to compete against two people who are literally all o ws its not going to happen and the final result of this game is essentially that red took road here so theyre theyre sitting here with eight points theyre essentially six points with longest road and then they need to manufacture two more points while not losing road to black ultimately what happened was that purple here just absolutely cooked dropped four cities vp just built a tent uh didnt even need armor which is crazy that blacket army here but you can see the inflexibility of these setups really became problematic red i think went for the wrong plan on the wrong board and it cost him the game so knowing this what would you do here what you do here and forth i want you to revisit the fact and maybe if you pick that setup thats perfectly fine the 492 8103 but how can we essentially change our thought here we know ows is not the way buying development cards is going to be too heavily conteste'}]
    cuda memory allocated: 15.54 GB, cuda memory cached: 16.37 GB
Processing: hashing
    Tokens: 7633
    Decoding took: 54.174 seconds
    Messages: [{'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hello guys welcome back to my channel today we are going to talk about mistral so as you know mistral is a new language model that came out a few months ago from mistal ai which is a one of the hottest startup right now in europe for language models it also became a unicorn recently and we will exploring both the models they released one is the 7 billion and one is the 8 by7 billion model so lets review the topics of today the first thing i will introduce you is the architectural differences between the vanilla transformer and the architecture of mistal later we will see what is the sliding window attention and how it is related to the concept of receptive field a concept that usually we find in convolutional neural networks i will briefly review the kv cache because i want to introduce the concept of rolling buffer cache and also how it is done with prefilling and chunking uh we will see what is sparse mixture of experts model sharding with a little with a very brief introduction with the pipeline parallelism and last but not least we will also go through the code of mistal because there is a lot of innovations in the code especially when they use the x forers library with the block attention so i want to guide you into understanding the code because it can be really hard for beginners to understand and find thems around there are some topics that are related to mistal but will not be covered in this current video because i already covered them in my previous video about llama and in particular i will not be talking about the rms normalization the rotary positional encoding and the group query attention because i already um teach them in depth in my previous video on llama so if you want to know about them please watch my previous video on llama another the only prerequisite that i hope you have before watching this video because the topics we are going to touch are quite advanced is that you are familiar with the transformer model so if youre not familiar with the transformer model and the attention mechanism in particular and in particular the self attention mechanism please go watch my video on the transformer in which i teach all this concept very thoroughly very in detail these are really a prerequisite for watching this video because the top the topics here are quite advanced okay lets proceed further so lets watch the differences between the vanilla transformer and mistal at the architecture level as you can see from the um image here which i built by myself using the code because they didnt release any architecture picture in the paper u the architecture of mistal first of all lets talk about some terminology when you have a model like this made up of many encoder layers plus linear and the soft max we are talking about a decoder only model because this part this model here looks like the decoder of the vanilla transformer you can see here except for the cross attention because as you can see here there is no cross attention when we have a model without the linear and the softmax we call it an incoder only model for example bir is an encoder only model because birth has some heads at at the end which is one or more linear layers depending on the application but it self birth doesnt need a head because it can be used for multiple downstream tasks so its called an encoder only model because it resembles the encoder side of the transformer because as you can see in the encoder side there is no linear and soft max so mistal is a decoder only model and its very similar if not equal to llama the differences between llama and mistal are highlighted here in red the first difference between llama and mistal is that in the self attention we use the sliding window attention and we still use the group query attention but and also the kv cache for inferencing but this is a rolling buffer kv cache and its actually related to the fact that we are using sliding window attention so later we will see all these concepts and the another difference is that the feed forward layer here instead of using the reu function that we used in um in the vanilla transformer or the zigo function that we us in lama here in mistal we use the ceu function um and the feed forward is one in case of mistal 7b so the first model they released and its it can be eight feed forwards uh networks in parallel with each other which are the experts of this mixture of expert in the case of mral 8x 7b um we will see later how it works so for now you just need to understand that mistal is made up of okay the input which are converted into embeddings then we have this block which is repeated n times and we will see that in the case of mistal is repeated 32 times one after another such that the output of each layer is fed to the next layer as input and the output of the last layer is then sent to this rms norm to the linear and to the softmax to produce the output of the model and um this is exactly the same as what we do with any other transformer model usually we have many of this blocks here now in the code of mistal this part here is known as transformer block but its also known as encoder block or decoder block depending on the in the contents of this um block here i will refer to it as an encoder block because if you look at it it looks like exactly as the block of the encoder side so it has a multi header tension od and norm a feed forward and other norm the only difference is that the normalization here comes before the uh the the bl of the feit forward and the self attention okay lets move forward now lets compare the the two models so one is mistal 7b and one in mistal 8x 7b the parameter dim indicates the dimension of the this the dimensions of the embedding vector so how big is the embedding vector so each token is represented by an embedding vector of size 496 dimensions we have 32 of the encoder layers so this block here is repeated 32 times the head dimension indicates as you remember in the multiad attention we have um each head is watching the entire sentence but only a part of the embedding of each token and this indicates how much how many dimensions each head will attend to in each um for in the multiad attention and the hidden dimension here indicates the hidden dimension of the feed forward layer so if the in the case of the fit forward layer we have two linear layers one that converts the the dimension of the embedding vector into the hidden size then another one that converts the hidden size back into the embedding vector dimensions so in the case of the mistal they are using as a hidden size 14336 usually this is a multiple of the dimension and it looks like its 35 the dimension here the number of heads of attention for the query is 32 two while the number of heads for the k and v so the key and values is eight and they are not equal because of the grouped query attention so if you remember from my previous video on lama in which we talk about the group query attention um in the very sim'}, {'role': 'assistant', 'content': '{\n  "introduction": "This video provides an in-depth analysis and tutorial on Mistral, a new language model developed by Mistral AI, a leading European startup in the language model space. The presenter delves into the architectural nuances of Mistral compared to traditional transformers, explores advanced concepts like sliding window attention, the use of a rolling buffer KV cache, sparse mixture of experts model, and the intricacies of coding with the Xformers library for block attention.",\n  "sections": [\n    {\n      "title": "Section 1: Architectural Overview",\n      "content": [\n        "Comparison between Mistral and vanilla transformer models.",\n        "Introduction to decoder-only models and their relevance to Mistral.",\n        "Key architectural differences highlighted, including attention mechanisms and feedforward layers.",\n        "Exploration of the sliding window attention mechanism."\n      ],\n      "topics": ["Transformer Architecture", "Decoder Models", "Sliding Window Attention"]\n    },\n    {\n      "title": "Section 2: Advanced Attention Mechanisms",\n      "content": [\n        "Deep dive into sliding window attention and its computational benefits.",\n        "Discussion on the concept of receptive fields and their analogy in CNNs.",\n        "Introduction to rolling buffer KV cache for efficient memory usage.",\n        "Explanation of chunking and pre-filling techniques for optimized processing."\n      ],\n      "topics": ["Sliding Window Attention", "Receptive Fields", "KV Cache"]\n    },\n    {\n      "title": "Section 3: Sparse Mixture of Experts",\n      "content": [\n        "Introduction to the concept of sparse mixture of experts and its implementation in Mistral.",\n        "Discussion on model sharding and pipeline parallelism for scaling models.",\n        "The significance of selecting experts based on token processing.",\n        "Efficiency gains from using sparse models in terms of computation and specialization."\n      ],\n      "topics": ["Sparse Mixture of Experts", "Model Sharding", "Pipeline Parallelism"]\n    },\n    {\n      "title": "Section 4: Code Innovations",\n      "content": [\n        "Overview of code-level innovations in Mistral, focusing on the Xformers library.",\n        "Explanation of block attention techniques for handling variable-length prompts.",\n        "Strategies for managing KV caches and attention masks in code.",\n        "Insights into the development challenges and solutions for optimizing language model inference."\n      ],\n      "topics": ["Xformers Library", "Block Attention", "Code Optimization"]\n    },\n    {\n      "title": "Section 5: Practical Applications and Coding Tutorial",\n      "content": [\n        "Step-by-step coding tutorial for implementing Mistral features.",\n        "Examples of practical applications and the benefits of Mistral\'s architecture.",\n        "Discussion on the importance of understanding transformer models as a prerequisite.",\n        "Guidance on navigating and understanding the Mistral codebase for developers."\n      ],\n      "topics": ["Coding Tutorial", "Practical Applications", "Understanding Transformers"]\n    }\n  ],\n  "topics": ["Transformer Architecture", "Sliding Window Attention", "Sparse Mixture of Experts", "Code Optimization", "Practical Applications"],\n  "General Topics": [\n    {"topic": "Artificial Intelligence (AI) and Machine Learning", "complexity": 0.89},\n    {"topic": "Software Engineering and System Design", "complexity": 0.75},\n    {"topic": "Programming Languages and Software Development", "complexity": 0.66}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.whats up guys back today with another longer video which is to build a job board app that could actually be a real startup that people use theres a lot of different places to find entry level or junior developer jobs on the internet for example github jobs stack overflow jobs you have angel list you have indeed but filtering through those especially because you kind of have to spam applications for your first job can take a long time so the good thing about all these job boards is they have public apis for the most part you always want to start with an mvp that is the minimum viable product today that means were going to start with a single data feed that is a single job board api feeding into our app and then finally were gonna have a super minimal simple front end were gonna do this in react and material ui on the front end were gonna use an express server redis for our data storage because were not writing or persisting any data that is not part of the job feed and then finally a node cron job to fetch these jobs and refresh them at a certain interval which are going to be filtered through an algorithm so lets draw this all out to get a better idea of our plan heres our front end what we basically want here is a list of jobs this is going to be pulling data from our api and that will be express and then this will pull from our store which is actually going to be redis and redis will be populated by our cron called a worker which is pulling from music one or more apis its going to be eventually multiple this is going to be job uh board apis so like in lets say indeed we have github we have stack jobs and this is going to be filtered through our algorithm were filtering down the jobs getting rid of the senior jobs getting rid of the manager jobs and eventually when we make it more complicated we could even look through the description for years of experience and create uh search indexes and different things like that but again the minimum is just going to be pulling the jobs in and filtering them down okay so this is our plan lets start with the front end i know a lot of you guys like react and its gonna actually be super simple lets just do a create react app to get started uh i already have a folder our directory here called junior dev so lets uh do a create react app and then call it client you guys know that i love material ui so lets install that as well once we get into our client and lets do yarn add okay thats done and we will start our react at okay lets go through the stuff we can actually delete no tests you always want to write tests in real life but not today logo and also clear this out here now lets open the material ui docs lets get our component api and lets get a title for our page typography h1 lets just copy this and instead of putting it directly in app lets make a new component for jobs and then lets make a new component for a single job all job which well use in jobs and then lets import react exports default functions okay in this we will use typography okay so just to explain what im doing here i am making a separate component because i want our app just to hold our state and then jobs will actually hold our component tree our render styling and app will hold our application state our use state and call our hooks for kubota did mount and for state that was really confusing sorry were using typography here and lets do variant typography variant okay im naming our page entry level software jobs i think its a good name then save import jobs throw that in there like this okay that is some huge text but were gonna leave it for now within jobs we already know were gonna um import job make this a similar export well just copy this whole thing almost sneezed okay turn div and then this will just be a single job row which will put on a class name of a single job and then well just do this in advance because we know were going to eventually have to write some css to style this stuff lets make a job list should probably actually be matching our component name just to change that back jobs and then job okay so lets just say that were passing down some props for all our jobs from our uh app which is holding our state lets just do it like this and lets do some mock json that we might return from our api swe software engineer one and company google um theres gonna be a bunch of fields but lets just leave them like that for now and my mock job so we dont get it mixed up mock just being mock json data and it should work then we can do jobs map job this will return a job job job equals job hopefully thats not too confusing okay now you could just hear the structure job in the box but jobtitle lets see if this works there it is jobtitle and jobcompany and lets actually add some css for job and just make it a display flex next direction oh thats right its always freaking hard switching from jsx to javascript okay there we go boom ill leave it like that for now we can add more stuff to this this list if we want like this facebook apple itll map it out for us lets give that a little bit of margin a little bit of padding lets do a 10 pixel top left right zero and then padding will be the same okay not too bad not too bad so our front end we could call this like kind of done lets call this done for now and lets return to it after doing some full stack stuff so im gonna collapse our client lets see what our actual data feed is gonna look like coming from uh our source which im just gonna use as github jobs because i know that has a really good clean api output that you dont need a key for or anything so api github jobs open it up you can see some examples here okay so it says that the api supports pagination itll return 50 at a time and you could do it by adding a parameter to your queries before jumping ahead we just know we want these json representation of these jobs so we can manipulate it with our node worker so what im actually going to do is call a similar url like this in our node side which is going to give us output like this just by eyeballing this i could see that it is somewhat matching what we already wrote out here in appjs where theres a title somewhere yes like that senior full stack nodejs developer and there is a company somewhere and we can also tell in advance that locations going to be an important field too but basing our analysis on this we could start to model kind of what our worker is going to do as well as how we want our api to act as well so looking back at our plan lets actually just make a folder for uh all our boxes here so this is the client right api is going to be simplexpress server and then the worker is going to have our algorithm and its going to be calling our apis on a cron job which is at a set interval so maybe every hour in the day we want to refresh these apis refresh our redis and make sure that everything is up to date theres no expired jobs that the companies dont want people to see anymore and were basically staying i'}, {'role': 'assistant', 'content': '{\n  "introduction": "The video tutorial demonstrates the process of building a job board app from scratch, intended to serve as a real startup platform for entry-level or junior developer positions. It covers the app\'s development from conceptualization to deployment, utilizing various technologies and programming languages.",\n  "sections": [\n    {\n      "title": "Section 1: Project Initialization and MVP",\n      "content": [\n        "Introduction to the project\'s goal of simplifying the job search for entry-level developer positions.",\n        "Decision to start with a single data feed using a job board API.",\n        "Explanation of the Minimum Viable Product (MVP) concept.",\n        "Initial setup of the project using React for the frontend and Express server."\n      ],\n      "topics": ["MVP Concept", "API Integration", "React"]\n    },\n    {\n      "title": "Section 2: Backend Development",\n      "content": [\n        "Setup of the Express server and Redis for data storage.",\n        "Implementation of a Node cron job to fetch and refresh job listings.",\n        "Discussion on filtering algorithms to refine job search results.",\n        "Detailed walkthrough of backend code, including async functions and API fetching."\n      ],\n      "topics": ["Express Server", "Redis", "Node Cron Job"]\n    },\n    {\n      "title": "Section 3: Frontend Development",\n      "content": [\n        "Initial setup of React components for job listings.",\n        "Introduction to Material UI for styling the frontend.",\n        "Development of a simple, user-friendly interface.",\n        "Incorporation of job filtering and pagination on the frontend."\n      ],\n      "topics": ["React Components", "Material UI", "Pagination"]\n    },\n    {\n      "title": "Section 4: Data Filtering and Algorithm",\n      "content": [\n        "Explanation of the algorithm to filter out non-entry level jobs.",\n        "Use of string methods to identify relevant job listings.",\n        "Adjustments to the algorithm for improved accuracy.",\n        "Testing and refining the filtering process."\n      ],\n      "topics": ["Filtering Algorithm", "String Methods", "Algorithm Testing"]\n    },\n    {\n      "title": "Section 5: Deployment",\n      "content": [\n        "Overview of deployment process on a virtual private server.",\n        "Configuration of Nginx and security with SSL certificates.",\n        "Final adjustments for production readiness.",\n        "Live deployment and testing of the job board app."\n      ],\n      "topics": ["Deployment", "Nginx Configuration", "SSL Certificates"]\n    }\n  ],\n  "topics": ["React", "Express Server", "Redis", "Filtering Algorithm", "Deployment"],\n  "General Topics": [\n    {"topic": "Web Development and Internet Technologies", "complexity": 0.45},\n    {"topic": "Software Engineering and System Design", "complexity": 0.65},\n    {"topic": "Data Science and Analytics", "complexity": 0.55}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.in a previous episode of the vacuum engineering show i talked about hash tables and how uh powerful and very commonly used they are given a key we can find its corresponding value in no time in zero seek time were not searching were not scanning were not doing anything its a single axis in memory retrieving that value the power behind hash tables is the use of the arrays which is a very common data structure obviously very very common data structure right knowing the array position the the index you can get the value of the array immediately because you know how how does memory work if you know the address of the ram where your cell exists where your values exist you can get the value immediately right the cpu can fetch the value immediately for you right so once you find the index you find the address you can value so what the hash table guys did it says okay were gonna take your name your string your color your car your va anything that has been this key were going to hash it using a oneway function and then convert that into an index using a modulo function based on the array size so we eventually from the name we convert and continue an index and that will give us the address and the memory and we can get the value so thats the trick the hash table guys use you know so the only cost you add is like what the hashing function which is not really that bad but thats the power of the hash table but the problem is the moment the size of the array changes the hash table size changes this all forms apart because what what the if blue the key blue used to fit in index number 11 if you increased or decreased the array size and i you know where im going with this then the blue will fit into index 99 now and as a result right you either wont find the value or youre gonna start writing the values duplicate and everything will basically be bad so you now have to really move things around your resize and its a really big problem so why im mentioning that the problem that we are seeing today with distributive system is as follows if my database are increasing in size and it no longer can fit in a single instance i i bumped up the vertical scaling to its maximum its now 48 core cpu three gigahertz whatever you know its 512 gigabyte or even one terabyte ram but still i have billions of rows i cannot i added all the indexes i try to partition it horizontally in the same instance by range so but still the even the partitions are so large so i that machine cannot handle the queries um throwing at my beautiful database so what do we do we distribute it we shard the database thats i really dont like to go there unless i kind of exhaust all my options and believe me people dont even look at the options anymore people are very quick to follow modern things you know without actually going to the basics and trying to tune your database and getting a better performance but regardless lets assume youre a youtube scale lets give you a google scale and you run out ideas that single instance cant handle anymore you need to distribute the billions of rows table or key dictionary or collection into multiple servers right so instead of having billions lets have i know a few millions on this server and few millions on this server a few millions on the server female in the server immediately a problem occur the problem is like how do i know right if i have a key i want to look it up we introduced an intermediately an intermediary problem right that didnt exist before well first if i have a key i go to my database server and i ask it and i immediately give it to me i only go to one hop now if youre distributed and you only have the key you have to answer the first question which server should i connect to to retrieve the key which server hosts my key and that is the problem here that is the original and only problem that we have in distributed system which server should i connect to to fetch that key so the trick was always lets figure out the server from the key and that is the concept of hashing hashing tables appear here so in this episode of the vacancy show id like to talk about that a little bit distributed hashing and then what problems did we have and how consistent hashing solves this problem and obviously nothing is perfect in this world so id also like like to talk about the problems consisting hashing actually have today welcome to the backend engineering show with your host hussein nelson and the concept of distributed system is a must when you get to a certain scale yeah i always try as much as possible to you know push people against being distributed if they can do things to have their single instance you know be more performant when it comes to query because you see a lot of a lot of people our engineers are hurry up to scale right and spend more money to start to work with the distributor without actually while their query is actually using 500 of their cpu and then doing like a million logical reads you know where they can tweak it a little bit and tweak it and tune the database a little bit understand their queries so they can have or even you know lower that cost you know as a result but we dont think this way anymore we always take the shortcut unfortunately but regardless so usually advanced and adept dpas try to optimize a single coin as a result if you if you can get a query to consume less cpu even if its a small query scaling that query right will eventually give you better scaling on your instance but thats not our topic thats another day but lets say you reached the state where you exhausted all your options you know when it comes to a single instance right then you moved he says hey i have to move to and uh distribute the system its just too large you gotta move so people what they did says okay i have a key and now i dont know which i have 10 servers right i dont know where this key lives in distant server environment so ill say all right so were going to do lets say i have four server a cluster with four servers and i want to distribute my values across these four servers so server s0 s1 s2 and s3 right what were gonna do is like giving the key i need to know the server name the server ip and thats something that we are introducing as a problem like we introduced a friction that didnt exist before first previously so i just one server we know the server right but now we have to figure out from the key we have to figure out the iprs of the server to connect to in order where our key actually exists that answer can be answered using a very simple hashing function so were going to hash the value lets say im have value number four uh gonna hash it get some value and then that value were gonna do modulo number four and that gives you server zero so store server zero right here right in this case right so four modulo four is zero and then okay how about key number five right or even whatever that key used to be maybe lets say its a its a blue or red right red youre gonna hash'}]
    cuda memory allocated: 15.54 GB, cuda memory cached: 16.37 GB
Processing: localized_deployment
    Tokens: 6951
    Decoding took: 10.206 seconds
    Messages: [{'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hello guys welcome back to my channel today we are going to talk about mistral so as you know mistral is a new language model that came out a few months ago from mistal ai which is a one of the hottest startup right now in europe for language models it also became a unicorn recently and we will exploring both the models they released one is the 7 billion and one is the 8 by7 billion model so lets review the topics of today the first thing i will introduce you is the architectural differences between the vanilla transformer and the architecture of mistal later we will see what is the sliding window attention and how it is related to the concept of receptive field a concept that usually we find in convolutional neural networks i will briefly review the kv cache because i want to introduce the concept of rolling buffer cache and also how it is done with prefilling and chunking uh we will see what is sparse mixture of experts model sharding with a little with a very brief introduction with the pipeline parallelism and last but not least we will also go through the code of mistal because there is a lot of innovations in the code especially when they use the x forers library with the block attention so i want to guide you into understanding the code because it can be really hard for beginners to understand and find thems around there are some topics that are related to mistal but will not be covered in this current video because i already covered them in my previous video about llama and in particular i will not be talking about the rms normalization the rotary positional encoding and the group query attention because i already um teach them in depth in my previous video on llama so if you want to know about them please watch my previous video on llama another the only prerequisite that i hope you have before watching this video because the topics we are going to touch are quite advanced is that you are familiar with the transformer model so if youre not familiar with the transformer model and the attention mechanism in particular and in particular the self attention mechanism please go watch my video on the transformer in which i teach all this concept very thoroughly very in detail these are really a prerequisite for watching this video because the top the topics here are quite advanced okay lets proceed further so lets watch the differences between the vanilla transformer and mistal at the architecture level as you can see from the um image here which i built by myself using the code because they didnt release any architecture picture in the paper u the architecture of mistal first of all lets talk about some terminology when you have a model like this made up of many encoder layers plus linear and the soft max we are talking about a decoder only model because this part this model here looks like the decoder of the vanilla transformer you can see here except for the cross attention because as you can see here there is no cross attention when we have a model without the linear and the softmax we call it an incoder only model for example bir is an encoder only model because birth has some heads at at the end which is one or more linear layers depending on the application but it self birth doesnt need a head because it can be used for multiple downstream tasks so its called an encoder only model because it resembles the encoder side of the transformer because as you can see in the encoder side there is no linear and soft max so mistal is a decoder only model and its very similar if not equal to llama the differences between llama and mistal are highlighted here in red the first difference between llama and mistal is that in the self attention we use the sliding window attention and we still use the group query attention but and also the kv cache for inferencing but this is a rolling buffer kv cache and its actually related to the fact that we are using sliding window attention so later we will see all these concepts and the another difference is that the feed forward layer here instead of using the reu function that we used in um in the vanilla transformer or the zigo function that we us in lama here in mistal we use the ceu function um and the feed forward is one in case of mistal 7b so the first model they released and its it can be eight feed forwards uh networks in parallel with each other which are the experts of this mixture of expert in the case of mral 8x 7b um we will see later how it works so for now you just need to understand that mistal is made up of okay the input which are converted into embeddings then we have this block which is repeated n times and we will see that in the case of mistal is repeated 32 times one after another such that the output of each layer is fed to the next layer as input and the output of the last layer is then sent to this rms norm to the linear and to the softmax to produce the output of the model and um this is exactly the same as what we do with any other transformer model usually we have many of this blocks here now in the code of mistal this part here is known as transformer block but its also known as encoder block or decoder block depending on the in the contents of this um block here i will refer to it as an encoder block because if you look at it it looks like exactly as the block of the encoder side so it has a multi header tension od and norm a feed forward and other norm the only difference is that the normalization here comes before the uh the the bl of the feit forward and the self attention okay lets move forward now lets compare the the two models so one is mistal 7b and one in mistal 8x 7b the parameter dim indicates the dimension of the this the dimensions of the embedding vector so how big is the embedding vector so each token is represented by an embedding vector of size 496 dimensions we have 32 of the encoder layers so this block here is repeated 32 times the head dimension indicates as you remember in the multiad attention we have um each head is watching the entire sentence but only a part of the embedding of each token and this indicates how much how many dimensions each head will attend to in each um for in the multiad attention and the hidden dimension here indicates the hidden dimension of the feed forward layer so if the in the case of the fit forward layer we have two linear layers one that converts the the dimension of the embedding vector into the hidden size then another one that converts the hidden size back into the embedding vector dimensions so in the case of the mistal they are using as a hidden size 14336 usually this is a multiple of the dimension and it looks like its 35 the dimension here the number of heads of attention for the query is 32 two while the number of heads for the k and v so the key and values is eight and they are not equal because of the grouped query attention so if you remember from my previous video on lama in which we talk about the group query attention um in the very sim'}, {'role': 'assistant', 'content': '{\n  "introduction": "This video provides an in-depth analysis and tutorial on Mistral, a new language model developed by Mistral AI, a leading European startup in the language model space. The presenter delves into the architectural nuances of Mistral compared to traditional transformers, explores advanced concepts like sliding window attention, the use of a rolling buffer KV cache, sparse mixture of experts model, and the intricacies of coding with the Xformers library for block attention.",\n  "sections": [\n    {\n      "title": "Section 1: Architectural Overview",\n      "content": [\n        "Comparison between Mistral and vanilla transformer models.",\n        "Introduction to decoder-only models and their relevance to Mistral.",\n        "Key architectural differences highlighted, including attention mechanisms and feedforward layers.",\n        "Exploration of the sliding window attention mechanism."\n      ],\n      "topics": ["Transformer Architecture", "Decoder Models", "Sliding Window Attention"]\n    },\n    {\n      "title": "Section 2: Advanced Attention Mechanisms",\n      "content": [\n        "Deep dive into sliding window attention and its computational benefits.",\n        "Discussion on the concept of receptive fields and their analogy in CNNs.",\n        "Introduction to rolling buffer KV cache for efficient memory usage.",\n        "Explanation of chunking and pre-filling techniques for optimized processing."\n      ],\n      "topics": ["Sliding Window Attention", "Receptive Fields", "KV Cache"]\n    },\n    {\n      "title": "Section 3: Sparse Mixture of Experts",\n      "content": [\n        "Introduction to the concept of sparse mixture of experts and its implementation in Mistral.",\n        "Discussion on model sharding and pipeline parallelism for scaling models.",\n        "The significance of selecting experts based on token processing.",\n        "Efficiency gains from using sparse models in terms of computation and specialization."\n      ],\n      "topics": ["Sparse Mixture of Experts", "Model Sharding", "Pipeline Parallelism"]\n    },\n    {\n      "title": "Section 4: Code Innovations",\n      "content": [\n        "Overview of code-level innovations in Mistral, focusing on the Xformers library.",\n        "Explanation of block attention techniques for handling variable-length prompts.",\n        "Strategies for managing KV caches and attention masks in code.",\n        "Insights into the development challenges and solutions for optimizing language model inference."\n      ],\n      "topics": ["Xformers Library", "Block Attention", "Code Optimization"]\n    },\n    {\n      "title": "Section 5: Practical Applications and Coding Tutorial",\n      "content": [\n        "Step-by-step coding tutorial for implementing Mistral features.",\n        "Examples of practical applications and the benefits of Mistral\'s architecture.",\n        "Discussion on the importance of understanding transformer models as a prerequisite.",\n        "Guidance on navigating and understanding the Mistral codebase for developers."\n      ],\n      "topics": ["Coding Tutorial", "Practical Applications", "Understanding Transformers"]\n    }\n  ],\n  "topics": ["Transformer Architecture", "Sliding Window Attention", "Sparse Mixture of Experts", "Code Optimization", "Practical Applications"],\n  "General Topics": [\n    {"topic": "Artificial Intelligence (AI) and Machine Learning", "complexity": 0.89},\n    {"topic": "Software Engineering and System Design", "complexity": 0.75},\n    {"topic": "Programming Languages and Software Development", "complexity": 0.66}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.whats up guys back today with another longer video which is to build a job board app that could actually be a real startup that people use theres a lot of different places to find entry level or junior developer jobs on the internet for example github jobs stack overflow jobs you have angel list you have indeed but filtering through those especially because you kind of have to spam applications for your first job can take a long time so the good thing about all these job boards is they have public apis for the most part you always want to start with an mvp that is the minimum viable product today that means were going to start with a single data feed that is a single job board api feeding into our app and then finally were gonna have a super minimal simple front end were gonna do this in react and material ui on the front end were gonna use an express server redis for our data storage because were not writing or persisting any data that is not part of the job feed and then finally a node cron job to fetch these jobs and refresh them at a certain interval which are going to be filtered through an algorithm so lets draw this all out to get a better idea of our plan heres our front end what we basically want here is a list of jobs this is going to be pulling data from our api and that will be express and then this will pull from our store which is actually going to be redis and redis will be populated by our cron called a worker which is pulling from music one or more apis its going to be eventually multiple this is going to be job uh board apis so like in lets say indeed we have github we have stack jobs and this is going to be filtered through our algorithm were filtering down the jobs getting rid of the senior jobs getting rid of the manager jobs and eventually when we make it more complicated we could even look through the description for years of experience and create uh search indexes and different things like that but again the minimum is just going to be pulling the jobs in and filtering them down okay so this is our plan lets start with the front end i know a lot of you guys like react and its gonna actually be super simple lets just do a create react app to get started uh i already have a folder our directory here called junior dev so lets uh do a create react app and then call it client you guys know that i love material ui so lets install that as well once we get into our client and lets do yarn add okay thats done and we will start our react at okay lets go through the stuff we can actually delete no tests you always want to write tests in real life but not today logo and also clear this out here now lets open the material ui docs lets get our component api and lets get a title for our page typography h1 lets just copy this and instead of putting it directly in app lets make a new component for jobs and then lets make a new component for a single job all job which well use in jobs and then lets import react exports default functions okay in this we will use typography okay so just to explain what im doing here i am making a separate component because i want our app just to hold our state and then jobs will actually hold our component tree our render styling and app will hold our application state our use state and call our hooks for kubota did mount and for state that was really confusing sorry were using typography here and lets do variant typography variant okay im naming our page entry level software jobs i think its a good name then save import jobs throw that in there like this okay that is some huge text but were gonna leave it for now within jobs we already know were gonna um import job make this a similar export well just copy this whole thing almost sneezed okay turn div and then this will just be a single job row which will put on a class name of a single job and then well just do this in advance because we know were going to eventually have to write some css to style this stuff lets make a job list should probably actually be matching our component name just to change that back jobs and then job okay so lets just say that were passing down some props for all our jobs from our uh app which is holding our state lets just do it like this and lets do some mock json that we might return from our api swe software engineer one and company google um theres gonna be a bunch of fields but lets just leave them like that for now and my mock job so we dont get it mixed up mock just being mock json data and it should work then we can do jobs map job this will return a job job job equals job hopefully thats not too confusing okay now you could just hear the structure job in the box but jobtitle lets see if this works there it is jobtitle and jobcompany and lets actually add some css for job and just make it a display flex next direction oh thats right its always freaking hard switching from jsx to javascript okay there we go boom ill leave it like that for now we can add more stuff to this this list if we want like this facebook apple itll map it out for us lets give that a little bit of margin a little bit of padding lets do a 10 pixel top left right zero and then padding will be the same okay not too bad not too bad so our front end we could call this like kind of done lets call this done for now and lets return to it after doing some full stack stuff so im gonna collapse our client lets see what our actual data feed is gonna look like coming from uh our source which im just gonna use as github jobs because i know that has a really good clean api output that you dont need a key for or anything so api github jobs open it up you can see some examples here okay so it says that the api supports pagination itll return 50 at a time and you could do it by adding a parameter to your queries before jumping ahead we just know we want these json representation of these jobs so we can manipulate it with our node worker so what im actually going to do is call a similar url like this in our node side which is going to give us output like this just by eyeballing this i could see that it is somewhat matching what we already wrote out here in appjs where theres a title somewhere yes like that senior full stack nodejs developer and there is a company somewhere and we can also tell in advance that locations going to be an important field too but basing our analysis on this we could start to model kind of what our worker is going to do as well as how we want our api to act as well so looking back at our plan lets actually just make a folder for uh all our boxes here so this is the client right api is going to be simplexpress server and then the worker is going to have our algorithm and its going to be calling our apis on a cron job which is at a set interval so maybe every hour in the day we want to refresh these apis refresh our redis and make sure that everything is up to date theres no expired jobs that the companies dont want people to see anymore and were basically staying i'}, {'role': 'assistant', 'content': '{\n  "introduction": "The video tutorial demonstrates the process of building a job board app from scratch, intended to serve as a real startup platform for entry-level or junior developer positions. It covers the app\'s development from conceptualization to deployment, utilizing various technologies and programming languages.",\n  "sections": [\n    {\n      "title": "Section 1: Project Initialization and MVP",\n      "content": [\n        "Introduction to the project\'s goal of simplifying the job search for entry-level developer positions.",\n        "Decision to start with a single data feed using a job board API.",\n        "Explanation of the Minimum Viable Product (MVP) concept.",\n        "Initial setup of the project using React for the frontend and Express server."\n      ],\n      "topics": ["MVP Concept", "API Integration", "React"]\n    },\n    {\n      "title": "Section 2: Backend Development",\n      "content": [\n        "Setup of the Express server and Redis for data storage.",\n        "Implementation of a Node cron job to fetch and refresh job listings.",\n        "Discussion on filtering algorithms to refine job search results.",\n        "Detailed walkthrough of backend code, including async functions and API fetching."\n      ],\n      "topics": ["Express Server", "Redis", "Node Cron Job"]\n    },\n    {\n      "title": "Section 3: Frontend Development",\n      "content": [\n        "Initial setup of React components for job listings.",\n        "Introduction to Material UI for styling the frontend.",\n        "Development of a simple, user-friendly interface.",\n        "Incorporation of job filtering and pagination on the frontend."\n      ],\n      "topics": ["React Components", "Material UI", "Pagination"]\n    },\n    {\n      "title": "Section 4: Data Filtering and Algorithm",\n      "content": [\n        "Explanation of the algorithm to filter out non-entry level jobs.",\n        "Use of string methods to identify relevant job listings.",\n        "Adjustments to the algorithm for improved accuracy.",\n        "Testing and refining the filtering process."\n      ],\n      "topics": ["Filtering Algorithm", "String Methods", "Algorithm Testing"]\n    },\n    {\n      "title": "Section 5: Deployment",\n      "content": [\n        "Overview of deployment process on a virtual private server.",\n        "Configuration of Nginx and security with SSL certificates.",\n        "Final adjustments for production readiness.",\n        "Live deployment and testing of the job board app."\n      ],\n      "topics": ["Deployment", "Nginx Configuration", "SSL Certificates"]\n    }\n  ],\n  "topics": ["React", "Express Server", "Redis", "Filtering Algorithm", "Deployment"],\n  "General Topics": [\n    {"topic": "Web Development and Internet Technologies", "complexity": 0.45},\n    {"topic": "Software Engineering and System Design", "complexity": 0.65},\n    {"topic": "Data Science and Analytics", "complexity": 0.55}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.and i dont just mean your code and its librariesall preconfigured to run as soon as you deploy it thats a container theyre lightning fastisolated environments that you can create in mere momentsand after this video youre going to wonder how you ever developed and deployed applications without them but thats just a vm nookayan osto spin upif there was a scale with vms on one side and normal native applications on the othervirtual machines are pretty much just tricked by the hosts hypervisor layer into thinking theyre actually running on real hardware containersemulate a minimal file systemthe hosts kernel the kernel is the noclose enough the kernel is the core of any operating system its the bridge between what the software asks for and what the hardware actually does its responsible for all sorts of critical lowlevel tasks like cpu and memory managementfile systemsdevelopers wellfingertipsenvironments at once without having to really compromise anything on our local machine for exampleusing the os and package dependencies it was originally built on top ofwhile also being able to use bleeding edge tech for our next multimillion dollar project without having to worry about any conflicts in doing so were also now able to put an end to the it works on my machine problemwhich is a pretty common phrase to hear in the tech industrybecause a container is essentially a full os at its coreyou can be sure that wherever it runs youre going to get the exact same environmentmachinenow weve got the basics out of the way lets see how we can make a container of our own the first thing were going to need is a container platform this will give us all the tools we need to create and run our containerjust because its the most well supported all containers run from a base file system and some metadataand the way container images work is kind of fascinatingbecause they are formed with overlapping layers heres a banana to kind of badly demonstrate this idea okayits sourcedifferences to the previous layerthe final system state its somewhat similar to how source control tracks changes in your code this concept is really powerful for containersany previous image or image layer theres loads of premade and officially supported base images out thererequirementsto do this in dockerfile called a dockerfile docker will execute each command in sequenceand then add each generated change to the final image as a new file system layerlike from a single image we can do this because when a container is first createdlayerthis means that we can make any runtime changes we likeother containers using that same image whats moreuntil we delete the containerwithout losing any data we can even enter our running containerslike we do with a vm with linux containerswe can start a shell prompt when executing itenvironment to explore and kind of just play around with as we please communication between containers is usually pretty simple as wellas most runtimes virtualize a network layer for you when our app is ready to be published into the worldtag it with something uniqueit again later we can then publish it to something called a container registrywarehouse for our images by defaultusing the official docker registry howeverif you wish to use another when it comes to deploymentcloud platforms have builtin support for deploying containers as standalone units alternativelycompatible container runtime on whatever machine you want to usepull your image from the registry you pushed to earlier it does require a few more steps doing it this wayvalue for money and quite a bit more control if you want to go even deeperkubernetes essentially allow you to create your own containerbased cloud you describe the desired state of your deployment declarativelyand let kubernetes handle the details of how to get there and thats it ohand with enough supportand ill see you next time '}]
    cuda memory allocated: 15.54 GB, cuda memory cached: 16.37 GB
Processing: dpo
    Tokens: 7612
    Decoding took: 56.16 seconds
    Messages: [{'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hello guys welcome back to my channel today we are going to talk about mistral so as you know mistral is a new language model that came out a few months ago from mistal ai which is a one of the hottest startup right now in europe for language models it also became a unicorn recently and we will exploring both the models they released one is the 7 billion and one is the 8 by7 billion model so lets review the topics of today the first thing i will introduce you is the architectural differences between the vanilla transformer and the architecture of mistal later we will see what is the sliding window attention and how it is related to the concept of receptive field a concept that usually we find in convolutional neural networks i will briefly review the kv cache because i want to introduce the concept of rolling buffer cache and also how it is done with prefilling and chunking uh we will see what is sparse mixture of experts model sharding with a little with a very brief introduction with the pipeline parallelism and last but not least we will also go through the code of mistal because there is a lot of innovations in the code especially when they use the x forers library with the block attention so i want to guide you into understanding the code because it can be really hard for beginners to understand and find thems around there are some topics that are related to mistal but will not be covered in this current video because i already covered them in my previous video about llama and in particular i will not be talking about the rms normalization the rotary positional encoding and the group query attention because i already um teach them in depth in my previous video on llama so if you want to know about them please watch my previous video on llama another the only prerequisite that i hope you have before watching this video because the topics we are going to touch are quite advanced is that you are familiar with the transformer model so if youre not familiar with the transformer model and the attention mechanism in particular and in particular the self attention mechanism please go watch my video on the transformer in which i teach all this concept very thoroughly very in detail these are really a prerequisite for watching this video because the top the topics here are quite advanced okay lets proceed further so lets watch the differences between the vanilla transformer and mistal at the architecture level as you can see from the um image here which i built by myself using the code because they didnt release any architecture picture in the paper u the architecture of mistal first of all lets talk about some terminology when you have a model like this made up of many encoder layers plus linear and the soft max we are talking about a decoder only model because this part this model here looks like the decoder of the vanilla transformer you can see here except for the cross attention because as you can see here there is no cross attention when we have a model without the linear and the softmax we call it an incoder only model for example bir is an encoder only model because birth has some heads at at the end which is one or more linear layers depending on the application but it self birth doesnt need a head because it can be used for multiple downstream tasks so its called an encoder only model because it resembles the encoder side of the transformer because as you can see in the encoder side there is no linear and soft max so mistal is a decoder only model and its very similar if not equal to llama the differences between llama and mistal are highlighted here in red the first difference between llama and mistal is that in the self attention we use the sliding window attention and we still use the group query attention but and also the kv cache for inferencing but this is a rolling buffer kv cache and its actually related to the fact that we are using sliding window attention so later we will see all these concepts and the another difference is that the feed forward layer here instead of using the reu function that we used in um in the vanilla transformer or the zigo function that we us in lama here in mistal we use the ceu function um and the feed forward is one in case of mistal 7b so the first model they released and its it can be eight feed forwards uh networks in parallel with each other which are the experts of this mixture of expert in the case of mral 8x 7b um we will see later how it works so for now you just need to understand that mistal is made up of okay the input which are converted into embeddings then we have this block which is repeated n times and we will see that in the case of mistal is repeated 32 times one after another such that the output of each layer is fed to the next layer as input and the output of the last layer is then sent to this rms norm to the linear and to the softmax to produce the output of the model and um this is exactly the same as what we do with any other transformer model usually we have many of this blocks here now in the code of mistal this part here is known as transformer block but its also known as encoder block or decoder block depending on the in the contents of this um block here i will refer to it as an encoder block because if you look at it it looks like exactly as the block of the encoder side so it has a multi header tension od and norm a feed forward and other norm the only difference is that the normalization here comes before the uh the the bl of the feit forward and the self attention okay lets move forward now lets compare the the two models so one is mistal 7b and one in mistal 8x 7b the parameter dim indicates the dimension of the this the dimensions of the embedding vector so how big is the embedding vector so each token is represented by an embedding vector of size 496 dimensions we have 32 of the encoder layers so this block here is repeated 32 times the head dimension indicates as you remember in the multiad attention we have um each head is watching the entire sentence but only a part of the embedding of each token and this indicates how much how many dimensions each head will attend to in each um for in the multiad attention and the hidden dimension here indicates the hidden dimension of the feed forward layer so if the in the case of the fit forward layer we have two linear layers one that converts the the dimension of the embedding vector into the hidden size then another one that converts the hidden size back into the embedding vector dimensions so in the case of the mistal they are using as a hidden size 14336 usually this is a multiple of the dimension and it looks like its 35 the dimension here the number of heads of attention for the query is 32 two while the number of heads for the k and v so the key and values is eight and they are not equal because of the grouped query attention so if you remember from my previous video on lama in which we talk about the group query attention um in the very sim'}, {'role': 'assistant', 'content': '{\n  "introduction": "This video provides an in-depth analysis and tutorial on Mistral, a new language model developed by Mistral AI, a leading European startup in the language model space. The presenter delves into the architectural nuances of Mistral compared to traditional transformers, explores advanced concepts like sliding window attention, the use of a rolling buffer KV cache, sparse mixture of experts model, and the intricacies of coding with the Xformers library for block attention.",\n  "sections": [\n    {\n      "title": "Section 1: Architectural Overview",\n      "content": [\n        "Comparison between Mistral and vanilla transformer models.",\n        "Introduction to decoder-only models and their relevance to Mistral.",\n        "Key architectural differences highlighted, including attention mechanisms and feedforward layers.",\n        "Exploration of the sliding window attention mechanism."\n      ],\n      "topics": ["Transformer Architecture", "Decoder Models", "Sliding Window Attention"]\n    },\n    {\n      "title": "Section 2: Advanced Attention Mechanisms",\n      "content": [\n        "Deep dive into sliding window attention and its computational benefits.",\n        "Discussion on the concept of receptive fields and their analogy in CNNs.",\n        "Introduction to rolling buffer KV cache for efficient memory usage.",\n        "Explanation of chunking and pre-filling techniques for optimized processing."\n      ],\n      "topics": ["Sliding Window Attention", "Receptive Fields", "KV Cache"]\n    },\n    {\n      "title": "Section 3: Sparse Mixture of Experts",\n      "content": [\n        "Introduction to the concept of sparse mixture of experts and its implementation in Mistral.",\n        "Discussion on model sharding and pipeline parallelism for scaling models.",\n        "The significance of selecting experts based on token processing.",\n        "Efficiency gains from using sparse models in terms of computation and specialization."\n      ],\n      "topics": ["Sparse Mixture of Experts", "Model Sharding", "Pipeline Parallelism"]\n    },\n    {\n      "title": "Section 4: Code Innovations",\n      "content": [\n        "Overview of code-level innovations in Mistral, focusing on the Xformers library.",\n        "Explanation of block attention techniques for handling variable-length prompts.",\n        "Strategies for managing KV caches and attention masks in code.",\n        "Insights into the development challenges and solutions for optimizing language model inference."\n      ],\n      "topics": ["Xformers Library", "Block Attention", "Code Optimization"]\n    },\n    {\n      "title": "Section 5: Practical Applications and Coding Tutorial",\n      "content": [\n        "Step-by-step coding tutorial for implementing Mistral features.",\n        "Examples of practical applications and the benefits of Mistral\'s architecture.",\n        "Discussion on the importance of understanding transformer models as a prerequisite.",\n        "Guidance on navigating and understanding the Mistral codebase for developers."\n      ],\n      "topics": ["Coding Tutorial", "Practical Applications", "Understanding Transformers"]\n    }\n  ],\n  "topics": ["Transformer Architecture", "Sliding Window Attention", "Sparse Mixture of Experts", "Code Optimization", "Practical Applications"],\n  "General Topics": [\n    {"topic": "Artificial Intelligence (AI) and Machine Learning", "complexity": 0.89},\n    {"topic": "Software Engineering and System Design", "complexity": 0.75},\n    {"topic": "Programming Languages and Software Development", "complexity": 0.66}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.whats up guys back today with another longer video which is to build a job board app that could actually be a real startup that people use theres a lot of different places to find entry level or junior developer jobs on the internet for example github jobs stack overflow jobs you have angel list you have indeed but filtering through those especially because you kind of have to spam applications for your first job can take a long time so the good thing about all these job boards is they have public apis for the most part you always want to start with an mvp that is the minimum viable product today that means were going to start with a single data feed that is a single job board api feeding into our app and then finally were gonna have a super minimal simple front end were gonna do this in react and material ui on the front end were gonna use an express server redis for our data storage because were not writing or persisting any data that is not part of the job feed and then finally a node cron job to fetch these jobs and refresh them at a certain interval which are going to be filtered through an algorithm so lets draw this all out to get a better idea of our plan heres our front end what we basically want here is a list of jobs this is going to be pulling data from our api and that will be express and then this will pull from our store which is actually going to be redis and redis will be populated by our cron called a worker which is pulling from music one or more apis its going to be eventually multiple this is going to be job uh board apis so like in lets say indeed we have github we have stack jobs and this is going to be filtered through our algorithm were filtering down the jobs getting rid of the senior jobs getting rid of the manager jobs and eventually when we make it more complicated we could even look through the description for years of experience and create uh search indexes and different things like that but again the minimum is just going to be pulling the jobs in and filtering them down okay so this is our plan lets start with the front end i know a lot of you guys like react and its gonna actually be super simple lets just do a create react app to get started uh i already have a folder our directory here called junior dev so lets uh do a create react app and then call it client you guys know that i love material ui so lets install that as well once we get into our client and lets do yarn add okay thats done and we will start our react at okay lets go through the stuff we can actually delete no tests you always want to write tests in real life but not today logo and also clear this out here now lets open the material ui docs lets get our component api and lets get a title for our page typography h1 lets just copy this and instead of putting it directly in app lets make a new component for jobs and then lets make a new component for a single job all job which well use in jobs and then lets import react exports default functions okay in this we will use typography okay so just to explain what im doing here i am making a separate component because i want our app just to hold our state and then jobs will actually hold our component tree our render styling and app will hold our application state our use state and call our hooks for kubota did mount and for state that was really confusing sorry were using typography here and lets do variant typography variant okay im naming our page entry level software jobs i think its a good name then save import jobs throw that in there like this okay that is some huge text but were gonna leave it for now within jobs we already know were gonna um import job make this a similar export well just copy this whole thing almost sneezed okay turn div and then this will just be a single job row which will put on a class name of a single job and then well just do this in advance because we know were going to eventually have to write some css to style this stuff lets make a job list should probably actually be matching our component name just to change that back jobs and then job okay so lets just say that were passing down some props for all our jobs from our uh app which is holding our state lets just do it like this and lets do some mock json that we might return from our api swe software engineer one and company google um theres gonna be a bunch of fields but lets just leave them like that for now and my mock job so we dont get it mixed up mock just being mock json data and it should work then we can do jobs map job this will return a job job job equals job hopefully thats not too confusing okay now you could just hear the structure job in the box but jobtitle lets see if this works there it is jobtitle and jobcompany and lets actually add some css for job and just make it a display flex next direction oh thats right its always freaking hard switching from jsx to javascript okay there we go boom ill leave it like that for now we can add more stuff to this this list if we want like this facebook apple itll map it out for us lets give that a little bit of margin a little bit of padding lets do a 10 pixel top left right zero and then padding will be the same okay not too bad not too bad so our front end we could call this like kind of done lets call this done for now and lets return to it after doing some full stack stuff so im gonna collapse our client lets see what our actual data feed is gonna look like coming from uh our source which im just gonna use as github jobs because i know that has a really good clean api output that you dont need a key for or anything so api github jobs open it up you can see some examples here okay so it says that the api supports pagination itll return 50 at a time and you could do it by adding a parameter to your queries before jumping ahead we just know we want these json representation of these jobs so we can manipulate it with our node worker so what im actually going to do is call a similar url like this in our node side which is going to give us output like this just by eyeballing this i could see that it is somewhat matching what we already wrote out here in appjs where theres a title somewhere yes like that senior full stack nodejs developer and there is a company somewhere and we can also tell in advance that locations going to be an important field too but basing our analysis on this we could start to model kind of what our worker is going to do as well as how we want our api to act as well so looking back at our plan lets actually just make a folder for uh all our boxes here so this is the client right api is going to be simplexpress server and then the worker is going to have our algorithm and its going to be calling our apis on a cron job which is at a set interval so maybe every hour in the day we want to refresh these apis refresh our redis and make sure that everything is up to date theres no expired jobs that the companies dont want people to see anymore and were basically staying i'}, {'role': 'assistant', 'content': '{\n  "introduction": "The video tutorial demonstrates the process of building a job board app from scratch, intended to serve as a real startup platform for entry-level or junior developer positions. It covers the app\'s development from conceptualization to deployment, utilizing various technologies and programming languages.",\n  "sections": [\n    {\n      "title": "Section 1: Project Initialization and MVP",\n      "content": [\n        "Introduction to the project\'s goal of simplifying the job search for entry-level developer positions.",\n        "Decision to start with a single data feed using a job board API.",\n        "Explanation of the Minimum Viable Product (MVP) concept.",\n        "Initial setup of the project using React for the frontend and Express server."\n      ],\n      "topics": ["MVP Concept", "API Integration", "React"]\n    },\n    {\n      "title": "Section 2: Backend Development",\n      "content": [\n        "Setup of the Express server and Redis for data storage.",\n        "Implementation of a Node cron job to fetch and refresh job listings.",\n        "Discussion on filtering algorithms to refine job search results.",\n        "Detailed walkthrough of backend code, including async functions and API fetching."\n      ],\n      "topics": ["Express Server", "Redis", "Node Cron Job"]\n    },\n    {\n      "title": "Section 3: Frontend Development",\n      "content": [\n        "Initial setup of React components for job listings.",\n        "Introduction to Material UI for styling the frontend.",\n        "Development of a simple, user-friendly interface.",\n        "Incorporation of job filtering and pagination on the frontend."\n      ],\n      "topics": ["React Components", "Material UI", "Pagination"]\n    },\n    {\n      "title": "Section 4: Data Filtering and Algorithm",\n      "content": [\n        "Explanation of the algorithm to filter out non-entry level jobs.",\n        "Use of string methods to identify relevant job listings.",\n        "Adjustments to the algorithm for improved accuracy.",\n        "Testing and refining the filtering process."\n      ],\n      "topics": ["Filtering Algorithm", "String Methods", "Algorithm Testing"]\n    },\n    {\n      "title": "Section 5: Deployment",\n      "content": [\n        "Overview of deployment process on a virtual private server.",\n        "Configuration of Nginx and security with SSL certificates.",\n        "Final adjustments for production readiness.",\n        "Live deployment and testing of the job board app."\n      ],\n      "topics": ["Deployment", "Nginx Configuration", "SSL Certificates"]\n    }\n  ],\n  "topics": ["React", "Express Server", "Redis", "Filtering Algorithm", "Deployment"],\n  "General Topics": [\n    {"topic": "Web Development and Internet Technologies", "complexity": 0.45},\n    {"topic": "Software Engineering and System Design", "complexity": 0.65},\n    {"topic": "Data Science and Analytics", "complexity": 0.55}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.this video is about a new approach to training language models specifically it allows you to move the probabilities of a language model away from bad answers and towards good answers direct preference optimization or dpo for short is a type of reinforcement learning its a more efficient type than has long been used by companies like open ai and meta in developing lama 2 and with this dpo technique it makes it much easier to find you models towards a chat format that is aligned in a similar way to those commercial models available for agenda were going to take a look at how normal training works standard finetuning or supervised finetuning as ive done in previous videos then ill contrast how direct preference optimization works and why its a bit different in terms of a technique and its useful in a different and complimentary way to standard finetuning then ill show you two dpo data sets the data sets need to be in a specific format if youre going to use the hugging face trainer that we will use today and then ill walk step by step through the training notebook ive developed for doing direct preference optimization by the end of this tutorial you should be able to take a model youve developed a language model ideally you do some supervised finetuning to get it into a chat format and this will allow you to do the final stage of aligning the model um another way to think of that is moving the model probabilities away from bad answers and towards good answers that will make sense as we get a bit deeper into this video lets start off with a description very high level of how standard training works standard language model training involves penalizing the model based on predicted what it predicts for the next token versus the actual next token for example if you feed in a phrase or part of a phrase that says the capital of ireland is and you ask the model to predict the next token if the model predicts dublin and then you wouldnt free penalize it because that answer is the next token here in this sentence but if it says something like cork then you would penalize the model and back back propagate through so fundamentally language models are statistical models that look at the frequency of information that is in the training data set if i train a language model with the capital of ireland is dublin the capital of ireland is dublin the capital of ireland is cork well if will see dublin more frequently and so that is more likely to be returned when the model predicts the next token if i want to bias the model towards saying dublin with a very high probability i can just keep feeding in the capital of ireland is dublin the captain ireland is dublin and eventually the relative frequency it is seen for dublin will be much greater than cork and so it is going to respond with the word dublin as the answer and that if you generalize it is how language models work work theyre statistical the more data you feed them a certain format the more it will bias bias the model towards that answer lets just look at a simple example here where we have a data set with doublin as the next token 10 times and cork as the next token one time if we train on this data set the language model is very often going to predict dublin as the next token because it has seen it so many more times in a data set now if we wanted to increase the probability even higher we would just have to add more and more and more data that says the capital violent is doubling so that we increase the probability of dublin being the answer now by contrast lets take a look at direct preference optimization here instead of adding more data to the model and penalizing it based on the next token prediction were going to do something a little bit more nuanced at a high level were going to drag the probability distribution away from one answer like cork and towards another answer dublin so as an example we have a prompt the capital of arland is and then were waiting on the next token and were going to set up two responses were going to set up a chosen response which is dublin and were going to set up a rejected response which is cork so remember in standard training the only data we have is on the actual token and we just compare actual to what the model predicts which could be anything it could be russ common up in new york it could be any value the only input data we have is the actual next token but here in direct preference optimization we have a pair of options we have a chosen and we have a rejected option and the way that we penalize the model now is not by comparing the actual to the predicted but rather we penalize the model so that the probability of dublin of the model were training we want that probability to be high relative to a ref reference model the reference model is just a copy of the model when we start this whole dpo step so imagine starting dpo we have a model we duplicate it so we now have a model and a reference model and during the training were going to penalize the model in such a way to incentivize the probability of the model being trained increasing for dublin relative to the probability that the reference model predicts for dublin and likewise were going to want to incentivize the model in a way such that the probability it predicts for cork should be reduced relative to the probability of the reference model so you can see how these pairs are being used and were trying to increase the probability of the chosen answer and decrease the probability of the rejected answer really high level what were doing here is imagine a training data set so youve come along with the model youve done some supervised fine tuning its been trained on a trillion tokens there are lots and lots of data points here within um the data set and in that data set of course because weve trained it on the internet there are some bad answers some answers that you know people have written things on the internet that arent correct and then there are some answers we consider good answers uh where maybe theres more of these but theres not enough more to statistically get the right answer all of the time so we have this data set body with bad answers and great answers and how direct preference optimization works is by using pairs of answers by feeding it some pairs we bias the model away from bad answers and we bias it towards great ideally great but certainly better answers so again to contrast this with standard training if we want to bias the model towards better answers with standard training the only way we can do that is by feeding more great answers so with standard training you have to keep feeding in more of these great answers the bad answers will still be there in the data set but over time these great answers will start to dominate as we train on more and more sets of the capital of ireland is dublin whereas by contrast in dpo were penalizing the model for a bad answer and were incentivizing it for a good answer now im giving a v'}]
    cuda memory allocated: 15.54 GB, cuda memory cached: 16.37 GB
Processing: mixtral8x7b
    Tokens: 7662
    Decoding took: 9.791 seconds
    Messages: [{'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hello guys welcome back to my channel today we are going to talk about mistral so as you know mistral is a new language model that came out a few months ago from mistal ai which is a one of the hottest startup right now in europe for language models it also became a unicorn recently and we will exploring both the models they released one is the 7 billion and one is the 8 by7 billion model so lets review the topics of today the first thing i will introduce you is the architectural differences between the vanilla transformer and the architecture of mistal later we will see what is the sliding window attention and how it is related to the concept of receptive field a concept that usually we find in convolutional neural networks i will briefly review the kv cache because i want to introduce the concept of rolling buffer cache and also how it is done with prefilling and chunking uh we will see what is sparse mixture of experts model sharding with a little with a very brief introduction with the pipeline parallelism and last but not least we will also go through the code of mistal because there is a lot of innovations in the code especially when they use the x forers library with the block attention so i want to guide you into understanding the code because it can be really hard for beginners to understand and find thems around there are some topics that are related to mistal but will not be covered in this current video because i already covered them in my previous video about llama and in particular i will not be talking about the rms normalization the rotary positional encoding and the group query attention because i already um teach them in depth in my previous video on llama so if you want to know about them please watch my previous video on llama another the only prerequisite that i hope you have before watching this video because the topics we are going to touch are quite advanced is that you are familiar with the transformer model so if youre not familiar with the transformer model and the attention mechanism in particular and in particular the self attention mechanism please go watch my video on the transformer in which i teach all this concept very thoroughly very in detail these are really a prerequisite for watching this video because the top the topics here are quite advanced okay lets proceed further so lets watch the differences between the vanilla transformer and mistal at the architecture level as you can see from the um image here which i built by myself using the code because they didnt release any architecture picture in the paper u the architecture of mistal first of all lets talk about some terminology when you have a model like this made up of many encoder layers plus linear and the soft max we are talking about a decoder only model because this part this model here looks like the decoder of the vanilla transformer you can see here except for the cross attention because as you can see here there is no cross attention when we have a model without the linear and the softmax we call it an incoder only model for example bir is an encoder only model because birth has some heads at at the end which is one or more linear layers depending on the application but it self birth doesnt need a head because it can be used for multiple downstream tasks so its called an encoder only model because it resembles the encoder side of the transformer because as you can see in the encoder side there is no linear and soft max so mistal is a decoder only model and its very similar if not equal to llama the differences between llama and mistal are highlighted here in red the first difference between llama and mistal is that in the self attention we use the sliding window attention and we still use the group query attention but and also the kv cache for inferencing but this is a rolling buffer kv cache and its actually related to the fact that we are using sliding window attention so later we will see all these concepts and the another difference is that the feed forward layer here instead of using the reu function that we used in um in the vanilla transformer or the zigo function that we us in lama here in mistal we use the ceu function um and the feed forward is one in case of mistal 7b so the first model they released and its it can be eight feed forwards uh networks in parallel with each other which are the experts of this mixture of expert in the case of mral 8x 7b um we will see later how it works so for now you just need to understand that mistal is made up of okay the input which are converted into embeddings then we have this block which is repeated n times and we will see that in the case of mistal is repeated 32 times one after another such that the output of each layer is fed to the next layer as input and the output of the last layer is then sent to this rms norm to the linear and to the softmax to produce the output of the model and um this is exactly the same as what we do with any other transformer model usually we have many of this blocks here now in the code of mistal this part here is known as transformer block but its also known as encoder block or decoder block depending on the in the contents of this um block here i will refer to it as an encoder block because if you look at it it looks like exactly as the block of the encoder side so it has a multi header tension od and norm a feed forward and other norm the only difference is that the normalization here comes before the uh the the bl of the feit forward and the self attention okay lets move forward now lets compare the the two models so one is mistal 7b and one in mistal 8x 7b the parameter dim indicates the dimension of the this the dimensions of the embedding vector so how big is the embedding vector so each token is represented by an embedding vector of size 496 dimensions we have 32 of the encoder layers so this block here is repeated 32 times the head dimension indicates as you remember in the multiad attention we have um each head is watching the entire sentence but only a part of the embedding of each token and this indicates how much how many dimensions each head will attend to in each um for in the multiad attention and the hidden dimension here indicates the hidden dimension of the feed forward layer so if the in the case of the fit forward layer we have two linear layers one that converts the the dimension of the embedding vector into the hidden size then another one that converts the hidden size back into the embedding vector dimensions so in the case of the mistal they are using as a hidden size 14336 usually this is a multiple of the dimension and it looks like its 35 the dimension here the number of heads of attention for the query is 32 two while the number of heads for the k and v so the key and values is eight and they are not equal because of the grouped query attention so if you remember from my previous video on lama in which we talk about the group query attention um in the very sim'}, {'role': 'assistant', 'content': '{\n  "introduction": "This video provides an in-depth analysis and tutorial on Mistral, a new language model developed by Mistral AI, a leading European startup in the language model space. The presenter delves into the architectural nuances of Mistral compared to traditional transformers, explores advanced concepts like sliding window attention, the use of a rolling buffer KV cache, sparse mixture of experts model, and the intricacies of coding with the Xformers library for block attention.",\n  "sections": [\n    {\n      "title": "Section 1: Architectural Overview",\n      "content": [\n        "Comparison between Mistral and vanilla transformer models.",\n        "Introduction to decoder-only models and their relevance to Mistral.",\n        "Key architectural differences highlighted, including attention mechanisms and feedforward layers.",\n        "Exploration of the sliding window attention mechanism."\n      ],\n      "topics": ["Transformer Architecture", "Decoder Models", "Sliding Window Attention"]\n    },\n    {\n      "title": "Section 2: Advanced Attention Mechanisms",\n      "content": [\n        "Deep dive into sliding window attention and its computational benefits.",\n        "Discussion on the concept of receptive fields and their analogy in CNNs.",\n        "Introduction to rolling buffer KV cache for efficient memory usage.",\n        "Explanation of chunking and pre-filling techniques for optimized processing."\n      ],\n      "topics": ["Sliding Window Attention", "Receptive Fields", "KV Cache"]\n    },\n    {\n      "title": "Section 3: Sparse Mixture of Experts",\n      "content": [\n        "Introduction to the concept of sparse mixture of experts and its implementation in Mistral.",\n        "Discussion on model sharding and pipeline parallelism for scaling models.",\n        "The significance of selecting experts based on token processing.",\n        "Efficiency gains from using sparse models in terms of computation and specialization."\n      ],\n      "topics": ["Sparse Mixture of Experts", "Model Sharding", "Pipeline Parallelism"]\n    },\n    {\n      "title": "Section 4: Code Innovations",\n      "content": [\n        "Overview of code-level innovations in Mistral, focusing on the Xformers library.",\n        "Explanation of block attention techniques for handling variable-length prompts.",\n        "Strategies for managing KV caches and attention masks in code.",\n        "Insights into the development challenges and solutions for optimizing language model inference."\n      ],\n      "topics": ["Xformers Library", "Block Attention", "Code Optimization"]\n    },\n    {\n      "title": "Section 5: Practical Applications and Coding Tutorial",\n      "content": [\n        "Step-by-step coding tutorial for implementing Mistral features.",\n        "Examples of practical applications and the benefits of Mistral\'s architecture.",\n        "Discussion on the importance of understanding transformer models as a prerequisite.",\n        "Guidance on navigating and understanding the Mistral codebase for developers."\n      ],\n      "topics": ["Coding Tutorial", "Practical Applications", "Understanding Transformers"]\n    }\n  ],\n  "topics": ["Transformer Architecture", "Sliding Window Attention", "Sparse Mixture of Experts", "Code Optimization", "Practical Applications"],\n  "General Topics": [\n    {"topic": "Artificial Intelligence (AI) and Machine Learning", "complexity": 0.89},\n    {"topic": "Software Engineering and System Design", "complexity": 0.75},\n    {"topic": "Programming Languages and Software Development", "complexity": 0.66}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.whats up guys back today with another longer video which is to build a job board app that could actually be a real startup that people use theres a lot of different places to find entry level or junior developer jobs on the internet for example github jobs stack overflow jobs you have angel list you have indeed but filtering through those especially because you kind of have to spam applications for your first job can take a long time so the good thing about all these job boards is they have public apis for the most part you always want to start with an mvp that is the minimum viable product today that means were going to start with a single data feed that is a single job board api feeding into our app and then finally were gonna have a super minimal simple front end were gonna do this in react and material ui on the front end were gonna use an express server redis for our data storage because were not writing or persisting any data that is not part of the job feed and then finally a node cron job to fetch these jobs and refresh them at a certain interval which are going to be filtered through an algorithm so lets draw this all out to get a better idea of our plan heres our front end what we basically want here is a list of jobs this is going to be pulling data from our api and that will be express and then this will pull from our store which is actually going to be redis and redis will be populated by our cron called a worker which is pulling from music one or more apis its going to be eventually multiple this is going to be job uh board apis so like in lets say indeed we have github we have stack jobs and this is going to be filtered through our algorithm were filtering down the jobs getting rid of the senior jobs getting rid of the manager jobs and eventually when we make it more complicated we could even look through the description for years of experience and create uh search indexes and different things like that but again the minimum is just going to be pulling the jobs in and filtering them down okay so this is our plan lets start with the front end i know a lot of you guys like react and its gonna actually be super simple lets just do a create react app to get started uh i already have a folder our directory here called junior dev so lets uh do a create react app and then call it client you guys know that i love material ui so lets install that as well once we get into our client and lets do yarn add okay thats done and we will start our react at okay lets go through the stuff we can actually delete no tests you always want to write tests in real life but not today logo and also clear this out here now lets open the material ui docs lets get our component api and lets get a title for our page typography h1 lets just copy this and instead of putting it directly in app lets make a new component for jobs and then lets make a new component for a single job all job which well use in jobs and then lets import react exports default functions okay in this we will use typography okay so just to explain what im doing here i am making a separate component because i want our app just to hold our state and then jobs will actually hold our component tree our render styling and app will hold our application state our use state and call our hooks for kubota did mount and for state that was really confusing sorry were using typography here and lets do variant typography variant okay im naming our page entry level software jobs i think its a good name then save import jobs throw that in there like this okay that is some huge text but were gonna leave it for now within jobs we already know were gonna um import job make this a similar export well just copy this whole thing almost sneezed okay turn div and then this will just be a single job row which will put on a class name of a single job and then well just do this in advance because we know were going to eventually have to write some css to style this stuff lets make a job list should probably actually be matching our component name just to change that back jobs and then job okay so lets just say that were passing down some props for all our jobs from our uh app which is holding our state lets just do it like this and lets do some mock json that we might return from our api swe software engineer one and company google um theres gonna be a bunch of fields but lets just leave them like that for now and my mock job so we dont get it mixed up mock just being mock json data and it should work then we can do jobs map job this will return a job job job equals job hopefully thats not too confusing okay now you could just hear the structure job in the box but jobtitle lets see if this works there it is jobtitle and jobcompany and lets actually add some css for job and just make it a display flex next direction oh thats right its always freaking hard switching from jsx to javascript okay there we go boom ill leave it like that for now we can add more stuff to this this list if we want like this facebook apple itll map it out for us lets give that a little bit of margin a little bit of padding lets do a 10 pixel top left right zero and then padding will be the same okay not too bad not too bad so our front end we could call this like kind of done lets call this done for now and lets return to it after doing some full stack stuff so im gonna collapse our client lets see what our actual data feed is gonna look like coming from uh our source which im just gonna use as github jobs because i know that has a really good clean api output that you dont need a key for or anything so api github jobs open it up you can see some examples here okay so it says that the api supports pagination itll return 50 at a time and you could do it by adding a parameter to your queries before jumping ahead we just know we want these json representation of these jobs so we can manipulate it with our node worker so what im actually going to do is call a similar url like this in our node side which is going to give us output like this just by eyeballing this i could see that it is somewhat matching what we already wrote out here in appjs where theres a title somewhere yes like that senior full stack nodejs developer and there is a company somewhere and we can also tell in advance that locations going to be an important field too but basing our analysis on this we could start to model kind of what our worker is going to do as well as how we want our api to act as well so looking back at our plan lets actually just make a folder for uh all our boxes here so this is the client right api is going to be simplexpress server and then the worker is going to have our algorithm and its going to be calling our apis on a cron job which is at a set interval so maybe every hour in the day we want to refresh these apis refresh our redis and make sure that everything is up to date theres no expired jobs that the companies dont want people to see anymore and were basically staying i'}, {'role': 'assistant', 'content': '{\n  "introduction": "The video tutorial demonstrates the process of building a job board app from scratch, intended to serve as a real startup platform for entry-level or junior developer positions. It covers the app\'s development from conceptualization to deployment, utilizing various technologies and programming languages.",\n  "sections": [\n    {\n      "title": "Section 1: Project Initialization and MVP",\n      "content": [\n        "Introduction to the project\'s goal of simplifying the job search for entry-level developer positions.",\n        "Decision to start with a single data feed using a job board API.",\n        "Explanation of the Minimum Viable Product (MVP) concept.",\n        "Initial setup of the project using React for the frontend and Express server."\n      ],\n      "topics": ["MVP Concept", "API Integration", "React"]\n    },\n    {\n      "title": "Section 2: Backend Development",\n      "content": [\n        "Setup of the Express server and Redis for data storage.",\n        "Implementation of a Node cron job to fetch and refresh job listings.",\n        "Discussion on filtering algorithms to refine job search results.",\n        "Detailed walkthrough of backend code, including async functions and API fetching."\n      ],\n      "topics": ["Express Server", "Redis", "Node Cron Job"]\n    },\n    {\n      "title": "Section 3: Frontend Development",\n      "content": [\n        "Initial setup of React components for job listings.",\n        "Introduction to Material UI for styling the frontend.",\n        "Development of a simple, user-friendly interface.",\n        "Incorporation of job filtering and pagination on the frontend."\n      ],\n      "topics": ["React Components", "Material UI", "Pagination"]\n    },\n    {\n      "title": "Section 4: Data Filtering and Algorithm",\n      "content": [\n        "Explanation of the algorithm to filter out non-entry level jobs.",\n        "Use of string methods to identify relevant job listings.",\n        "Adjustments to the algorithm for improved accuracy.",\n        "Testing and refining the filtering process."\n      ],\n      "topics": ["Filtering Algorithm", "String Methods", "Algorithm Testing"]\n    },\n    {\n      "title": "Section 5: Deployment",\n      "content": [\n        "Overview of deployment process on a virtual private server.",\n        "Configuration of Nginx and security with SSL certificates.",\n        "Final adjustments for production readiness.",\n        "Live deployment and testing of the job board app."\n      ],\n      "topics": ["Deployment", "Nginx Configuration", "SSL Certificates"]\n    }\n  ],\n  "topics": ["React", "Express Server", "Redis", "Filtering Algorithm", "Deployment"],\n  "General Topics": [\n    {"topic": "Web Development and Internet Technologies", "complexity": 0.45},\n    {"topic": "Software Engineering and System Design", "complexity": 0.65},\n    {"topic": "Data Science and Analytics", "complexity": 0.55}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hello guys welcome back to my channel today we are going to talk about mistral so as you know mistral is a new language model that came out a few months ago from mistal ai which is a one of the hottest startup right now in europe for language models it also became a unicorn recently and we will exploring both the models they released one is the 7 billion and one is the 8 by7 billion model so lets review the topics of today the first thing i will introduce you is the architectural differences between the vanilla transformer and the architecture of mistal later we will see what is the sliding window attention and how it is related to the concept of receptive field a concept that usually we find in convolutional neural networks i will briefly review the kv cache because i want to introduce the concept of rolling buffer cache and also how it is done with prefilling and chunking uh we will see what is sparse mixture of experts model sharding with a little with a very brief introduction with the pipeline parallelism and last but not least we will also go through the code of mistal because there is a lot of innovations in the code especially when they use the x forers library with the block attention so i want to guide you into understanding the code because it can be really hard for beginners to understand and find thems around there are some topics that are related to mistal but will not be covered in this current video because i already covered them in my previous video about llama and in particular i will not be talking about the rms normalization the rotary positional encoding and the group query attention because i already um teach them in depth in my previous video on llama so if you want to know about them please watch my previous video on llama another the only prerequisite that i hope you have before watching this video because the topics we are going to touch are quite advanced is that you are familiar with the transformer model so if youre not familiar with the transformer model and the attention mechanism in particular and in particular the self attention mechanism please go watch my video on the transformer in which i teach all this concept very thoroughly very in detail these are really a prerequisite for watching this video because the top the topics here are quite advanced okay lets proceed further so lets watch the differences between the vanilla transformer and mistal at the architecture level as you can see from the um image here which i built by myself using the code because they didnt release any architecture picture in the paper u the architecture of mistal first of all lets talk about some terminology when you have a model like this made up of many encoder layers plus linear and the soft max we are talking about a decoder only model because this part this model here looks like the decoder of the vanilla transformer you can see here except for the cross attention because as you can see here there is no cross attention when we have a model without the linear and the softmax we call it an incoder only model for example bir is an encoder only model because birth has some heads at at the end which is one or more linear layers depending on the application but it self birth doesnt need a head because it can be used for multiple downstream tasks so its called an encoder only model because it resembles the encoder side of the transformer because as you can see in the encoder side there is no linear and soft max so mistal is a decoder only model and its very similar if not equal to llama the differences between llama and mistal are highlighted here in red the first difference between llama and mistal is that in the self attention we use the sliding window attention and we still use the group query attention but and also the kv cache for inferencing but this is a rolling buffer kv cache and its actually related to the fact that we are using sliding window attention so later we will see all these concepts and the another difference is that the feed forward layer here instead of using the reu function that we used in um in the vanilla transformer or the zigo function that we us in lama here in mistal we use the ceu function um and the feed forward is one in case of mistal 7b so the first model they released and its it can be eight feed forwards uh networks in parallel with each other which are the experts of this mixture of expert in the case of mral 8x 7b um we will see later how it works so for now you just need to understand that mistal is made up of okay the input which are converted into embeddings then we have this block which is repeated n times and we will see that in the case of mistal is repeated 32 times one after another such that the output of each layer is fed to the next layer as input and the output of the last layer is then sent to this rms norm to the linear and to the softmax to produce the output of the model and um this is exactly the same as what we do with any other transformer model usually we have many of this blocks here now in the code of mistal this part here is known as transformer block but its also known as encoder block or decoder block depending on the in the contents of this um block here i will refer to it as an encoder block because if you look at it it looks like exactly as the block of the encoder side so it has a multi header tension od and norm a feed forward and other norm the only difference is that the normalization here comes before the uh the the bl of the feit forward and the self attention okay lets move forward now lets compare the the two models so one is mistal 7b and one in mistal 8x 7b the parameter dim indicates the dimension of the this the dimensions of the embedding vector so how big is the embedding vector so each token is represented by an embedding vector of size 496 dimensions we have 32 of the encoder layers so this block here is repeated 32 times the head dimension indicates as you remember in the multiad attention we have um each head is watching the entire sentence but only a part of the embedding of each token and this indicates how much how many dimensions each head will attend to in each um for in the multiad attention and the hidden dimension here indicates the hidden dimension of the feed forward layer so if the in the case of the fit forward layer we have two linear layers one that converts the the dimension of the embedding vector into the hidden size then another one that converts the hidden size back into the embedding vector dimensions so in the case of the mistal they are using as a hidden size 14336 usually this is a multiple of the dimension and it looks like its 35 the dimension here the number of heads of attention for the query is 32 two while the number of heads for the k and v so the key and values is eight and they are not equal because of the grouped query attention so if you remember from my previous video on lama in which we talk about the group query attention um in the very sim'}]
    cuda memory allocated: 15.54 GB, cuda memory cached: 16.37 GB
Processing: mlops_llm_eval
    Tokens: 7783
    Decoding took: 58.469 seconds
    Messages: [{'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hello guys welcome back to my channel today we are going to talk about mistral so as you know mistral is a new language model that came out a few months ago from mistal ai which is a one of the hottest startup right now in europe for language models it also became a unicorn recently and we will exploring both the models they released one is the 7 billion and one is the 8 by7 billion model so lets review the topics of today the first thing i will introduce you is the architectural differences between the vanilla transformer and the architecture of mistal later we will see what is the sliding window attention and how it is related to the concept of receptive field a concept that usually we find in convolutional neural networks i will briefly review the kv cache because i want to introduce the concept of rolling buffer cache and also how it is done with prefilling and chunking uh we will see what is sparse mixture of experts model sharding with a little with a very brief introduction with the pipeline parallelism and last but not least we will also go through the code of mistal because there is a lot of innovations in the code especially when they use the x forers library with the block attention so i want to guide you into understanding the code because it can be really hard for beginners to understand and find thems around there are some topics that are related to mistal but will not be covered in this current video because i already covered them in my previous video about llama and in particular i will not be talking about the rms normalization the rotary positional encoding and the group query attention because i already um teach them in depth in my previous video on llama so if you want to know about them please watch my previous video on llama another the only prerequisite that i hope you have before watching this video because the topics we are going to touch are quite advanced is that you are familiar with the transformer model so if youre not familiar with the transformer model and the attention mechanism in particular and in particular the self attention mechanism please go watch my video on the transformer in which i teach all this concept very thoroughly very in detail these are really a prerequisite for watching this video because the top the topics here are quite advanced okay lets proceed further so lets watch the differences between the vanilla transformer and mistal at the architecture level as you can see from the um image here which i built by myself using the code because they didnt release any architecture picture in the paper u the architecture of mistal first of all lets talk about some terminology when you have a model like this made up of many encoder layers plus linear and the soft max we are talking about a decoder only model because this part this model here looks like the decoder of the vanilla transformer you can see here except for the cross attention because as you can see here there is no cross attention when we have a model without the linear and the softmax we call it an incoder only model for example bir is an encoder only model because birth has some heads at at the end which is one or more linear layers depending on the application but it self birth doesnt need a head because it can be used for multiple downstream tasks so its called an encoder only model because it resembles the encoder side of the transformer because as you can see in the encoder side there is no linear and soft max so mistal is a decoder only model and its very similar if not equal to llama the differences between llama and mistal are highlighted here in red the first difference between llama and mistal is that in the self attention we use the sliding window attention and we still use the group query attention but and also the kv cache for inferencing but this is a rolling buffer kv cache and its actually related to the fact that we are using sliding window attention so later we will see all these concepts and the another difference is that the feed forward layer here instead of using the reu function that we used in um in the vanilla transformer or the zigo function that we us in lama here in mistal we use the ceu function um and the feed forward is one in case of mistal 7b so the first model they released and its it can be eight feed forwards uh networks in parallel with each other which are the experts of this mixture of expert in the case of mral 8x 7b um we will see later how it works so for now you just need to understand that mistal is made up of okay the input which are converted into embeddings then we have this block which is repeated n times and we will see that in the case of mistal is repeated 32 times one after another such that the output of each layer is fed to the next layer as input and the output of the last layer is then sent to this rms norm to the linear and to the softmax to produce the output of the model and um this is exactly the same as what we do with any other transformer model usually we have many of this blocks here now in the code of mistal this part here is known as transformer block but its also known as encoder block or decoder block depending on the in the contents of this um block here i will refer to it as an encoder block because if you look at it it looks like exactly as the block of the encoder side so it has a multi header tension od and norm a feed forward and other norm the only difference is that the normalization here comes before the uh the the bl of the feit forward and the self attention okay lets move forward now lets compare the the two models so one is mistal 7b and one in mistal 8x 7b the parameter dim indicates the dimension of the this the dimensions of the embedding vector so how big is the embedding vector so each token is represented by an embedding vector of size 496 dimensions we have 32 of the encoder layers so this block here is repeated 32 times the head dimension indicates as you remember in the multiad attention we have um each head is watching the entire sentence but only a part of the embedding of each token and this indicates how much how many dimensions each head will attend to in each um for in the multiad attention and the hidden dimension here indicates the hidden dimension of the feed forward layer so if the in the case of the fit forward layer we have two linear layers one that converts the the dimension of the embedding vector into the hidden size then another one that converts the hidden size back into the embedding vector dimensions so in the case of the mistal they are using as a hidden size 14336 usually this is a multiple of the dimension and it looks like its 35 the dimension here the number of heads of attention for the query is 32 two while the number of heads for the k and v so the key and values is eight and they are not equal because of the grouped query attention so if you remember from my previous video on lama in which we talk about the group query attention um in the very sim'}, {'role': 'assistant', 'content': '{\n  "introduction": "This video provides an in-depth analysis and tutorial on Mistral, a new language model developed by Mistral AI, a leading European startup in the language model space. The presenter delves into the architectural nuances of Mistral compared to traditional transformers, explores advanced concepts like sliding window attention, the use of a rolling buffer KV cache, sparse mixture of experts model, and the intricacies of coding with the Xformers library for block attention.",\n  "sections": [\n    {\n      "title": "Section 1: Architectural Overview",\n      "content": [\n        "Comparison between Mistral and vanilla transformer models.",\n        "Introduction to decoder-only models and their relevance to Mistral.",\n        "Key architectural differences highlighted, including attention mechanisms and feedforward layers.",\n        "Exploration of the sliding window attention mechanism."\n      ],\n      "topics": ["Transformer Architecture", "Decoder Models", "Sliding Window Attention"]\n    },\n    {\n      "title": "Section 2: Advanced Attention Mechanisms",\n      "content": [\n        "Deep dive into sliding window attention and its computational benefits.",\n        "Discussion on the concept of receptive fields and their analogy in CNNs.",\n        "Introduction to rolling buffer KV cache for efficient memory usage.",\n        "Explanation of chunking and pre-filling techniques for optimized processing."\n      ],\n      "topics": ["Sliding Window Attention", "Receptive Fields", "KV Cache"]\n    },\n    {\n      "title": "Section 3: Sparse Mixture of Experts",\n      "content": [\n        "Introduction to the concept of sparse mixture of experts and its implementation in Mistral.",\n        "Discussion on model sharding and pipeline parallelism for scaling models.",\n        "The significance of selecting experts based on token processing.",\n        "Efficiency gains from using sparse models in terms of computation and specialization."\n      ],\n      "topics": ["Sparse Mixture of Experts", "Model Sharding", "Pipeline Parallelism"]\n    },\n    {\n      "title": "Section 4: Code Innovations",\n      "content": [\n        "Overview of code-level innovations in Mistral, focusing on the Xformers library.",\n        "Explanation of block attention techniques for handling variable-length prompts.",\n        "Strategies for managing KV caches and attention masks in code.",\n        "Insights into the development challenges and solutions for optimizing language model inference."\n      ],\n      "topics": ["Xformers Library", "Block Attention", "Code Optimization"]\n    },\n    {\n      "title": "Section 5: Practical Applications and Coding Tutorial",\n      "content": [\n        "Step-by-step coding tutorial for implementing Mistral features.",\n        "Examples of practical applications and the benefits of Mistral\'s architecture.",\n        "Discussion on the importance of understanding transformer models as a prerequisite.",\n        "Guidance on navigating and understanding the Mistral codebase for developers."\n      ],\n      "topics": ["Coding Tutorial", "Practical Applications", "Understanding Transformers"]\n    }\n  ],\n  "topics": ["Transformer Architecture", "Sliding Window Attention", "Sparse Mixture of Experts", "Code Optimization", "Practical Applications"],\n  "General Topics": [\n    {"topic": "Artificial Intelligence (AI) and Machine Learning", "complexity": 0.89},\n    {"topic": "Software Engineering and System Design", "complexity": 0.75},\n    {"topic": "Programming Languages and Software Development", "complexity": 0.66}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.whats up guys back today with another longer video which is to build a job board app that could actually be a real startup that people use theres a lot of different places to find entry level or junior developer jobs on the internet for example github jobs stack overflow jobs you have angel list you have indeed but filtering through those especially because you kind of have to spam applications for your first job can take a long time so the good thing about all these job boards is they have public apis for the most part you always want to start with an mvp that is the minimum viable product today that means were going to start with a single data feed that is a single job board api feeding into our app and then finally were gonna have a super minimal simple front end were gonna do this in react and material ui on the front end were gonna use an express server redis for our data storage because were not writing or persisting any data that is not part of the job feed and then finally a node cron job to fetch these jobs and refresh them at a certain interval which are going to be filtered through an algorithm so lets draw this all out to get a better idea of our plan heres our front end what we basically want here is a list of jobs this is going to be pulling data from our api and that will be express and then this will pull from our store which is actually going to be redis and redis will be populated by our cron called a worker which is pulling from music one or more apis its going to be eventually multiple this is going to be job uh board apis so like in lets say indeed we have github we have stack jobs and this is going to be filtered through our algorithm were filtering down the jobs getting rid of the senior jobs getting rid of the manager jobs and eventually when we make it more complicated we could even look through the description for years of experience and create uh search indexes and different things like that but again the minimum is just going to be pulling the jobs in and filtering them down okay so this is our plan lets start with the front end i know a lot of you guys like react and its gonna actually be super simple lets just do a create react app to get started uh i already have a folder our directory here called junior dev so lets uh do a create react app and then call it client you guys know that i love material ui so lets install that as well once we get into our client and lets do yarn add okay thats done and we will start our react at okay lets go through the stuff we can actually delete no tests you always want to write tests in real life but not today logo and also clear this out here now lets open the material ui docs lets get our component api and lets get a title for our page typography h1 lets just copy this and instead of putting it directly in app lets make a new component for jobs and then lets make a new component for a single job all job which well use in jobs and then lets import react exports default functions okay in this we will use typography okay so just to explain what im doing here i am making a separate component because i want our app just to hold our state and then jobs will actually hold our component tree our render styling and app will hold our application state our use state and call our hooks for kubota did mount and for state that was really confusing sorry were using typography here and lets do variant typography variant okay im naming our page entry level software jobs i think its a good name then save import jobs throw that in there like this okay that is some huge text but were gonna leave it for now within jobs we already know were gonna um import job make this a similar export well just copy this whole thing almost sneezed okay turn div and then this will just be a single job row which will put on a class name of a single job and then well just do this in advance because we know were going to eventually have to write some css to style this stuff lets make a job list should probably actually be matching our component name just to change that back jobs and then job okay so lets just say that were passing down some props for all our jobs from our uh app which is holding our state lets just do it like this and lets do some mock json that we might return from our api swe software engineer one and company google um theres gonna be a bunch of fields but lets just leave them like that for now and my mock job so we dont get it mixed up mock just being mock json data and it should work then we can do jobs map job this will return a job job job equals job hopefully thats not too confusing okay now you could just hear the structure job in the box but jobtitle lets see if this works there it is jobtitle and jobcompany and lets actually add some css for job and just make it a display flex next direction oh thats right its always freaking hard switching from jsx to javascript okay there we go boom ill leave it like that for now we can add more stuff to this this list if we want like this facebook apple itll map it out for us lets give that a little bit of margin a little bit of padding lets do a 10 pixel top left right zero and then padding will be the same okay not too bad not too bad so our front end we could call this like kind of done lets call this done for now and lets return to it after doing some full stack stuff so im gonna collapse our client lets see what our actual data feed is gonna look like coming from uh our source which im just gonna use as github jobs because i know that has a really good clean api output that you dont need a key for or anything so api github jobs open it up you can see some examples here okay so it says that the api supports pagination itll return 50 at a time and you could do it by adding a parameter to your queries before jumping ahead we just know we want these json representation of these jobs so we can manipulate it with our node worker so what im actually going to do is call a similar url like this in our node side which is going to give us output like this just by eyeballing this i could see that it is somewhat matching what we already wrote out here in appjs where theres a title somewhere yes like that senior full stack nodejs developer and there is a company somewhere and we can also tell in advance that locations going to be an important field too but basing our analysis on this we could start to model kind of what our worker is going to do as well as how we want our api to act as well so looking back at our plan lets actually just make a folder for uh all our boxes here so this is the client right api is going to be simplexpress server and then the worker is going to have our algorithm and its going to be calling our apis on a cron job which is at a set interval so maybe every hour in the day we want to refresh these apis refresh our redis and make sure that everything is up to date theres no expired jobs that the companies dont want people to see anymore and were basically staying i'}, {'role': 'assistant', 'content': '{\n  "introduction": "The video tutorial demonstrates the process of building a job board app from scratch, intended to serve as a real startup platform for entry-level or junior developer positions. It covers the app\'s development from conceptualization to deployment, utilizing various technologies and programming languages.",\n  "sections": [\n    {\n      "title": "Section 1: Project Initialization and MVP",\n      "content": [\n        "Introduction to the project\'s goal of simplifying the job search for entry-level developer positions.",\n        "Decision to start with a single data feed using a job board API.",\n        "Explanation of the Minimum Viable Product (MVP) concept.",\n        "Initial setup of the project using React for the frontend and Express server."\n      ],\n      "topics": ["MVP Concept", "API Integration", "React"]\n    },\n    {\n      "title": "Section 2: Backend Development",\n      "content": [\n        "Setup of the Express server and Redis for data storage.",\n        "Implementation of a Node cron job to fetch and refresh job listings.",\n        "Discussion on filtering algorithms to refine job search results.",\n        "Detailed walkthrough of backend code, including async functions and API fetching."\n      ],\n      "topics": ["Express Server", "Redis", "Node Cron Job"]\n    },\n    {\n      "title": "Section 3: Frontend Development",\n      "content": [\n        "Initial setup of React components for job listings.",\n        "Introduction to Material UI for styling the frontend.",\n        "Development of a simple, user-friendly interface.",\n        "Incorporation of job filtering and pagination on the frontend."\n      ],\n      "topics": ["React Components", "Material UI", "Pagination"]\n    },\n    {\n      "title": "Section 4: Data Filtering and Algorithm",\n      "content": [\n        "Explanation of the algorithm to filter out non-entry level jobs.",\n        "Use of string methods to identify relevant job listings.",\n        "Adjustments to the algorithm for improved accuracy.",\n        "Testing and refining the filtering process."\n      ],\n      "topics": ["Filtering Algorithm", "String Methods", "Algorithm Testing"]\n    },\n    {\n      "title": "Section 5: Deployment",\n      "content": [\n        "Overview of deployment process on a virtual private server.",\n        "Configuration of Nginx and security with SSL certificates.",\n        "Final adjustments for production readiness.",\n        "Live deployment and testing of the job board app."\n      ],\n      "topics": ["Deployment", "Nginx Configuration", "SSL Certificates"]\n    }\n  ],\n  "topics": ["React", "Express Server", "Redis", "Filtering Algorithm", "Deployment"],\n  "General Topics": [\n    {"topic": "Web Development and Internet Technologies", "complexity": 0.45},\n    {"topic": "Software Engineering and System Design", "complexity": 0.65},\n    {"topic": "Data Science and Analytics", "complexity": 0.55}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hold up before we get into this next episode i want to tell you about our virtual conference thats coming up on february 15th and february 22nd we did it two thursdays in a row this year because we wanted to make sure that the maximum amount of people could come for each day since the lineup is just looking absolutely incredible as you know we do let me name a few of the guests that weve got coming because it is worth talking about weve got jason louie weve got shrea shanar weve got dro who is product applied ai at uber weve got cameron wolf whos got an incredible podcast and hes director of ai at reeby engine weve got lauren lockridge who is working at google also doing some product stuff oh why is there so many product people here funny you should ask that because weve got a whole ai product owner track along with an engineering track and then as we like to weve got some handson workshops too let me just tell you some of these other names just for a moment you know because weve got them coming and it is really cool i havent named any of the keynotes yet either by the way go and check them out on your own if you want just go to home ops community and youll see but weve got tunji whos the lead researcher on the deep speed project at microsoft weve got golden who is the open source engineer at netflix weve got kai whos leading the ai platform at uber you may have heard of it its called michelangelo oh my gosh weve got fison whos product manager at linkedin jerry louie who created good old llama index hes coming weve got matt sharp friend of the pod shreya raj paul the creator and ceo of guard rails oh my gosh the list goes on theres 7 plus people that will be with us at this conference so i hope to see you there and now lets get into this podcast hey everyone my name is apara um im one of the cofounders of arise ai um and i recently stopped drinking coffee so i take i ive started on machil lattes instead hello and welcome back to the mops community podcast as always i am your host dimitri o and were coming at you with another fire episode this one was with my good and old friend apara and she has been doing some really cool stuff in the evaluation space most specifically the llm evaluation space we talked all about how they are looking at evaluating the whole llm systems and of course course she comes from the observability space and for those that dont know shes cofounder of arise and arise is doing lots of great stuff in the observability space theyve been doing it since the traditional mlops days and now theyve got this open source package phoenix that is for the new llm days and you can just tell that she has been diving in head first shes chief product officer and she has really been thinking deeply about how to create a product that will help people along their journey when it comes to using llms and really making sure that your llm is useful and not outputting just absolute garbage so we talked at length about evaluating rags not only the rag the part that is the output but also the retrieval piece she also mentioned and she was very bullish on something that a lot of you have probably heard about which is llms as a judge so i really appreciated her take on how you can use llms to evaluate your systems and evaluate the output but then at the very end we got into her hot takes and so definitely stick around for that because she thinks very much on the same lines as i do i dont want to give it away but she came up with some really good stuff when it comes to finetuning and traditional ml and how traditional ml engineers might jump to f tuning but that is all no spoilers here were going to get right into the conversation and ill let you hear it straight from a parta before we do though huge shout out to the arise team for being a sponsor of the mlops community since 2020 theyve been huge supporters and ive got to thank them for it aarta was one of the first people we had on a virtual meetup back when everything was closed in the co era and she came into the community slack was super useful in those early days when we were all trying to figure out how to even think about observability when it relates to ml and so ive got to say huge thanks huge shout out to the arise team check out all the links below if you want to see any of the stuff that we talked about concerning all of the llm observability or just ml observability tools and before we get into the conversation would love it if you share this piece with just one person so that we can keep the good old mlops vibes rolling all right lets get into music it okay so you wanted the story about how i ended up in germany here it is heres the tldr version i was living in spain so i moved to spain in 2010 and i moved there because i met a girl in india and she was in bilbow spain doing her masters she wasnt from she wasnt from india or spain she was from portugal but i was like oh i want to be closer to her and i also want to like live in spain because i enjoyed it i had lived in spain i spoke a little bit of spanish poito and then i was like all right cool lets go over to bill bal uh ive heard good things about the city and the food and the people so i moved there as soon as i got there this girl was like i want nothing to do with you and so i was sitting there like heartbroken on the coastline of the bass country and it took me probably like a month to realize well theres theres much worse places i could be stuck and so i enjoyed it and i had the time in my life that year in bilbo and then i met my wife at the end of that year at this big music festival and uh so we were living in spain we ended up getting married like 5 years later had our first daughter like 8 years later and then we were living there until 2020 when co hit and when co hit the lockdown was really hard and we were in this small apartment in bilb and we were like lets get out of here lets go to the countryside and we had been coming to the german countryside because theres like this meditation retreat center that we go to quite a bit and so we thought you know what lets go there lets see like if theres any places available and we can hang out on the countryside not see anybody the lockdowns werent as strict i mean there were lockdowns and stuff but when youre on the countryside nobodys really enforcing it so we did that and we ended up in the middle of nowhere germany with you know 100 cows and maybe like 50 people in the village that were in so thats the short story of it wow w well thats an interesting intro there you go i mean we were just talking and i will mention this to the listeners because we were talking about how you moved from california to new york and you are freezing right now because it is currently winter there and germany isnt known for its incredible weather but its definitely not like new york that is for sure yeah its a east coast winter out here so i wanted to jump in to the evaluation space because i know youve been kne deep in t'}]
    cuda memory allocated: 15.54 GB, cuda memory cached: 16.37 GB
Processing: react_svelte
    Tokens: 7586
    Decoding took: 37.535 seconds
    Messages: [{'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hello guys welcome back to my channel today we are going to talk about mistral so as you know mistral is a new language model that came out a few months ago from mistal ai which is a one of the hottest startup right now in europe for language models it also became a unicorn recently and we will exploring both the models they released one is the 7 billion and one is the 8 by7 billion model so lets review the topics of today the first thing i will introduce you is the architectural differences between the vanilla transformer and the architecture of mistal later we will see what is the sliding window attention and how it is related to the concept of receptive field a concept that usually we find in convolutional neural networks i will briefly review the kv cache because i want to introduce the concept of rolling buffer cache and also how it is done with prefilling and chunking uh we will see what is sparse mixture of experts model sharding with a little with a very brief introduction with the pipeline parallelism and last but not least we will also go through the code of mistal because there is a lot of innovations in the code especially when they use the x forers library with the block attention so i want to guide you into understanding the code because it can be really hard for beginners to understand and find thems around there are some topics that are related to mistal but will not be covered in this current video because i already covered them in my previous video about llama and in particular i will not be talking about the rms normalization the rotary positional encoding and the group query attention because i already um teach them in depth in my previous video on llama so if you want to know about them please watch my previous video on llama another the only prerequisite that i hope you have before watching this video because the topics we are going to touch are quite advanced is that you are familiar with the transformer model so if youre not familiar with the transformer model and the attention mechanism in particular and in particular the self attention mechanism please go watch my video on the transformer in which i teach all this concept very thoroughly very in detail these are really a prerequisite for watching this video because the top the topics here are quite advanced okay lets proceed further so lets watch the differences between the vanilla transformer and mistal at the architecture level as you can see from the um image here which i built by myself using the code because they didnt release any architecture picture in the paper u the architecture of mistal first of all lets talk about some terminology when you have a model like this made up of many encoder layers plus linear and the soft max we are talking about a decoder only model because this part this model here looks like the decoder of the vanilla transformer you can see here except for the cross attention because as you can see here there is no cross attention when we have a model without the linear and the softmax we call it an incoder only model for example bir is an encoder only model because birth has some heads at at the end which is one or more linear layers depending on the application but it self birth doesnt need a head because it can be used for multiple downstream tasks so its called an encoder only model because it resembles the encoder side of the transformer because as you can see in the encoder side there is no linear and soft max so mistal is a decoder only model and its very similar if not equal to llama the differences between llama and mistal are highlighted here in red the first difference between llama and mistal is that in the self attention we use the sliding window attention and we still use the group query attention but and also the kv cache for inferencing but this is a rolling buffer kv cache and its actually related to the fact that we are using sliding window attention so later we will see all these concepts and the another difference is that the feed forward layer here instead of using the reu function that we used in um in the vanilla transformer or the zigo function that we us in lama here in mistal we use the ceu function um and the feed forward is one in case of mistal 7b so the first model they released and its it can be eight feed forwards uh networks in parallel with each other which are the experts of this mixture of expert in the case of mral 8x 7b um we will see later how it works so for now you just need to understand that mistal is made up of okay the input which are converted into embeddings then we have this block which is repeated n times and we will see that in the case of mistal is repeated 32 times one after another such that the output of each layer is fed to the next layer as input and the output of the last layer is then sent to this rms norm to the linear and to the softmax to produce the output of the model and um this is exactly the same as what we do with any other transformer model usually we have many of this blocks here now in the code of mistal this part here is known as transformer block but its also known as encoder block or decoder block depending on the in the contents of this um block here i will refer to it as an encoder block because if you look at it it looks like exactly as the block of the encoder side so it has a multi header tension od and norm a feed forward and other norm the only difference is that the normalization here comes before the uh the the bl of the feit forward and the self attention okay lets move forward now lets compare the the two models so one is mistal 7b and one in mistal 8x 7b the parameter dim indicates the dimension of the this the dimensions of the embedding vector so how big is the embedding vector so each token is represented by an embedding vector of size 496 dimensions we have 32 of the encoder layers so this block here is repeated 32 times the head dimension indicates as you remember in the multiad attention we have um each head is watching the entire sentence but only a part of the embedding of each token and this indicates how much how many dimensions each head will attend to in each um for in the multiad attention and the hidden dimension here indicates the hidden dimension of the feed forward layer so if the in the case of the fit forward layer we have two linear layers one that converts the the dimension of the embedding vector into the hidden size then another one that converts the hidden size back into the embedding vector dimensions so in the case of the mistal they are using as a hidden size 14336 usually this is a multiple of the dimension and it looks like its 35 the dimension here the number of heads of attention for the query is 32 two while the number of heads for the k and v so the key and values is eight and they are not equal because of the grouped query attention so if you remember from my previous video on lama in which we talk about the group query attention um in the very sim'}, {'role': 'assistant', 'content': '{\n  "introduction": "This video provides an in-depth analysis and tutorial on Mistral, a new language model developed by Mistral AI, a leading European startup in the language model space. The presenter delves into the architectural nuances of Mistral compared to traditional transformers, explores advanced concepts like sliding window attention, the use of a rolling buffer KV cache, sparse mixture of experts model, and the intricacies of coding with the Xformers library for block attention.",\n  "sections": [\n    {\n      "title": "Section 1: Architectural Overview",\n      "content": [\n        "Comparison between Mistral and vanilla transformer models.",\n        "Introduction to decoder-only models and their relevance to Mistral.",\n        "Key architectural differences highlighted, including attention mechanisms and feedforward layers.",\n        "Exploration of the sliding window attention mechanism."\n      ],\n      "topics": ["Transformer Architecture", "Decoder Models", "Sliding Window Attention"]\n    },\n    {\n      "title": "Section 2: Advanced Attention Mechanisms",\n      "content": [\n        "Deep dive into sliding window attention and its computational benefits.",\n        "Discussion on the concept of receptive fields and their analogy in CNNs.",\n        "Introduction to rolling buffer KV cache for efficient memory usage.",\n        "Explanation of chunking and pre-filling techniques for optimized processing."\n      ],\n      "topics": ["Sliding Window Attention", "Receptive Fields", "KV Cache"]\n    },\n    {\n      "title": "Section 3: Sparse Mixture of Experts",\n      "content": [\n        "Introduction to the concept of sparse mixture of experts and its implementation in Mistral.",\n        "Discussion on model sharding and pipeline parallelism for scaling models.",\n        "The significance of selecting experts based on token processing.",\n        "Efficiency gains from using sparse models in terms of computation and specialization."\n      ],\n      "topics": ["Sparse Mixture of Experts", "Model Sharding", "Pipeline Parallelism"]\n    },\n    {\n      "title": "Section 4: Code Innovations",\n      "content": [\n        "Overview of code-level innovations in Mistral, focusing on the Xformers library.",\n        "Explanation of block attention techniques for handling variable-length prompts.",\n        "Strategies for managing KV caches and attention masks in code.",\n        "Insights into the development challenges and solutions for optimizing language model inference."\n      ],\n      "topics": ["Xformers Library", "Block Attention", "Code Optimization"]\n    },\n    {\n      "title": "Section 5: Practical Applications and Coding Tutorial",\n      "content": [\n        "Step-by-step coding tutorial for implementing Mistral features.",\n        "Examples of practical applications and the benefits of Mistral\'s architecture.",\n        "Discussion on the importance of understanding transformer models as a prerequisite.",\n        "Guidance on navigating and understanding the Mistral codebase for developers."\n      ],\n      "topics": ["Coding Tutorial", "Practical Applications", "Understanding Transformers"]\n    }\n  ],\n  "topics": ["Transformer Architecture", "Sliding Window Attention", "Sparse Mixture of Experts", "Code Optimization", "Practical Applications"],\n  "General Topics": [\n    {"topic": "Artificial Intelligence (AI) and Machine Learning", "complexity": 0.89},\n    {"topic": "Software Engineering and System Design", "complexity": 0.75},\n    {"topic": "Programming Languages and Software Development", "complexity": 0.66}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.whats up guys back today with another longer video which is to build a job board app that could actually be a real startup that people use theres a lot of different places to find entry level or junior developer jobs on the internet for example github jobs stack overflow jobs you have angel list you have indeed but filtering through those especially because you kind of have to spam applications for your first job can take a long time so the good thing about all these job boards is they have public apis for the most part you always want to start with an mvp that is the minimum viable product today that means were going to start with a single data feed that is a single job board api feeding into our app and then finally were gonna have a super minimal simple front end were gonna do this in react and material ui on the front end were gonna use an express server redis for our data storage because were not writing or persisting any data that is not part of the job feed and then finally a node cron job to fetch these jobs and refresh them at a certain interval which are going to be filtered through an algorithm so lets draw this all out to get a better idea of our plan heres our front end what we basically want here is a list of jobs this is going to be pulling data from our api and that will be express and then this will pull from our store which is actually going to be redis and redis will be populated by our cron called a worker which is pulling from music one or more apis its going to be eventually multiple this is going to be job uh board apis so like in lets say indeed we have github we have stack jobs and this is going to be filtered through our algorithm were filtering down the jobs getting rid of the senior jobs getting rid of the manager jobs and eventually when we make it more complicated we could even look through the description for years of experience and create uh search indexes and different things like that but again the minimum is just going to be pulling the jobs in and filtering them down okay so this is our plan lets start with the front end i know a lot of you guys like react and its gonna actually be super simple lets just do a create react app to get started uh i already have a folder our directory here called junior dev so lets uh do a create react app and then call it client you guys know that i love material ui so lets install that as well once we get into our client and lets do yarn add okay thats done and we will start our react at okay lets go through the stuff we can actually delete no tests you always want to write tests in real life but not today logo and also clear this out here now lets open the material ui docs lets get our component api and lets get a title for our page typography h1 lets just copy this and instead of putting it directly in app lets make a new component for jobs and then lets make a new component for a single job all job which well use in jobs and then lets import react exports default functions okay in this we will use typography okay so just to explain what im doing here i am making a separate component because i want our app just to hold our state and then jobs will actually hold our component tree our render styling and app will hold our application state our use state and call our hooks for kubota did mount and for state that was really confusing sorry were using typography here and lets do variant typography variant okay im naming our page entry level software jobs i think its a good name then save import jobs throw that in there like this okay that is some huge text but were gonna leave it for now within jobs we already know were gonna um import job make this a similar export well just copy this whole thing almost sneezed okay turn div and then this will just be a single job row which will put on a class name of a single job and then well just do this in advance because we know were going to eventually have to write some css to style this stuff lets make a job list should probably actually be matching our component name just to change that back jobs and then job okay so lets just say that were passing down some props for all our jobs from our uh app which is holding our state lets just do it like this and lets do some mock json that we might return from our api swe software engineer one and company google um theres gonna be a bunch of fields but lets just leave them like that for now and my mock job so we dont get it mixed up mock just being mock json data and it should work then we can do jobs map job this will return a job job job equals job hopefully thats not too confusing okay now you could just hear the structure job in the box but jobtitle lets see if this works there it is jobtitle and jobcompany and lets actually add some css for job and just make it a display flex next direction oh thats right its always freaking hard switching from jsx to javascript okay there we go boom ill leave it like that for now we can add more stuff to this this list if we want like this facebook apple itll map it out for us lets give that a little bit of margin a little bit of padding lets do a 10 pixel top left right zero and then padding will be the same okay not too bad not too bad so our front end we could call this like kind of done lets call this done for now and lets return to it after doing some full stack stuff so im gonna collapse our client lets see what our actual data feed is gonna look like coming from uh our source which im just gonna use as github jobs because i know that has a really good clean api output that you dont need a key for or anything so api github jobs open it up you can see some examples here okay so it says that the api supports pagination itll return 50 at a time and you could do it by adding a parameter to your queries before jumping ahead we just know we want these json representation of these jobs so we can manipulate it with our node worker so what im actually going to do is call a similar url like this in our node side which is going to give us output like this just by eyeballing this i could see that it is somewhat matching what we already wrote out here in appjs where theres a title somewhere yes like that senior full stack nodejs developer and there is a company somewhere and we can also tell in advance that locations going to be an important field too but basing our analysis on this we could start to model kind of what our worker is going to do as well as how we want our api to act as well so looking back at our plan lets actually just make a folder for uh all our boxes here so this is the client right api is going to be simplexpress server and then the worker is going to have our algorithm and its going to be calling our apis on a cron job which is at a set interval so maybe every hour in the day we want to refresh these apis refresh our redis and make sure that everything is up to date theres no expired jobs that the companies dont want people to see anymore and were basically staying i'}, {'role': 'assistant', 'content': '{\n  "introduction": "The video tutorial demonstrates the process of building a job board app from scratch, intended to serve as a real startup platform for entry-level or junior developer positions. It covers the app\'s development from conceptualization to deployment, utilizing various technologies and programming languages.",\n  "sections": [\n    {\n      "title": "Section 1: Project Initialization and MVP",\n      "content": [\n        "Introduction to the project\'s goal of simplifying the job search for entry-level developer positions.",\n        "Decision to start with a single data feed using a job board API.",\n        "Explanation of the Minimum Viable Product (MVP) concept.",\n        "Initial setup of the project using React for the frontend and Express server."\n      ],\n      "topics": ["MVP Concept", "API Integration", "React"]\n    },\n    {\n      "title": "Section 2: Backend Development",\n      "content": [\n        "Setup of the Express server and Redis for data storage.",\n        "Implementation of a Node cron job to fetch and refresh job listings.",\n        "Discussion on filtering algorithms to refine job search results.",\n        "Detailed walkthrough of backend code, including async functions and API fetching."\n      ],\n      "topics": ["Express Server", "Redis", "Node Cron Job"]\n    },\n    {\n      "title": "Section 3: Frontend Development",\n      "content": [\n        "Initial setup of React components for job listings.",\n        "Introduction to Material UI for styling the frontend.",\n        "Development of a simple, user-friendly interface.",\n        "Incorporation of job filtering and pagination on the frontend."\n      ],\n      "topics": ["React Components", "Material UI", "Pagination"]\n    },\n    {\n      "title": "Section 4: Data Filtering and Algorithm",\n      "content": [\n        "Explanation of the algorithm to filter out non-entry level jobs.",\n        "Use of string methods to identify relevant job listings.",\n        "Adjustments to the algorithm for improved accuracy.",\n        "Testing and refining the filtering process."\n      ],\n      "topics": ["Filtering Algorithm", "String Methods", "Algorithm Testing"]\n    },\n    {\n      "title": "Section 5: Deployment",\n      "content": [\n        "Overview of deployment process on a virtual private server.",\n        "Configuration of Nginx and security with SSL certificates.",\n        "Final adjustments for production readiness.",\n        "Live deployment and testing of the job board app."\n      ],\n      "topics": ["Deployment", "Nginx Configuration", "SSL Certificates"]\n    }\n  ],\n  "topics": ["React", "Express Server", "Redis", "Filtering Algorithm", "Deployment"],\n  "General Topics": [\n    {"topic": "Web Development and Internet Technologies", "complexity": 0.45},\n    {"topic": "Software Engineering and System Design", "complexity": 0.65},\n    {"topic": "Data Science and Analytics", "complexity": 0.55}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.any reasonable developer in todays world would learn react because its the status quo and thats where the jobs are but life is a lot more fun when you become unreasonable and go against the status quo to push web development forward for future generations in todays video well compare react and spelled side by side by looking at common patterns and design choices by the framework creators im not here to tell you that one is better than the other because thats what the comment section below this video is for the only way to truly find out which one is best is to build something with both of them and decide for yourself i just released a brand new full spell kick course yesterday and also have a full next js13 course for fireship pro members going through each one of these courses will give you a really good idea of which framework is best for you first up we need to talk about rendering both of these frameworks do the same thing they help developers build reactive uis with javascript by organizing code into reusable components an end user would never be able to tell the difference between the two but when it comes to the developer experience there is a world of difference reactjs uses a runtime called the virtual dom it keeps track of data changes in the application in order to render them in the act actual dom in the browser the drawback is that this runtime requires some initial javascript and in frameworks like nextjs your baseline is around 70 kilobytes just to render a hello world as felt on the other hand takes an entirely different approach using a compiler to eliminate the need for a runtime it takes your svelt code and converts it into vanilla javascript which results in a far smaller hello world using a compiler though is kind of like cheating reactjs is just javascript whereas spill can take nonjavascript code to allow developers to do things more efficiently than they could otherwise but some javascript fundamentalists might consider this black magic whats ironic though is that vanilla javascript libraries tend to be much easier to work with in spell when compared to react however react does have a massive ecosystem of dedicated libraries to help you get things done now lets look at an actual code example of component state here we have a basic counter app in react we use functions to create components and then add reactive state to them with the use state hook that returns a reactive value and a setter function to update the state pretty simple but lets see how it compares to svelt here on the right side in spelled you have only one component file and define the logic within the script tags to create reactive state all you do is create a variable with the let keyword from there we can define a function on the click event that mutates the value directly the spell code is able to be more concise because it doesnt require any imports or function calls to initialize the state it looks and feels like vanilla javascript but thats just an illusion so now lets look at how props work between the two frameworks to pass props and react we do so by defining them as function arguments which are typically destructured like so in spell things look a lot different putting the export keyword in front of a variable allows it to be passed in from the outside on the other side using props looks basically identical in both frameworks although spelled does use some syntactic sugar allowing you to more easily match variable names to props when it comes to props though one thing you can do in react that you cant do in svelte is pass components as props and that brings us to our next comparison children in react because we can pass components as props we can render them directly in the jsx in addition if we want to insert ui inside of a component we can use the builtin propschildren value you now in smelt we have an entirely different system called slots the default slot is the equivalent to propschildren however you can also create name slots that allow you to insert ui at specific points in this components markup that gets the job done but i do kind of miss the ability to use components as props and so now lets look at how we might run code when a component is initialized in react we have the use effect hook which takes a callback function followed by an empty array to signify that it doesnt have any dependent data so it only runs once in svelte we have a similar pattern with the on mount function its more readable but more importantly it can handle an async function which is not possible in react which means you need to jump through this extra hoop of defining your own async function thats separate from the main callback but now were going to see a much bigger divergence between these two frameworks with side effects and computed state in react we can create a side effect with the use effect hook again that updates the document title anytime the count changes we just need to tell it to watch the count by putting it in the dependencies array in svelte we have an entirely different mechanism called reactive declarations that start with a dollar sign and a colon this looks kind of weird at first but what it telespell to do is rerun the code whenever any dependent data changes in this case the compiler knows that this code is dependent on the count value therefore it updates the document title whenever the value changes not only is it more concise but it also tends to be more reliable than react because its easy to screw up the dependencies array and get unexpected results that are hard to debug thats just one of the reasons they call it useful gun but we can also use reactive declarations for computed state in react you can easily create computed state by simply defining a variable thats dependent on some state the problem is that this code will run every time this component is rerendered therefore if you have an expensive computation youll need to wrap this code and use memo and once again tell it explicitly which data it depends on this will cache or memorize the value between renders in svelt you dont even have to memorize the word memoize we can just use the same reactive declaration as before to define a new variable again it automatically knows to only run this code when the count changes thats pretty cool but now lets look at some differences in templating starting with conditional logic react uses jsx where you put your html in your javascript whereas spelled has its own templating approach where you bring javascript into your html jsx is one of reacts great innovations if you like some of the ideas of svelte but dont like its templating system a good alternative is solajs which is kind of like react with a smelt style compiler when it comes to conditional logic and react we cant directly use an if statement because a function component needs to return a javascript expression that represents a single value to represent a basic ifel statement or true false situation we can u'}]
    cuda memory allocated: 15.54 GB, cuda memory cached: 16.37 GB
Processing: react
    Tokens: 6836
    Decoding took: 60.975 seconds
    Messages: [{'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hello guys welcome back to my channel today we are going to talk about mistral so as you know mistral is a new language model that came out a few months ago from mistal ai which is a one of the hottest startup right now in europe for language models it also became a unicorn recently and we will exploring both the models they released one is the 7 billion and one is the 8 by7 billion model so lets review the topics of today the first thing i will introduce you is the architectural differences between the vanilla transformer and the architecture of mistal later we will see what is the sliding window attention and how it is related to the concept of receptive field a concept that usually we find in convolutional neural networks i will briefly review the kv cache because i want to introduce the concept of rolling buffer cache and also how it is done with prefilling and chunking uh we will see what is sparse mixture of experts model sharding with a little with a very brief introduction with the pipeline parallelism and last but not least we will also go through the code of mistal because there is a lot of innovations in the code especially when they use the x forers library with the block attention so i want to guide you into understanding the code because it can be really hard for beginners to understand and find thems around there are some topics that are related to mistal but will not be covered in this current video because i already covered them in my previous video about llama and in particular i will not be talking about the rms normalization the rotary positional encoding and the group query attention because i already um teach them in depth in my previous video on llama so if you want to know about them please watch my previous video on llama another the only prerequisite that i hope you have before watching this video because the topics we are going to touch are quite advanced is that you are familiar with the transformer model so if youre not familiar with the transformer model and the attention mechanism in particular and in particular the self attention mechanism please go watch my video on the transformer in which i teach all this concept very thoroughly very in detail these are really a prerequisite for watching this video because the top the topics here are quite advanced okay lets proceed further so lets watch the differences between the vanilla transformer and mistal at the architecture level as you can see from the um image here which i built by myself using the code because they didnt release any architecture picture in the paper u the architecture of mistal first of all lets talk about some terminology when you have a model like this made up of many encoder layers plus linear and the soft max we are talking about a decoder only model because this part this model here looks like the decoder of the vanilla transformer you can see here except for the cross attention because as you can see here there is no cross attention when we have a model without the linear and the softmax we call it an incoder only model for example bir is an encoder only model because birth has some heads at at the end which is one or more linear layers depending on the application but it self birth doesnt need a head because it can be used for multiple downstream tasks so its called an encoder only model because it resembles the encoder side of the transformer because as you can see in the encoder side there is no linear and soft max so mistal is a decoder only model and its very similar if not equal to llama the differences between llama and mistal are highlighted here in red the first difference between llama and mistal is that in the self attention we use the sliding window attention and we still use the group query attention but and also the kv cache for inferencing but this is a rolling buffer kv cache and its actually related to the fact that we are using sliding window attention so later we will see all these concepts and the another difference is that the feed forward layer here instead of using the reu function that we used in um in the vanilla transformer or the zigo function that we us in lama here in mistal we use the ceu function um and the feed forward is one in case of mistal 7b so the first model they released and its it can be eight feed forwards uh networks in parallel with each other which are the experts of this mixture of expert in the case of mral 8x 7b um we will see later how it works so for now you just need to understand that mistal is made up of okay the input which are converted into embeddings then we have this block which is repeated n times and we will see that in the case of mistal is repeated 32 times one after another such that the output of each layer is fed to the next layer as input and the output of the last layer is then sent to this rms norm to the linear and to the softmax to produce the output of the model and um this is exactly the same as what we do with any other transformer model usually we have many of this blocks here now in the code of mistal this part here is known as transformer block but its also known as encoder block or decoder block depending on the in the contents of this um block here i will refer to it as an encoder block because if you look at it it looks like exactly as the block of the encoder side so it has a multi header tension od and norm a feed forward and other norm the only difference is that the normalization here comes before the uh the the bl of the feit forward and the self attention okay lets move forward now lets compare the the two models so one is mistal 7b and one in mistal 8x 7b the parameter dim indicates the dimension of the this the dimensions of the embedding vector so how big is the embedding vector so each token is represented by an embedding vector of size 496 dimensions we have 32 of the encoder layers so this block here is repeated 32 times the head dimension indicates as you remember in the multiad attention we have um each head is watching the entire sentence but only a part of the embedding of each token and this indicates how much how many dimensions each head will attend to in each um for in the multiad attention and the hidden dimension here indicates the hidden dimension of the feed forward layer so if the in the case of the fit forward layer we have two linear layers one that converts the the dimension of the embedding vector into the hidden size then another one that converts the hidden size back into the embedding vector dimensions so in the case of the mistal they are using as a hidden size 14336 usually this is a multiple of the dimension and it looks like its 35 the dimension here the number of heads of attention for the query is 32 two while the number of heads for the k and v so the key and values is eight and they are not equal because of the grouped query attention so if you remember from my previous video on lama in which we talk about the group query attention um in the very sim'}, {'role': 'assistant', 'content': '{\n  "introduction": "This video provides an in-depth analysis and tutorial on Mistral, a new language model developed by Mistral AI, a leading European startup in the language model space. The presenter delves into the architectural nuances of Mistral compared to traditional transformers, explores advanced concepts like sliding window attention, the use of a rolling buffer KV cache, sparse mixture of experts model, and the intricacies of coding with the Xformers library for block attention.",\n  "sections": [\n    {\n      "title": "Section 1: Architectural Overview",\n      "content": [\n        "Comparison between Mistral and vanilla transformer models.",\n        "Introduction to decoder-only models and their relevance to Mistral.",\n        "Key architectural differences highlighted, including attention mechanisms and feedforward layers.",\n        "Exploration of the sliding window attention mechanism."\n      ],\n      "topics": ["Transformer Architecture", "Decoder Models", "Sliding Window Attention"]\n    },\n    {\n      "title": "Section 2: Advanced Attention Mechanisms",\n      "content": [\n        "Deep dive into sliding window attention and its computational benefits.",\n        "Discussion on the concept of receptive fields and their analogy in CNNs.",\n        "Introduction to rolling buffer KV cache for efficient memory usage.",\n        "Explanation of chunking and pre-filling techniques for optimized processing."\n      ],\n      "topics": ["Sliding Window Attention", "Receptive Fields", "KV Cache"]\n    },\n    {\n      "title": "Section 3: Sparse Mixture of Experts",\n      "content": [\n        "Introduction to the concept of sparse mixture of experts and its implementation in Mistral.",\n        "Discussion on model sharding and pipeline parallelism for scaling models.",\n        "The significance of selecting experts based on token processing.",\n        "Efficiency gains from using sparse models in terms of computation and specialization."\n      ],\n      "topics": ["Sparse Mixture of Experts", "Model Sharding", "Pipeline Parallelism"]\n    },\n    {\n      "title": "Section 4: Code Innovations",\n      "content": [\n        "Overview of code-level innovations in Mistral, focusing on the Xformers library.",\n        "Explanation of block attention techniques for handling variable-length prompts.",\n        "Strategies for managing KV caches and attention masks in code.",\n        "Insights into the development challenges and solutions for optimizing language model inference."\n      ],\n      "topics": ["Xformers Library", "Block Attention", "Code Optimization"]\n    },\n    {\n      "title": "Section 5: Practical Applications and Coding Tutorial",\n      "content": [\n        "Step-by-step coding tutorial for implementing Mistral features.",\n        "Examples of practical applications and the benefits of Mistral\'s architecture.",\n        "Discussion on the importance of understanding transformer models as a prerequisite.",\n        "Guidance on navigating and understanding the Mistral codebase for developers."\n      ],\n      "topics": ["Coding Tutorial", "Practical Applications", "Understanding Transformers"]\n    }\n  ],\n  "topics": ["Transformer Architecture", "Sliding Window Attention", "Sparse Mixture of Experts", "Code Optimization", "Practical Applications"],\n  "General Topics": [\n    {"topic": "Artificial Intelligence (AI) and Machine Learning", "complexity": 0.89},\n    {"topic": "Software Engineering and System Design", "complexity": 0.75},\n    {"topic": "Programming Languages and Software Development", "complexity": 0.66}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.whats up guys back today with another longer video which is to build a job board app that could actually be a real startup that people use theres a lot of different places to find entry level or junior developer jobs on the internet for example github jobs stack overflow jobs you have angel list you have indeed but filtering through those especially because you kind of have to spam applications for your first job can take a long time so the good thing about all these job boards is they have public apis for the most part you always want to start with an mvp that is the minimum viable product today that means were going to start with a single data feed that is a single job board api feeding into our app and then finally were gonna have a super minimal simple front end were gonna do this in react and material ui on the front end were gonna use an express server redis for our data storage because were not writing or persisting any data that is not part of the job feed and then finally a node cron job to fetch these jobs and refresh them at a certain interval which are going to be filtered through an algorithm so lets draw this all out to get a better idea of our plan heres our front end what we basically want here is a list of jobs this is going to be pulling data from our api and that will be express and then this will pull from our store which is actually going to be redis and redis will be populated by our cron called a worker which is pulling from music one or more apis its going to be eventually multiple this is going to be job uh board apis so like in lets say indeed we have github we have stack jobs and this is going to be filtered through our algorithm were filtering down the jobs getting rid of the senior jobs getting rid of the manager jobs and eventually when we make it more complicated we could even look through the description for years of experience and create uh search indexes and different things like that but again the minimum is just going to be pulling the jobs in and filtering them down okay so this is our plan lets start with the front end i know a lot of you guys like react and its gonna actually be super simple lets just do a create react app to get started uh i already have a folder our directory here called junior dev so lets uh do a create react app and then call it client you guys know that i love material ui so lets install that as well once we get into our client and lets do yarn add okay thats done and we will start our react at okay lets go through the stuff we can actually delete no tests you always want to write tests in real life but not today logo and also clear this out here now lets open the material ui docs lets get our component api and lets get a title for our page typography h1 lets just copy this and instead of putting it directly in app lets make a new component for jobs and then lets make a new component for a single job all job which well use in jobs and then lets import react exports default functions okay in this we will use typography okay so just to explain what im doing here i am making a separate component because i want our app just to hold our state and then jobs will actually hold our component tree our render styling and app will hold our application state our use state and call our hooks for kubota did mount and for state that was really confusing sorry were using typography here and lets do variant typography variant okay im naming our page entry level software jobs i think its a good name then save import jobs throw that in there like this okay that is some huge text but were gonna leave it for now within jobs we already know were gonna um import job make this a similar export well just copy this whole thing almost sneezed okay turn div and then this will just be a single job row which will put on a class name of a single job and then well just do this in advance because we know were going to eventually have to write some css to style this stuff lets make a job list should probably actually be matching our component name just to change that back jobs and then job okay so lets just say that were passing down some props for all our jobs from our uh app which is holding our state lets just do it like this and lets do some mock json that we might return from our api swe software engineer one and company google um theres gonna be a bunch of fields but lets just leave them like that for now and my mock job so we dont get it mixed up mock just being mock json data and it should work then we can do jobs map job this will return a job job job equals job hopefully thats not too confusing okay now you could just hear the structure job in the box but jobtitle lets see if this works there it is jobtitle and jobcompany and lets actually add some css for job and just make it a display flex next direction oh thats right its always freaking hard switching from jsx to javascript okay there we go boom ill leave it like that for now we can add more stuff to this this list if we want like this facebook apple itll map it out for us lets give that a little bit of margin a little bit of padding lets do a 10 pixel top left right zero and then padding will be the same okay not too bad not too bad so our front end we could call this like kind of done lets call this done for now and lets return to it after doing some full stack stuff so im gonna collapse our client lets see what our actual data feed is gonna look like coming from uh our source which im just gonna use as github jobs because i know that has a really good clean api output that you dont need a key for or anything so api github jobs open it up you can see some examples here okay so it says that the api supports pagination itll return 50 at a time and you could do it by adding a parameter to your queries before jumping ahead we just know we want these json representation of these jobs so we can manipulate it with our node worker so what im actually going to do is call a similar url like this in our node side which is going to give us output like this just by eyeballing this i could see that it is somewhat matching what we already wrote out here in appjs where theres a title somewhere yes like that senior full stack nodejs developer and there is a company somewhere and we can also tell in advance that locations going to be an important field too but basing our analysis on this we could start to model kind of what our worker is going to do as well as how we want our api to act as well so looking back at our plan lets actually just make a folder for uh all our boxes here so this is the client right api is going to be simplexpress server and then the worker is going to have our algorithm and its going to be calling our apis on a cron job which is at a set interval so maybe every hour in the day we want to refresh these apis refresh our redis and make sure that everything is up to date theres no expired jobs that the companies dont want people to see anymore and were basically staying i'}, {'role': 'assistant', 'content': '{\n  "introduction": "The video tutorial demonstrates the process of building a job board app from scratch, intended to serve as a real startup platform for entry-level or junior developer positions. It covers the app\'s development from conceptualization to deployment, utilizing various technologies and programming languages.",\n  "sections": [\n    {\n      "title": "Section 1: Project Initialization and MVP",\n      "content": [\n        "Introduction to the project\'s goal of simplifying the job search for entry-level developer positions.",\n        "Decision to start with a single data feed using a job board API.",\n        "Explanation of the Minimum Viable Product (MVP) concept.",\n        "Initial setup of the project using React for the frontend and Express server."\n      ],\n      "topics": ["MVP Concept", "API Integration", "React"]\n    },\n    {\n      "title": "Section 2: Backend Development",\n      "content": [\n        "Setup of the Express server and Redis for data storage.",\n        "Implementation of a Node cron job to fetch and refresh job listings.",\n        "Discussion on filtering algorithms to refine job search results.",\n        "Detailed walkthrough of backend code, including async functions and API fetching."\n      ],\n      "topics": ["Express Server", "Redis", "Node Cron Job"]\n    },\n    {\n      "title": "Section 3: Frontend Development",\n      "content": [\n        "Initial setup of React components for job listings.",\n        "Introduction to Material UI for styling the frontend.",\n        "Development of a simple, user-friendly interface.",\n        "Incorporation of job filtering and pagination on the frontend."\n      ],\n      "topics": ["React Components", "Material UI", "Pagination"]\n    },\n    {\n      "title": "Section 4: Data Filtering and Algorithm",\n      "content": [\n        "Explanation of the algorithm to filter out non-entry level jobs.",\n        "Use of string methods to identify relevant job listings.",\n        "Adjustments to the algorithm for improved accuracy.",\n        "Testing and refining the filtering process."\n      ],\n      "topics": ["Filtering Algorithm", "String Methods", "Algorithm Testing"]\n    },\n    {\n      "title": "Section 5: Deployment",\n      "content": [\n        "Overview of deployment process on a virtual private server.",\n        "Configuration of Nginx and security with SSL certificates.",\n        "Final adjustments for production readiness.",\n        "Live deployment and testing of the job board app."\n      ],\n      "topics": ["Deployment", "Nginx Configuration", "SSL Certificates"]\n    }\n  ],\n  "topics": ["React", "Express Server", "Redis", "Filtering Algorithm", "Deployment"],\n  "General Topics": [\n    {"topic": "Web Development and Internet Technologies", "complexity": 0.45},\n    {"topic": "Software Engineering and System Design", "complexity": 0.65},\n    {"topic": "Data Science and Analytics", "complexity": 0.55}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.reactjs a halfbaked functional ui library created at facebook thats used by millions of developers because it has a cool name and logo it was invented by mark zuckerberg in 2013 and that was a big mistake and it was my mistake and im sorry react is simple its just javascript bro and thats why it gives you dozens of weird ways to solve the same problems like functional and classbased components hooks forward ref higher order components mixins render props suspense and so on its credited as the first declarative ui library even though it took most of those ideas from angularjs its killer feature though is the fact that you can write pure functional code that is until you want to do anything useful in which case youll need to write imper functions with state and effects the beauty of this approach is that it makes simple things like reactive state much more complicated than they need to be and thats what makes us feel like real developers use effect is especially fun and was originally going to be called use foot gun because its a great way to introduce infinite loops performance issues and bugs that youll never be able to figure out not to worry though react is always evolving with revolutionary new features to monkey patch all the weirdness nobody saw coming on the previous release now even though it has an extremely high learning curve react is a library and not a framework and that means to build something cool youll need to find and install hundreds of different packages most of which were built by teenagers who stopped maintaining them years ago when they went off to college to learn a real language like c to get started create a new react app then open up google to enter the gates of tutorial hell notice how we start in strict mode thats used to hide baggage from previous versions of the framework i mean library now in the code we pretend were doing functional programming by writing our components as functions classes are also possible but they are literally the double instead we use these hooks everywhere that do the same classes do in a more magical hipstery way templating is handled in jsx its a nonstandard way to write html which allows you to represent the ui entirely in nonportable callback hell now we can all agree to hate css but react will make you hate it even more when you try to style something on your own luckily there are hundreds of css and js libraries working on this problem as we speak the extra complexity is worth it though because react is blazingly fast assuming you implemented all the weird tricks flawlessly life is about suffering its not supposed to be fun like spelt or fast like solid or reliable like angular or all of the above like view the only thing that matters is react is the most popular and that makes it undeniably the best just like microsoft makes the best operating system and mcdonalds makes the best food this has been me destroying my reputation with the react community in 100 seconds react has been the most influential library in front of web development for the last decade nothings perfect but it got to where it is today because it does a lot of things right and for that it deserves our respect thanks for watching and i will see you in the next one '}]
    cuda memory allocated: 15.54 GB, cuda memory cached: 16.37 GB
Processing: rust
    Tokens: 6738
    Decoding took: 41.958 seconds
    Messages: [{'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hello guys welcome back to my channel today we are going to talk about mistral so as you know mistral is a new language model that came out a few months ago from mistal ai which is a one of the hottest startup right now in europe for language models it also became a unicorn recently and we will exploring both the models they released one is the 7 billion and one is the 8 by7 billion model so lets review the topics of today the first thing i will introduce you is the architectural differences between the vanilla transformer and the architecture of mistal later we will see what is the sliding window attention and how it is related to the concept of receptive field a concept that usually we find in convolutional neural networks i will briefly review the kv cache because i want to introduce the concept of rolling buffer cache and also how it is done with prefilling and chunking uh we will see what is sparse mixture of experts model sharding with a little with a very brief introduction with the pipeline parallelism and last but not least we will also go through the code of mistal because there is a lot of innovations in the code especially when they use the x forers library with the block attention so i want to guide you into understanding the code because it can be really hard for beginners to understand and find thems around there are some topics that are related to mistal but will not be covered in this current video because i already covered them in my previous video about llama and in particular i will not be talking about the rms normalization the rotary positional encoding and the group query attention because i already um teach them in depth in my previous video on llama so if you want to know about them please watch my previous video on llama another the only prerequisite that i hope you have before watching this video because the topics we are going to touch are quite advanced is that you are familiar with the transformer model so if youre not familiar with the transformer model and the attention mechanism in particular and in particular the self attention mechanism please go watch my video on the transformer in which i teach all this concept very thoroughly very in detail these are really a prerequisite for watching this video because the top the topics here are quite advanced okay lets proceed further so lets watch the differences between the vanilla transformer and mistal at the architecture level as you can see from the um image here which i built by myself using the code because they didnt release any architecture picture in the paper u the architecture of mistal first of all lets talk about some terminology when you have a model like this made up of many encoder layers plus linear and the soft max we are talking about a decoder only model because this part this model here looks like the decoder of the vanilla transformer you can see here except for the cross attention because as you can see here there is no cross attention when we have a model without the linear and the softmax we call it an incoder only model for example bir is an encoder only model because birth has some heads at at the end which is one or more linear layers depending on the application but it self birth doesnt need a head because it can be used for multiple downstream tasks so its called an encoder only model because it resembles the encoder side of the transformer because as you can see in the encoder side there is no linear and soft max so mistal is a decoder only model and its very similar if not equal to llama the differences between llama and mistal are highlighted here in red the first difference between llama and mistal is that in the self attention we use the sliding window attention and we still use the group query attention but and also the kv cache for inferencing but this is a rolling buffer kv cache and its actually related to the fact that we are using sliding window attention so later we will see all these concepts and the another difference is that the feed forward layer here instead of using the reu function that we used in um in the vanilla transformer or the zigo function that we us in lama here in mistal we use the ceu function um and the feed forward is one in case of mistal 7b so the first model they released and its it can be eight feed forwards uh networks in parallel with each other which are the experts of this mixture of expert in the case of mral 8x 7b um we will see later how it works so for now you just need to understand that mistal is made up of okay the input which are converted into embeddings then we have this block which is repeated n times and we will see that in the case of mistal is repeated 32 times one after another such that the output of each layer is fed to the next layer as input and the output of the last layer is then sent to this rms norm to the linear and to the softmax to produce the output of the model and um this is exactly the same as what we do with any other transformer model usually we have many of this blocks here now in the code of mistal this part here is known as transformer block but its also known as encoder block or decoder block depending on the in the contents of this um block here i will refer to it as an encoder block because if you look at it it looks like exactly as the block of the encoder side so it has a multi header tension od and norm a feed forward and other norm the only difference is that the normalization here comes before the uh the the bl of the feit forward and the self attention okay lets move forward now lets compare the the two models so one is mistal 7b and one in mistal 8x 7b the parameter dim indicates the dimension of the this the dimensions of the embedding vector so how big is the embedding vector so each token is represented by an embedding vector of size 496 dimensions we have 32 of the encoder layers so this block here is repeated 32 times the head dimension indicates as you remember in the multiad attention we have um each head is watching the entire sentence but only a part of the embedding of each token and this indicates how much how many dimensions each head will attend to in each um for in the multiad attention and the hidden dimension here indicates the hidden dimension of the feed forward layer so if the in the case of the fit forward layer we have two linear layers one that converts the the dimension of the embedding vector into the hidden size then another one that converts the hidden size back into the embedding vector dimensions so in the case of the mistal they are using as a hidden size 14336 usually this is a multiple of the dimension and it looks like its 35 the dimension here the number of heads of attention for the query is 32 two while the number of heads for the k and v so the key and values is eight and they are not equal because of the grouped query attention so if you remember from my previous video on lama in which we talk about the group query attention um in the very sim'}, {'role': 'assistant', 'content': '{\n  "introduction": "This video provides an in-depth analysis and tutorial on Mistral, a new language model developed by Mistral AI, a leading European startup in the language model space. The presenter delves into the architectural nuances of Mistral compared to traditional transformers, explores advanced concepts like sliding window attention, the use of a rolling buffer KV cache, sparse mixture of experts model, and the intricacies of coding with the Xformers library for block attention.",\n  "sections": [\n    {\n      "title": "Section 1: Architectural Overview",\n      "content": [\n        "Comparison between Mistral and vanilla transformer models.",\n        "Introduction to decoder-only models and their relevance to Mistral.",\n        "Key architectural differences highlighted, including attention mechanisms and feedforward layers.",\n        "Exploration of the sliding window attention mechanism."\n      ],\n      "topics": ["Transformer Architecture", "Decoder Models", "Sliding Window Attention"]\n    },\n    {\n      "title": "Section 2: Advanced Attention Mechanisms",\n      "content": [\n        "Deep dive into sliding window attention and its computational benefits.",\n        "Discussion on the concept of receptive fields and their analogy in CNNs.",\n        "Introduction to rolling buffer KV cache for efficient memory usage.",\n        "Explanation of chunking and pre-filling techniques for optimized processing."\n      ],\n      "topics": ["Sliding Window Attention", "Receptive Fields", "KV Cache"]\n    },\n    {\n      "title": "Section 3: Sparse Mixture of Experts",\n      "content": [\n        "Introduction to the concept of sparse mixture of experts and its implementation in Mistral.",\n        "Discussion on model sharding and pipeline parallelism for scaling models.",\n        "The significance of selecting experts based on token processing.",\n        "Efficiency gains from using sparse models in terms of computation and specialization."\n      ],\n      "topics": ["Sparse Mixture of Experts", "Model Sharding", "Pipeline Parallelism"]\n    },\n    {\n      "title": "Section 4: Code Innovations",\n      "content": [\n        "Overview of code-level innovations in Mistral, focusing on the Xformers library.",\n        "Explanation of block attention techniques for handling variable-length prompts.",\n        "Strategies for managing KV caches and attention masks in code.",\n        "Insights into the development challenges and solutions for optimizing language model inference."\n      ],\n      "topics": ["Xformers Library", "Block Attention", "Code Optimization"]\n    },\n    {\n      "title": "Section 5: Practical Applications and Coding Tutorial",\n      "content": [\n        "Step-by-step coding tutorial for implementing Mistral features.",\n        "Examples of practical applications and the benefits of Mistral\'s architecture.",\n        "Discussion on the importance of understanding transformer models as a prerequisite.",\n        "Guidance on navigating and understanding the Mistral codebase for developers."\n      ],\n      "topics": ["Coding Tutorial", "Practical Applications", "Understanding Transformers"]\n    }\n  ],\n  "topics": ["Transformer Architecture", "Sliding Window Attention", "Sparse Mixture of Experts", "Code Optimization", "Practical Applications"],\n  "General Topics": [\n    {"topic": "Artificial Intelligence (AI) and Machine Learning", "complexity": 0.89},\n    {"topic": "Software Engineering and System Design", "complexity": 0.75},\n    {"topic": "Programming Languages and Software Development", "complexity": 0.66}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.whats up guys back today with another longer video which is to build a job board app that could actually be a real startup that people use theres a lot of different places to find entry level or junior developer jobs on the internet for example github jobs stack overflow jobs you have angel list you have indeed but filtering through those especially because you kind of have to spam applications for your first job can take a long time so the good thing about all these job boards is they have public apis for the most part you always want to start with an mvp that is the minimum viable product today that means were going to start with a single data feed that is a single job board api feeding into our app and then finally were gonna have a super minimal simple front end were gonna do this in react and material ui on the front end were gonna use an express server redis for our data storage because were not writing or persisting any data that is not part of the job feed and then finally a node cron job to fetch these jobs and refresh them at a certain interval which are going to be filtered through an algorithm so lets draw this all out to get a better idea of our plan heres our front end what we basically want here is a list of jobs this is going to be pulling data from our api and that will be express and then this will pull from our store which is actually going to be redis and redis will be populated by our cron called a worker which is pulling from music one or more apis its going to be eventually multiple this is going to be job uh board apis so like in lets say indeed we have github we have stack jobs and this is going to be filtered through our algorithm were filtering down the jobs getting rid of the senior jobs getting rid of the manager jobs and eventually when we make it more complicated we could even look through the description for years of experience and create uh search indexes and different things like that but again the minimum is just going to be pulling the jobs in and filtering them down okay so this is our plan lets start with the front end i know a lot of you guys like react and its gonna actually be super simple lets just do a create react app to get started uh i already have a folder our directory here called junior dev so lets uh do a create react app and then call it client you guys know that i love material ui so lets install that as well once we get into our client and lets do yarn add okay thats done and we will start our react at okay lets go through the stuff we can actually delete no tests you always want to write tests in real life but not today logo and also clear this out here now lets open the material ui docs lets get our component api and lets get a title for our page typography h1 lets just copy this and instead of putting it directly in app lets make a new component for jobs and then lets make a new component for a single job all job which well use in jobs and then lets import react exports default functions okay in this we will use typography okay so just to explain what im doing here i am making a separate component because i want our app just to hold our state and then jobs will actually hold our component tree our render styling and app will hold our application state our use state and call our hooks for kubota did mount and for state that was really confusing sorry were using typography here and lets do variant typography variant okay im naming our page entry level software jobs i think its a good name then save import jobs throw that in there like this okay that is some huge text but were gonna leave it for now within jobs we already know were gonna um import job make this a similar export well just copy this whole thing almost sneezed okay turn div and then this will just be a single job row which will put on a class name of a single job and then well just do this in advance because we know were going to eventually have to write some css to style this stuff lets make a job list should probably actually be matching our component name just to change that back jobs and then job okay so lets just say that were passing down some props for all our jobs from our uh app which is holding our state lets just do it like this and lets do some mock json that we might return from our api swe software engineer one and company google um theres gonna be a bunch of fields but lets just leave them like that for now and my mock job so we dont get it mixed up mock just being mock json data and it should work then we can do jobs map job this will return a job job job equals job hopefully thats not too confusing okay now you could just hear the structure job in the box but jobtitle lets see if this works there it is jobtitle and jobcompany and lets actually add some css for job and just make it a display flex next direction oh thats right its always freaking hard switching from jsx to javascript okay there we go boom ill leave it like that for now we can add more stuff to this this list if we want like this facebook apple itll map it out for us lets give that a little bit of margin a little bit of padding lets do a 10 pixel top left right zero and then padding will be the same okay not too bad not too bad so our front end we could call this like kind of done lets call this done for now and lets return to it after doing some full stack stuff so im gonna collapse our client lets see what our actual data feed is gonna look like coming from uh our source which im just gonna use as github jobs because i know that has a really good clean api output that you dont need a key for or anything so api github jobs open it up you can see some examples here okay so it says that the api supports pagination itll return 50 at a time and you could do it by adding a parameter to your queries before jumping ahead we just know we want these json representation of these jobs so we can manipulate it with our node worker so what im actually going to do is call a similar url like this in our node side which is going to give us output like this just by eyeballing this i could see that it is somewhat matching what we already wrote out here in appjs where theres a title somewhere yes like that senior full stack nodejs developer and there is a company somewhere and we can also tell in advance that locations going to be an important field too but basing our analysis on this we could start to model kind of what our worker is going to do as well as how we want our api to act as well so looking back at our plan lets actually just make a folder for uh all our boxes here so this is the client right api is going to be simplexpress server and then the worker is going to have our algorithm and its going to be calling our apis on a cron job which is at a set interval so maybe every hour in the day we want to refresh these apis refresh our redis and make sure that everything is up to date theres no expired jobs that the companies dont want people to see anymore and were basically staying i'}, {'role': 'assistant', 'content': '{\n  "introduction": "The video tutorial demonstrates the process of building a job board app from scratch, intended to serve as a real startup platform for entry-level or junior developer positions. It covers the app\'s development from conceptualization to deployment, utilizing various technologies and programming languages.",\n  "sections": [\n    {\n      "title": "Section 1: Project Initialization and MVP",\n      "content": [\n        "Introduction to the project\'s goal of simplifying the job search for entry-level developer positions.",\n        "Decision to start with a single data feed using a job board API.",\n        "Explanation of the Minimum Viable Product (MVP) concept.",\n        "Initial setup of the project using React for the frontend and Express server."\n      ],\n      "topics": ["MVP Concept", "API Integration", "React"]\n    },\n    {\n      "title": "Section 2: Backend Development",\n      "content": [\n        "Setup of the Express server and Redis for data storage.",\n        "Implementation of a Node cron job to fetch and refresh job listings.",\n        "Discussion on filtering algorithms to refine job search results.",\n        "Detailed walkthrough of backend code, including async functions and API fetching."\n      ],\n      "topics": ["Express Server", "Redis", "Node Cron Job"]\n    },\n    {\n      "title": "Section 3: Frontend Development",\n      "content": [\n        "Initial setup of React components for job listings.",\n        "Introduction to Material UI for styling the frontend.",\n        "Development of a simple, user-friendly interface.",\n        "Incorporation of job filtering and pagination on the frontend."\n      ],\n      "topics": ["React Components", "Material UI", "Pagination"]\n    },\n    {\n      "title": "Section 4: Data Filtering and Algorithm",\n      "content": [\n        "Explanation of the algorithm to filter out non-entry level jobs.",\n        "Use of string methods to identify relevant job listings.",\n        "Adjustments to the algorithm for improved accuracy.",\n        "Testing and refining the filtering process."\n      ],\n      "topics": ["Filtering Algorithm", "String Methods", "Algorithm Testing"]\n    },\n    {\n      "title": "Section 5: Deployment",\n      "content": [\n        "Overview of deployment process on a virtual private server.",\n        "Configuration of Nginx and security with SSL certificates.",\n        "Final adjustments for production readiness.",\n        "Live deployment and testing of the job board app."\n      ],\n      "topics": ["Deployment", "Nginx Configuration", "SSL Certificates"]\n    }\n  ],\n  "topics": ["React", "Express Server", "Redis", "Filtering Algorithm", "Deployment"],\n  "General Topics": [\n    {"topic": "Web Development and Internet Technologies", "complexity": 0.45},\n    {"topic": "Software Engineering and System Design", "complexity": 0.65},\n    {"topic": "Data Science and Analytics", "complexity": 0.55}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.rust a memory safe compiled programming language that delivers highlevel simplicity with lowlevel performance its a popular choice for building systems where performance is absolutely critical like game engines databases or operating systems and is an excellent choice when targeting webassembly it started as a side project of great on in 2007 who named it after the rust fungus it was sponsored by mozilla in 2009 and has been ranked the most loved programming language every year since 2016 with its fans being known as rust stations traditionally high level languages provide a garbage collector to nerf your control over memory management while lower level languages provide functions like free and allocate to shoot yourself in the foot rust takes a different approach it has no garbage collector but achieves memory safety with a concept known as ownership and borrowing by default every variable in rust is immutable this allows values to be used in the stack memory which has minimal performance overhead however mutable values or objects with an unknown size at compile time are stored in the heap memory every value in a rust program is assigned to a single variable known as its owner when that variable goes out of scope the memory allocated to it is dropped automatically in some cases though you may want to pass a reference to a different part of the program borrowing allows you to access a reference in memory without taking ownership of it there are a ton of rules to go along with this system that the rus borrow checker will validate at compile time these rules keep your code safe while providing absolute control over performance rust also has a package manager called cargo where each individual package is a crate to get started install rest then run cargo new from the command line in the mainrs file youll find a main function which is where the program will start executing declare a variable with let followed by its name and type the value cant be changed or reassigned by default so add mutt to make it mutable the name of the variable is the owner a reference to its location in memory can be borrowed by other parts of the program by prefixing it with an ampersand then use a macro like print line to log the value to the standard output rest also comes with a standard library that contains modules to handle io the file system concurrency among many other things now compile your code to an executable with the rust compiler you just built a memory safe executable that can handle the most performance intensive system requirements this has been rust in 100 seconds hit the like button and subscribe if you want to see more short videos like this and leave a comment if you want to see a full rust tutorial thanks for watching and i will see you in the next one '}]
    cuda memory allocated: 15.54 GB, cuda memory cached: 16.37 GB
Processing: sql_backend
    Tokens: 7620
Processing: catan
    Tokens: 7774
    Decoding took: 65.976 seconds
    Messages: [{'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.hello guys welcome back to my channel today we are going to talk about mistral so as you know mistral is a new language model that came out a few months ago from mistal ai which is a one of the hottest startup right now in europe for language models it also became a unicorn recently and we will exploring both the models they released one is the 7 billion and one is the 8 by7 billion model so lets review the topics of today the first thing i will introduce you is the architectural differences between the vanilla transformer and the architecture of mistal later we will see what is the sliding window attention and how it is related to the concept of receptive field a concept that usually we find in convolutional neural networks i will briefly review the kv cache because i want to introduce the concept of rolling buffer cache and also how it is done with prefilling and chunking uh we will see what is sparse mixture of experts model sharding with a little with a very brief introduction with the pipeline parallelism and last but not least we will also go through the code of mistal because there is a lot of innovations in the code especially when they use the x forers library with the block attention so i want to guide you into understanding the code because it can be really hard for beginners to understand and find thems around there are some topics that are related to mistal but will not be covered in this current video because i already covered them in my previous video about llama and in particular i will not be talking about the rms normalization the rotary positional encoding and the group query attention because i already um teach them in depth in my previous video on llama so if you want to know about them please watch my previous video on llama another the only prerequisite that i hope you have before watching this video because the topics we are going to touch are quite advanced is that you are familiar with the transformer model so if youre not familiar with the transformer model and the attention mechanism in particular and in particular the self attention mechanism please go watch my video on the transformer in which i teach all this concept very thoroughly very in detail these are really a prerequisite for watching this video because the top the topics here are quite advanced okay lets proceed further so lets watch the differences between the vanilla transformer and mistal at the architecture level as you can see from the um image here which i built by myself using the code because they didnt release any architecture picture in the paper u the architecture of mistal first of all lets talk about some terminology when you have a model like this made up of many encoder layers plus linear and the soft max we are talking about a decoder only model because this part this model here looks like the decoder of the vanilla transformer you can see here except for the cross attention because as you can see here there is no cross attention when we have a model without the linear and the softmax we call it an incoder only model for example bir is an encoder only model because birth has some heads at at the end which is one or more linear layers depending on the application but it self birth doesnt need a head because it can be used for multiple downstream tasks so its called an encoder only model because it resembles the encoder side of the transformer because as you can see in the encoder side there is no linear and soft max so mistal is a decoder only model and its very similar if not equal to llama the differences between llama and mistal are highlighted here in red the first difference between llama and mistal is that in the self attention we use the sliding window attention and we still use the group query attention but and also the kv cache for inferencing but this is a rolling buffer kv cache and its actually related to the fact that we are using sliding window attention so later we will see all these concepts and the another difference is that the feed forward layer here instead of using the reu function that we used in um in the vanilla transformer or the zigo function that we us in lama here in mistal we use the ceu function um and the feed forward is one in case of mistal 7b so the first model they released and its it can be eight feed forwards uh networks in parallel with each other which are the experts of this mixture of expert in the case of mral 8x 7b um we will see later how it works so for now you just need to understand that mistal is made up of okay the input which are converted into embeddings then we have this block which is repeated n times and we will see that in the case of mistal is repeated 32 times one after another such that the output of each layer is fed to the next layer as input and the output of the last layer is then sent to this rms norm to the linear and to the softmax to produce the output of the model and um this is exactly the same as what we do with any other transformer model usually we have many of this blocks here now in the code of mistal this part here is known as transformer block but its also known as encoder block or decoder block depending on the in the contents of this um block here i will refer to it as an encoder block because if you look at it it looks like exactly as the block of the encoder side so it has a multi header tension od and norm a feed forward and other norm the only difference is that the normalization here comes before the uh the the bl of the feit forward and the self attention okay lets move forward now lets compare the the two models so one is mistal 7b and one in mistal 8x 7b the parameter dim indicates the dimension of the this the dimensions of the embedding vector so how big is the embedding vector so each token is represented by an embedding vector of size 496 dimensions we have 32 of the encoder layers so this block here is repeated 32 times the head dimension indicates as you remember in the multiad attention we have um each head is watching the entire sentence but only a part of the embedding of each token and this indicates how much how many dimensions each head will attend to in each um for in the multiad attention and the hidden dimension here indicates the hidden dimension of the feed forward layer so if the in the case of the fit forward layer we have two linear layers one that converts the the dimension of the embedding vector into the hidden size then another one that converts the hidden size back into the embedding vector dimensions so in the case of the mistal they are using as a hidden size 14336 usually this is a multiple of the dimension and it looks like its 35 the dimension here the number of heads of attention for the query is 32 two while the number of heads for the k and v so the key and values is eight and they are not equal because of the grouped query attention so if you remember from my previous video on lama in which we talk about the group query attention um in the very sim'}, {'role': 'assistant', 'content': '{\n  "introduction": "This video provides an in-depth analysis and tutorial on Mistral, a new language model developed by Mistral AI, a leading European startup in the language model space. The presenter delves into the architectural nuances of Mistral compared to traditional transformers, explores advanced concepts like sliding window attention, the use of a rolling buffer KV cache, sparse mixture of experts model, and the intricacies of coding with the Xformers library for block attention.",\n  "sections": [\n    {\n      "title": "Section 1: Architectural Overview",\n      "content": [\n        "Comparison between Mistral and vanilla transformer models.",\n        "Introduction to decoder-only models and their relevance to Mistral.",\n        "Key architectural differences highlighted, including attention mechanisms and feedforward layers.",\n        "Exploration of the sliding window attention mechanism."\n      ],\n      "topics": ["Transformer Architecture", "Decoder Models", "Sliding Window Attention"]\n    },\n    {\n      "title": "Section 2: Advanced Attention Mechanisms",\n      "content": [\n        "Deep dive into sliding window attention and its computational benefits.",\n        "Discussion on the concept of receptive fields and their analogy in CNNs.",\n        "Introduction to rolling buffer KV cache for efficient memory usage.",\n        "Explanation of chunking and pre-filling techniques for optimized processing."\n      ],\n      "topics": ["Sliding Window Attention", "Receptive Fields", "KV Cache"]\n    },\n    {\n      "title": "Section 3: Sparse Mixture of Experts",\n      "content": [\n        "Introduction to the concept of sparse mixture of experts and its implementation in Mistral.",\n        "Discussion on model sharding and pipeline parallelism for scaling models.",\n        "The significance of selecting experts based on token processing.",\n        "Efficiency gains from using sparse models in terms of computation and specialization."\n      ],\n      "topics": ["Sparse Mixture of Experts", "Model Sharding", "Pipeline Parallelism"]\n    },\n    {\n      "title": "Section 4: Code Innovations",\n      "content": [\n        "Overview of code-level innovations in Mistral, focusing on the Xformers library.",\n        "Explanation of block attention techniques for handling variable-length prompts.",\n        "Strategies for managing KV caches and attention masks in code.",\n        "Insights into the development challenges and solutions for optimizing language model inference."\n      ],\n      "topics": ["Xformers Library", "Block Attention", "Code Optimization"]\n    },\n    {\n      "title": "Section 5: Practical Applications and Coding Tutorial",\n      "content": [\n        "Step-by-step coding tutorial for implementing Mistral features.",\n        "Examples of practical applications and the benefits of Mistral\'s architecture.",\n        "Discussion on the importance of understanding transformer models as a prerequisite.",\n        "Guidance on navigating and understanding the Mistral codebase for developers."\n      ],\n      "topics": ["Coding Tutorial", "Practical Applications", "Understanding Transformers"]\n    }\n  ],\n  "topics": ["Transformer Architecture", "Sliding Window Attention", "Sparse Mixture of Experts", "Code Optimization", "Practical Applications"],\n  "General Topics": [\n    {"topic": "Artificial Intelligence (AI) and Machine Learning", "complexity": 0.89},\n    {"topic": "Software Engineering and System Design", "complexity": 0.75},\n    {"topic": "Programming Languages and Software Development", "complexity": 0.66}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.whats up guys back today with another longer video which is to build a job board app that could actually be a real startup that people use theres a lot of different places to find entry level or junior developer jobs on the internet for example github jobs stack overflow jobs you have angel list you have indeed but filtering through those especially because you kind of have to spam applications for your first job can take a long time so the good thing about all these job boards is they have public apis for the most part you always want to start with an mvp that is the minimum viable product today that means were going to start with a single data feed that is a single job board api feeding into our app and then finally were gonna have a super minimal simple front end were gonna do this in react and material ui on the front end were gonna use an express server redis for our data storage because were not writing or persisting any data that is not part of the job feed and then finally a node cron job to fetch these jobs and refresh them at a certain interval which are going to be filtered through an algorithm so lets draw this all out to get a better idea of our plan heres our front end what we basically want here is a list of jobs this is going to be pulling data from our api and that will be express and then this will pull from our store which is actually going to be redis and redis will be populated by our cron called a worker which is pulling from music one or more apis its going to be eventually multiple this is going to be job uh board apis so like in lets say indeed we have github we have stack jobs and this is going to be filtered through our algorithm were filtering down the jobs getting rid of the senior jobs getting rid of the manager jobs and eventually when we make it more complicated we could even look through the description for years of experience and create uh search indexes and different things like that but again the minimum is just going to be pulling the jobs in and filtering them down okay so this is our plan lets start with the front end i know a lot of you guys like react and its gonna actually be super simple lets just do a create react app to get started uh i already have a folder our directory here called junior dev so lets uh do a create react app and then call it client you guys know that i love material ui so lets install that as well once we get into our client and lets do yarn add okay thats done and we will start our react at okay lets go through the stuff we can actually delete no tests you always want to write tests in real life but not today logo and also clear this out here now lets open the material ui docs lets get our component api and lets get a title for our page typography h1 lets just copy this and instead of putting it directly in app lets make a new component for jobs and then lets make a new component for a single job all job which well use in jobs and then lets import react exports default functions okay in this we will use typography okay so just to explain what im doing here i am making a separate component because i want our app just to hold our state and then jobs will actually hold our component tree our render styling and app will hold our application state our use state and call our hooks for kubota did mount and for state that was really confusing sorry were using typography here and lets do variant typography variant okay im naming our page entry level software jobs i think its a good name then save import jobs throw that in there like this okay that is some huge text but were gonna leave it for now within jobs we already know were gonna um import job make this a similar export well just copy this whole thing almost sneezed okay turn div and then this will just be a single job row which will put on a class name of a single job and then well just do this in advance because we know were going to eventually have to write some css to style this stuff lets make a job list should probably actually be matching our component name just to change that back jobs and then job okay so lets just say that were passing down some props for all our jobs from our uh app which is holding our state lets just do it like this and lets do some mock json that we might return from our api swe software engineer one and company google um theres gonna be a bunch of fields but lets just leave them like that for now and my mock job so we dont get it mixed up mock just being mock json data and it should work then we can do jobs map job this will return a job job job equals job hopefully thats not too confusing okay now you could just hear the structure job in the box but jobtitle lets see if this works there it is jobtitle and jobcompany and lets actually add some css for job and just make it a display flex next direction oh thats right its always freaking hard switching from jsx to javascript okay there we go boom ill leave it like that for now we can add more stuff to this this list if we want like this facebook apple itll map it out for us lets give that a little bit of margin a little bit of padding lets do a 10 pixel top left right zero and then padding will be the same okay not too bad not too bad so our front end we could call this like kind of done lets call this done for now and lets return to it after doing some full stack stuff so im gonna collapse our client lets see what our actual data feed is gonna look like coming from uh our source which im just gonna use as github jobs because i know that has a really good clean api output that you dont need a key for or anything so api github jobs open it up you can see some examples here okay so it says that the api supports pagination itll return 50 at a time and you could do it by adding a parameter to your queries before jumping ahead we just know we want these json representation of these jobs so we can manipulate it with our node worker so what im actually going to do is call a similar url like this in our node side which is going to give us output like this just by eyeballing this i could see that it is somewhat matching what we already wrote out here in appjs where theres a title somewhere yes like that senior full stack nodejs developer and there is a company somewhere and we can also tell in advance that locations going to be an important field too but basing our analysis on this we could start to model kind of what our worker is going to do as well as how we want our api to act as well so looking back at our plan lets actually just make a folder for uh all our boxes here so this is the client right api is going to be simplexpress server and then the worker is going to have our algorithm and its going to be calling our apis on a cron job which is at a set interval so maybe every hour in the day we want to refresh these apis refresh our redis and make sure that everything is up to date theres no expired jobs that the companies dont want people to see anymore and were basically staying i'}, {'role': 'assistant', 'content': '{\n  "introduction": "The video tutorial demonstrates the process of building a job board app from scratch, intended to serve as a real startup platform for entry-level or junior developer positions. It covers the app\'s development from conceptualization to deployment, utilizing various technologies and programming languages.",\n  "sections": [\n    {\n      "title": "Section 1: Project Initialization and MVP",\n      "content": [\n        "Introduction to the project\'s goal of simplifying the job search for entry-level developer positions.",\n        "Decision to start with a single data feed using a job board API.",\n        "Explanation of the Minimum Viable Product (MVP) concept.",\n        "Initial setup of the project using React for the frontend and Express server."\n      ],\n      "topics": ["MVP Concept", "API Integration", "React"]\n    },\n    {\n      "title": "Section 2: Backend Development",\n      "content": [\n        "Setup of the Express server and Redis for data storage.",\n        "Implementation of a Node cron job to fetch and refresh job listings.",\n        "Discussion on filtering algorithms to refine job search results.",\n        "Detailed walkthrough of backend code, including async functions and API fetching."\n      ],\n      "topics": ["Express Server", "Redis", "Node Cron Job"]\n    },\n    {\n      "title": "Section 3: Frontend Development",\n      "content": [\n        "Initial setup of React components for job listings.",\n        "Introduction to Material UI for styling the frontend.",\n        "Development of a simple, user-friendly interface.",\n        "Incorporation of job filtering and pagination on the frontend."\n      ],\n      "topics": ["React Components", "Material UI", "Pagination"]\n    },\n    {\n      "title": "Section 4: Data Filtering and Algorithm",\n      "content": [\n        "Explanation of the algorithm to filter out non-entry level jobs.",\n        "Use of string methods to identify relevant job listings.",\n        "Adjustments to the algorithm for improved accuracy.",\n        "Testing and refining the filtering process."\n      ],\n      "topics": ["Filtering Algorithm", "String Methods", "Algorithm Testing"]\n    },\n    {\n      "title": "Section 5: Deployment",\n      "content": [\n        "Overview of deployment process on a virtual private server.",\n        "Configuration of Nginx and security with SSL certificates.",\n        "Final adjustments for production readiness.",\n        "Live deployment and testing of the job board app."\n      ],\n      "topics": ["Deployment", "Nginx Configuration", "SSL Certificates"]\n    }\n  ],\n  "topics": ["React", "Express Server", "Redis", "Filtering Algorithm", "Deployment"],\n  "General Topics": [\n    {"topic": "Web Development and Internet Technologies", "complexity": 0.45},\n    {"topic": "Software Engineering and System Design", "complexity": 0.65},\n    {"topic": "Data Science and Analytics", "complexity": 0.55}\n  ]\n}\n'}, {'role': 'user', 'content': 'General Topics:\n[\n  "Algorithms and Data Structures",\n  "Artificial Intelligence (AI) and Machine Learning",\n  "Computer Architecture",\n  "Data Science and Analytics",\n  "Database Systems and Management",\n  "Human-Computer Interaction (HCI)",\n  "Programming Languages and Software Development",\n  "Software Engineering and System Design",\n  "Web Development and Internet Technologies",\n  "Computer Graphics and Visualization",\n  "Theoretical Computer Science",\n  "Quantum Computing"\n]\n\nComplexity scale:\n[\n  0.00-0.09: Elementary,\n  0.10-0.19: Middle School,\n  0.20-0.29: High School,\n  0.30-0.39: Advanced High School,\n  0.40-0.49: Introductory College,\n  0.50-0.59: Average College Lecture,\n  0.60-0.69: Advanced College,\n  0.70-0.79: Graduate Level,\n  0.80-0.89: Advanced Graduate Level,\n  0.90-1.00: PhD Level Lecture\n]\n\nYou have a very strong understanding of software and engineering concept. You will produce a summary of the text below. The text above is a transcript from a computer science or software engineering related video. Output in JSON format. Produce a high level synopsis of the video: "introduction". Then break the video down into 5 sections under "sections". Each section has "title" beginning with "Section x", "content", and "topics". "content" should provide 4 bullets on what the section is about. You must use as many domain based words as possible in both the "title" and "content". "topics" should be the most import 3 topics in the section. Include a global "topics" array that has 5 1-2 word descriptor topics covered in the video. Include a global "general topics" array that has 3 topics from the array above. Each general topic will have an exact "complexity" score with full two-decimal-place precision using the scale above to accurately reflect a detailed complexity. Do not include any other sections. Do not generate more than the JSON itself.music whats going on danny crew its danny drew here and we are back for another day of kadan in todays lesson video we are going to be talking about the placement traps that kill your game before it even starts i have seen too many new and beginning players play the game of katon make subtle placement decisions that absolutely eviscerate your chances of winning what were going to do is were going to break down these traps were to go through each one with a little bit of nuance and hopefully by the end of this video you will be placing better and winning more games if youre ready lets get into it get excited cuz i certainly am i want to make a quick statement here before we get into the examples which is that not every trap is necessarily a trap its more important to realize that certain situations have certain nuances and its important for you to read the board use the previous lesson videos we talked about placements and placing out and to be able to make a good read if this is going to be a trap or not as an example well walk through some of these key traps placing next to a starting road this is a very common mistake where a lot of players dont see that a player on the way back and start with a road and then drop a road onto their road and they lose the spot theyre going to so the plow we i think weve all been there weve all seen it how about starting with inflexible to resource setups a lot of players love to go for like a double or sheep theres some issues with that which is that it offers potentially some inflexibility again you have to back all these decisions up with good calculation placing with inflexible ports maybe you have a ton of wood and you dont have a way to use it effectively thats a problem how about building on only one potential road subtle well show some examples of that and the last one which you know you have to make a judgment call but placing on setups that might get over blocked op setups you know that 659 or we cheap probably worth taking in most cases but you have to know the dynamic of the board and know if youre going to get outpaced by the rest of the board so lets get into an example here im super excited i hope you are too why dont we sit down for a second pause the board if you need to do some calculations and i would recommend you place this board out as much as you can see if you can pick first second third fourth all the way through to all eight placements and then when youre done with that unpause the video and well talk about how this game actually occurred hopefully you did that so here you go the first placement on this board was 6510 and the whole idea is they want to go 6510 to 810 why is this a placement trap well theres a few reasons if you look at the makeup of this board the first thing is that 6510 is nice on the surface but youre only going to one subtle spot which is the 810 that would be okay but the issue here in first is its not guaranteed youre going to get the 810 if you look at the wheat on this board the eight is the best wheat so you know it has value with all this ore thats on this board but also the 810 is a fantastic spot potentially for like the five9 10 player so i think if black was just being a little bit more critical about their calculations they would see 6510 is probably losing the 810 in most cases and this makes it a very bad pick so first trap be careful make sure you back up your placement decision with good calculation second picks the 5910 now kind of playing off of what we saw in the previous slide the 5910 obviously can take the 810 but youre going to see that there are some clear problems with this one of the issues i have with the 5910 point left is that its too inflexible pointing left to a brick port makes no sense much better in this situation is the point up now it is true that the 5910 left gives you two settles but frankly youre probably not beating the 1083 at the bottom here to the brick port so effectively you have one settle on the five so much better is if you point up here then you get the road subtle onto the 52 but you also get the 31 which plays much better with the setup than simply playing off the brck port so be very careful about taking inflexible setups in second third takes the 643 here at the top you can see that makes a lot of sense now the question for you is what do you do in fourth i want you to pause the video and place it out take as much time as you need but make sure you do the exercise and come back id be very curious in the comments can you tell me what you picked here for fourth id be very very curious type it in now uh that way you dont see the answer give you a second 5 4 3 2 1 all right so this is what fourth decided to pick the 942 and the 8103 now clearly reds intention here was that they wanted to go for ows they want to go 52 get the pork get the or but whats the issue with this well i think a lot of things are going to be clear when you understand the forcing sequence and i believe that this sequence is absolutely forced because if you do your calculations again everything needs to be placed out with calculations and consideration then this is what happen on the way back this player here takes the 853 because they do not want to ever give that spot to the 5109 but then you ask where does the 5109 go well we talked about this earlier theyre going to go in the 810 all of this has been forced given reds placements so then black has to take the space it makes sense they have the wood and the brick they take the 5411 now they should have pointed left because road settling on the 9 through1 is much better than pointing right but i want you to see out of all that entire situation we could have calculated purple settle we could have calculated a white settle and we could have seen whats going to happen now the big issue for red is that hes playing ows when you have two other ows players and hes way too slow he needs to road settle 52 he needs to be buying development cards while trying to build a city and trying to compete against two people who are literally all o ws its not going to happen and the final result of this game is essentially that red took road here so theyre theyre sitting here with eight points theyre essentially six points with longest road and then they need to manufacture two more points while not losing road to black ultimately what happened was that purple here just absolutely cooked dropped four cities vp just built a tent uh didnt even need armor which is crazy that blacket army here but you can see the inflexibility of these setups really became problematic red i think went for the wrong plan on the wrong board and it cost him the game so knowing this what would you do here what you do here and forth i want you to revisit the fact and maybe if you pick that setup thats perfectly fine the 492 8103 but how can we essentially change our thought here we know ows is not the way buying development cards is going to be too heavily conteste'}]
    cuda memory allocated: 17.03 GB, cuda memory cached: 18.01 GB
Processing: hashing
    Tokens: 7633
