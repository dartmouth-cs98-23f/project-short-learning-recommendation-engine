{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import time\n",
    "import math, random\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "from pymongo.server_api import ServerApi\n",
    "from pinecone import Pinecone\n",
    "\n",
    "## Load Config\n",
    "with open('config/videos.json') as config_file:\n",
    "    videos = json.load(config_file)\n",
    "with open('config/name_to_url.json') as config_file:\n",
    "    name_to_url = json.load(config_file)\n",
    "with open('config/alltopics.json') as config_file:\n",
    "    alltopics = json.load(config_file)\n",
    "with open ('config/inferenceTopics.json') as config_file:\n",
    "    inferenceTopicsJson = json.load(config_file)\n",
    "with open('config/indexedtopics.json') as config_file:\n",
    "    file = json.load(config_file)\n",
    "    indexedtopics = {}\n",
    "    for i in range(len(file)):\n",
    "        obj = file[i]\n",
    "        indexedtopics[obj[\"topic\"]] = obj[\"subtopics\"]\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "CUR_DIR = os.getcwd()\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_KEY\"])\n",
    "index = pc.Index(\"pretechnigala\")\n",
    "DB_NAME = \"preTechnigalaClean_db\"\n",
    "DB_NAME1 = \"preTechnigalaClean1_db\"\n",
    "\n",
    "COLLECTION_NAME = \"video_metadata\"\n",
    "MONGO_DB_CLIENT = MongoClient(os.getenv(\"MONGODB_URI\"), server_api=ServerApi('1'))\n",
    "OUTPUT_DIR = f\"{CUR_DIR}/data/topics\"\n",
    "QUERY_MODE = \"avg\"  \n",
    "VECTOR_MODE = \"avg\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE SOME FAKE WATCH HISTORY OF 10 VIDEOS\n",
    "maintopic = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2270914621.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def generateHistoryJson:clipIds: list = []\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### CREATE SOME FAKE WATCH HISTORY OF \n",
    "def generateHistoryJson(doc_list, topic_id, limit):\n",
    "    subtopics = indexedtopics[str(topic_id)] + [topic_id]\n",
    "    docs = MONGO_DB_CLIENT[DB_NAME][COLLECTION_NAME].find(\n",
    "        {\"topicId\": {\"$in\": subtopics}})\n",
    "    doc_list = []\n",
    "    for doc in docs:\n",
    "        doc_list.append(doc)\n",
    "        clipIds: list = []\n",
    "        videoIds = []\n",
    "        durations = []\n",
    "        for i in range(limit):\n",
    "            random_doc = random.choice(doc_list)\n",
    "            clipIds.append(str(random_doc[\"clips\"][1]))\n",
    "            videoIds.append(str(random_doc[\"_id\"]))\n",
    "            durations.append(30)\n",
    "            print(random_doc)\n",
    "    return {\"clipIds\": clipIds, \"videoIds\": videoIds, \"durations\": durations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_ids = set()\n",
    "for doc in MONGO_DB_CLIENT[DB_NAME][COLLECTION_NAME].find():\n",
    "    good_ids.add(str(doc[\"_id\"]))\n",
    "\n",
    "bad_ids = set()\n",
    "for doc in MONGO_DB_CLIENT[DB_NAME1][COLLECTION_NAME].find():\n",
    "    if doc[\"_id\"] not in good_ids:\n",
    "        bad_ids.add(str(doc[\"_id\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = f'{CUR_DIR}/pipeline/data/outputs'\n",
    "\n",
    "vectors = []\n",
    "for id in os.listdir(DIR):\n",
    "    tensor = torch.load(f'{DIR}/{id}/avg_pool.pt', map_location=torch.device('cpu')).numpy().tolist()\n",
    "    if id in good_ids:\n",
    "        current_doc = MONGO_DB_CLIENT[DB_NAME][COLLECTION_NAME].find_one({\"_id\": ObjectId(id)})\n",
    "        metadata_avg = {\"mode\": \"avg_pool\", \"title\": current_doc[\"title\"], \"topics\": [str(topic) for topic in current_doc[\"topicId\"]], \"videoID\": str(current_doc[\"_id\"]), \"inferenceTopics\": [], \"inferenceComplexities\": []}\n",
    "        vectors.append({\"values\": tensor, \"id\": f'{id}_avg', \"metadata\": metadata_avg})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 127}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upsert 1/4\n",
    "index.upsert(vectors[:100])\n",
    "index.upsert(vectors[100:200])\n",
    "index.upsert(vectors[200:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.delete(ids=[f'{str(bad_id)}_avg' for bad_id in bad_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverseInferenceTopicsJson = {}\n",
    "for k,v in inferenceTopicsJson.items():\n",
    "    reverseInferenceTopicsJson[v] = k\n",
    "print (reverseInferenceTopicsJson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add inferencetopicsIds field\n",
    "for doc in MONGO_DB_CLIENT[DB_NAME][COLLECTION_NAME].find():\n",
    "    inferenceTopicIds = []\n",
    "    try:\n",
    "        inferenceTopics = doc['inferenceTopics']\n",
    "        inferenceTopicIds = []\n",
    "        for topic in inferenceTopics:\n",
    "            inferenceTopicIds.append(int(reverseInferenceTopicsJson[topic]))\n",
    "        ## Add upload topicIds \n",
    "        doc['inferenceTopicIds'] = inferenceTopicIds\n",
    "        MONGO_DB_CLIENT[DB_NAME][COLLECTION_NAME].update_one({'_id': ObjectId(doc['_id'])}, {\"$set\": doc}, upsert=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in doc: {doc['_id']}, {e}\")\n",
    "        doc['inferenceTopicIds'] = inferenceTopicIds\n",
    "        MONGO_DB_CLIENT[DB_NAME][COLLECTION_NAME].update_one({'_id': ObjectId(doc['_id'])}, {\"$set\": doc}, upsert=False)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If documentID does not have a matching one in Collection2, remove it CLEANS DB\n",
    "COLLECTION2 = \"inference_summary\"\n",
    "knownIds = set()\n",
    "for doc in MONGO_DB_CLIENT[DB_NAME][COLLECTION2].find():\n",
    "    knownIds.add(str(doc['_id']))\n",
    "for doc in MONGO_DB_CLIENT[DB_NAME][COLLECTION_NAME].find():\n",
    "    try:\n",
    "        if str(doc['_id']) not in knownIds:\n",
    "            print(f\"Removing doc: {doc['_id']}\")\n",
    "            MONGO_DB_CLIENT[DB_NAME][COLLECTION_NAME].delete_one({'_id': ObjectId(doc['_id'])})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in doc: {doc['_id']}, {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a copy of it in \"video_metadata_backup\" collection\n",
    "\n",
    "for doc in MONGO_DB_CLIENT[DB_NAME][COLLECTION_NAME].find():\n",
    "    try:\n",
    "        MONGO_DB_CLIENT[DB_NAME][\"video_metadata_backup\"].insert_one(doc)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in doc: {doc['_id']}, {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each doc, append id 65e619556bea5f71742c85e7 to 'clips'\n",
    "for doc in MONGO_DB_CLIENT[DB_NAME][COLLECTION_NAME].find():\n",
    "    try:\n",
    "        doc['clips'] = [ObjectId(\"65e619556bea5f71742c85e7\")]\n",
    "        MONGO_DB_CLIENT[DB_NAME][COLLECTION_NAME].update_one({'_id': ObjectId(doc['_id'])}, {\"$set\": doc}, upsert=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in doc: {doc['_id']}, {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example arrays\n",
    "array1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])    \n",
    "array2 = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# Perform the weighted addition\n",
    "result = array1 + 0.1 * array2\n",
    "\n",
    "# Renormalize to range 0-1\n",
    "min_val = np.min(result)\n",
    "max_val = np.max(result)\n",
    "renormalized = (result - min_val) / (max_val - min_val)\n",
    "\n",
    "print(\"Original Result:\", result)\n",
    "print(\"Renormalized Result:\", renormalized)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS98",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
